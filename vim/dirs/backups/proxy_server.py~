#!/usr/bin/python
# -*- coding:utf-8 -*-
#****************************************************************#
# ScriptName: server.py
# Author: yutao.yutao@alibaba-inc.com
# Create Date: 2017-02-24 16:08
# Modify Author: $SHTERM_REAL_USER@alibaba-inc.com
# Modify Date: 2018-09-13 18:04
# Function: 
#***************************************************************#
import os
import json
import copy
import shutil
import commands
import re
import httplib
import requests
from subprocess import Popen, PIPE, STDOUT

import common_pb2
import loadbalancer_pb2
import proxy_pb2
import response_pb2
import cgi
import datetime
import time 
import ipaddress 
import OpenSSL

if __name__ == '__main__':
    import sys
    sys.path.append("/home/slb/control-proxy")

from lib.config import readConfig, my_log_info, my_log_error, set_request_id
from lib.config import DEFAULT_TENGINE_PATH, LOADING_RETRY_COUNT
#from lib.agent_server import config
import gevent
from proxy_template import *
import syslog
import sys
import traceback

from lib.netaddr.ip import IPNetwork
from threading import Thread
import threading
import time

UPS_KEEPALIVE_DEFAULT = 9
UPS_KEEPALIVE_TIMEOUT_NEVER = 0
UPS_KEEPALIVE_TIMEOUT_DEFAULT = 60
UPS_KEEPALIVE_MAX_REQUESTS = 100
DYUPS_PORT = 6677
DYCONF_PORT = 8089
DYCERT_PORT = 8090
LISTEN_FILE = '/etc/proxy/conf/listen.conf'
WILDCONF_SYNC_FILE = '/home/slb/control-proxy/conf/wildconf.yaml'
STREAM_LISTEN_FILE = '/etc/proxy/conf/stream_listen.conf'
QUIC_LISTEN_FILE = '/etc/proxy/conf/quic_listen.conf'
SLB_SECURE_COOKIE = 0x1
SLB_HTTPONLY_COOKIE = 0x2
SLB_SECURE_HTTPONLY_COOKIE = 0x3
DEFAULT_QPS = 8111
DEFAULT_QPS_SLA = DEFAULT_QPS*8
MIN_QPS = 1000
START_PORT = 30000 #temp value
END_PORT = 60000
UT = 0
WILDCONF_SYNC = 1
DYUPS_TIMEOUT = 6
DEFAULT_ID_VALUE = "none"

KEYSERVER_VIPS_SWITCH = 0 # decide whether use keyserver_vips or not

# check for Elastic PPU
def is_eppu(listen):
    pilen = len(listen.layer_seven_port_info)
    #Elastic PPU only works for standard double sites PPU
    #Elastic PPU is meaningful when there are more than one PPUs
    #layer_seven_port_info should be even
    if (pilen >= 4) and ((pilen % 2) == 0):
        return True
    else:
        if pilen > 0:
            log_error("fatal error [Eppu] single site eppu found")
            return True
        return False
# get vip for Elastic PPU
def get_port_from_eppu(listen):
    global device_group

    if device_group == None:
        log_error("get_port_from_eppu [Eppu] device_group is None")
        return None, AGENT_ERR
    else:
        isfound = 0
        for ppu in listen.layer_seven_port_info:
            if ppu.device_group_name == device_group.device_group_name:
                isfound = 1
                break
        if isfound == 0:
            log_error("get_port_from_eppu [Eppu] can't find matched device_group_name %s" % device_group.device_group_name)
            return None, AGENT_ERR
        #sanity check here
        if abs(ppu.plug_count - device_group.device_count.plugged_count) > 1:
            if ppu.plug_count != 0:
                 log_error("get_port_from_eppu [Eppu] plugin count gap: %d,%d" % (ppu.plug_count, device_group.device_count.plugged_count))
                 return None, AGENT_ERR
        vip = ppu.port
    return vip, AGENT_OK

#update layer_seven_port_info
def update_l7port_infos(src_layer_seven_port_info, dst_layer_seven_port_info):
    #always overwrite dst by src
    if len(src_layer_seven_port_info) == 0:#add protection code
        return
    del dst_layer_seven_port_info[:]    
    for pi in src_layer_seven_port_info:
        newpi = dst_layer_seven_port_info.add()
        newpi.CopyFrom(pi)    

#get device count from layer_seven_port_info
def get_dc_from_l7portinfos(listen, use_global_dc):
    global device_group

    if use_global_dc:
        return int(device_group.device_count.plugged_count)
    plug_counts = []
    device_count = 0
    for pi in listen.layer_seven_port_info:
        if pi.plug_count != 0:
            plug_counts.append(pi.plug_count)
    plug_counts.sort()
    for i in range(0, len(plug_counts)/2):
        device_count += plug_counts[i]
    #log_info("get_dc_from_l7portinfos [Eppu] device_count %d" % (device_count/2))

    return device_count

#sanity check
def verify_devicegroup(dg):
     if dg.start_port < START_PORT or dg.end_port  > END_PORT:
         log_error('[Error][verify_devicegroup] device group out of range')
         return False
     if dg.start_port > dg.end_port:
         log_error('[Error][verify_devicegroup] device group port out of range')
         return False
     if dg.device_count.plugged_count < 1:
         log_error('[Error][verify_devicegroup] device group  plugged_count out of range')
         return False
     return True

def verify_listen(ls, vip, incr=False, create=False):
    #if not ls.HasFeild('port'), ls.port is 0
    if vip < START_PORT or vip > END_PORT:
        log_error('[Error][verify_listen] listen port out of range')
        return False

    if ls.HasField("config") and ls.config.HasField('sla_config'):
        if ls.config.sla_config.qps != 0:
             log_error('[Error][verify_listen] listen has valid qps configed')
             return False
        if verify_backend_protocol(ls) is False:
            return False
        if ls.HasField('config') and ls.config.HasField('check'):
            if verify_health_check_type(ls, ls.config.check) is False:
                return False
    for rs in ls.realserver:
        ret = check_rs(rs)
        if ret == False:
            return ret
    if create:
        ret = check_wildconfiginfolist(ls.httpWildConfigInfoList)
        if ret == False:
            log_error('[Error][verify_listen] verify WildConfigInfo of listen failed')
            return ret

    is_app_rule = False
    if ls.HasField("is_app_rule") and ls.is_app_rule == 1:
        is_app_rule = True
    for rule in ls.http_rule:
        if create and is_app_rule and len(rule.httpWildConfigInfoList) > 0:
            ret = check_wildconfiginfolist(rule.httpWildConfigInfoList)
            if ret == False:
                log_error('[Error][verify_listen] verify WildConfigInfo of listen failed')
                return ret
        if is_app_rule and rule.state == proxy_pb2.HttpRule.CREATED:
            if rule.HasField("priority"):
                if rule.priority < 0 or rule.priority > 2147483646:
                    log_error('[Error][verify_listen] invalid priority %d for app rule %s' % (rule.priority, rule.name))
                    return False
            elif not incr:
                log_error('[Error][verify_listen] no priority set for app rule %s' % rule.name)
                return False
            for condition in rule.conditions:
                if condition.type == proxy_pb2.Condition.HEADER and not condition.HasField("header_key"):
                    log_error('[Error][verify_listen] invalid condition without header_key in app rule %s' % rule.name)
                    return False
        if rule.HasField("config") and rule.config.HasField('sla_config'):
            if rule.config.sla_config.qps != 0:
                 log_error('[Error][verify_listen] rule has valid qps configed')
                 return False
            if rule.config.HasField('check'):
                if verify_health_check_type(ls, rule.config.check) == False:
                    return False
        for rs in rule.realserver:
            ret = check_rs(rs)
            if ret == False:
                return ret

    return True

def verify_lb(lb):
    if lb.HasField("sla_config") and lb.sla_config.HasField('qps'):
        if lb.sla_config.qps < MIN_QPS:
            log_error('[Error][verify_lb] qps check failed')
            return False
    return True

def verify_backend_protocol(ls):
    if ls.HasField("backend_protocol"):
        if not ls.backend_protocol in ['http', 'https']:
            log_error('[Error][verify_backend_protocol] backend_protocol should be http or https')
            return False
    return True

def verify_health_check_type(ls, check):
    backend_protocol = build_backend_protocol(ls)
    #log_info('[verify_health_check_type] backend_protocol %s' % (backend_protocol))
    if check.HasField('check_type'):
        if not check.check_type in [common_pb2.HealthCheck.HTTP, common_pb2.HealthCheck.TCP]:
            log_error('[Error][verify_health_check_type] unsupported health check type')
            return False
    return True

def gen_ssl_ciphers(ciphers):
    ssl_cipher_list = []
    ssl_ciphersuite_list = []
    ssl_ciphers = ""

    ssl_ciphersuite_name = ['TLS_AES_128_GCM_SHA256', 'TLS_AES_256_GCM_SHA384', 
                            'TLS_CHACHA20_POLY1305_SHA256', 'TLS_AES_128_CCM_SHA256',
                            'TLS_AES_128_CCM_8_SHA256']

    cipher_list = ciphers.split(',')

    count = 0
    while count < len(cipher_list):
        if cipher_list[count] in ssl_ciphersuite_name:
            ssl_ciphersuite_list.append(cipher_list[count])
        else:
            ssl_cipher_list.append(cipher_list[count])
        count += 1

    if len(ssl_ciphersuite_list) != 0:
        ssl_ciphers = "\tssl_ciphersuites " + ":".join(ssl_ciphersuite_list) + ";\n"

    if len(ssl_cipher_list) != 0:
        ssl_ciphers += "\tssl_ciphers " + ":".join(ssl_cipher_list) + ";\n"

    return ssl_ciphers

# check if bgpd_init.conf exists
if os.path.exists('/etc/quagga/bgpd_init.conf'):
    from lib.slbutil.bgp_util import bgp_util as route_util
else:
    from lib.slbutil.ospf_util import ospf_util as route_util

def is_hotconf_enable():    
    return 'tengine_hotconfig' in config and config['tengine_hotconfig'] == 'enable'

def is_websocket_enable():
    return 'tengine_websocket' in config and config['tengine_websocket'] == 'enable'

def is_http2_enable():
    return 'tengine_http2' in config and config['tengine_http2'] == 'enable'
	
def is_sslsync_enable():
    return 'tengine_sslsync' in config and config['tengine_sslsync'] == 'enable'

def is_force_http_version():
    if 'proxy_http_version' in config:
        if config['proxy_http_version'] == 1.1 or config['proxy_http_version'] == 1.0 \
           or config['proxy_http_version'] == 'auto':
            return True
    return False

def log_info(message):
    #print(message)
    my_log_info("proxy_server", message)

def log_error(message, exc_info = False):
    #print(message)
    my_log_error("proxy_server", message, exc_info)

PROXY_CONF_DIR = '/etc/proxy/conf/'
VIP_CONF_DIR = PROXY_CONF_DIR + 'vip/'
VIP_CONF_DIR_NEW = PROXY_CONF_DIR + 'vip.new/'
STREAM_VIP_CONF_DIR = PROXY_CONF_DIR + 'stream_vip/'
STREAM_VIP_CONF_DIR_NEW = PROXY_CONF_DIR + 'stream_vip.new/'
QUIC_VIP_CONF_DIR = PROXY_CONF_DIR + 'quic_vip/'
QUIC_VIP_CONF_DIR_NEW = PROXY_CONF_DIR + 'quic_vip.new/'
UPSREAM_FILE_NEW = PROXY_CONF_DIR + 'upstreams.conf.new'
DEFAULT_PROXY_FILE_NEW = PROXY_CONF_DIR + 'proxy.conf.new'
RCV_TICKETKEY_ENCDEC_FILE = PROXY_CONF_DIR + 'session_ticketkey_encdec.key'
RCV_TICKETKEY_DEC_FILE = PROXY_CONF_DIR + 'session_ticketkey_dec.key'
DEFAULT_TICKETKEY_ENCDEC_FILE  = '/home/slb/control-proxy/conf/ticket_key_encdec.key'
DEFAULT_TICKETKEY_DEC_FILE  = '/home/slb/control-proxy/conf/ticket_key_dec.key'
SSL_SESS_SYNC_IP_FILE = PROXY_CONF_DIR + 'sslsync_ipport.list'

RECONF_PROXY_NET_PRE_SCRIPT = DEFAULT_TENGINE_PATH + 'lib/proxy/reconf_proxy_net_pre.sh'
RECONF_PROXY_SCRIPT = DEFAULT_TENGINE_PATH + 'lib/proxy/reconf_proxy.sh'
RECONF_PROXY_AFTER_SCRIPT = DEFAULT_TENGINE_PATH + 'lib/proxy/reconf_proxy_after.sh'

TENGINE_CTL = DEFAULT_TENGINE_PATH + 'lib/proxy/tengine_ctl.sh'

DEFAULT_SSL_ON  = "ssl      on;\n"
SSL_KEYLESS_ON = "\tssl_keyless on; \n"
SSL_KEYLESS_CERTIFICATE = "\tssl_keyless_certificate /home/slb/control-proxy/conf/client.crt;\n"
SSL_KEYLESS_CERTIFICATE_KEY = "\tssl_keyless_certificate_key /home/slb/control-proxy/conf/client.key;\n"
SSL_KEYLESS_VARIFY = "\tssl_keyless_verify off;\n"
SSL_KEYLESS_SERVER_CA = "\tssl_keyless_server_ca /home/slb/control-proxy/conf/ca.crt;\n"
SSL_KEYLESS_SESSION_REUSE = "\tssl_keyless_session_reuse on;\n"
SSL_LEYLESS_KEEPALIVE = "\tssl_keyless_keepalive 500;\n"
DEFAULT_SSL_SESSION_CACHE = "\tssl_session_cache shared:SSL:8192m;\n"
DEFAULT_SSL_PROTOCOLS = "\tssl_protocols      TLSv1 TLSv1.1 TLSv1.2;\n"
"""
DEFAULT_SSL_CIPHERS = "\tssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-RSA-RC4-SHA:" \
                      "AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:ECDHE-RSA-AES256-GCM-SHA384:" \
                      "ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:" \
                      "ECDHE-RSA-AES128-SHA256:RC4-SHA:!aNULL:!eNULL:!EXPORT:!DES:!3DES:!MD5:!DSS:!PKS;\n"
"""
# according to
# http://docs.alibaba-inc.com:8090/pages/viewpage.action?pageId=248134714
DEFAULT_SSL_CIPHERS = "\tssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:" \
                      "ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES128-GCM-SHA256:" \
                      "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:" \
                      "AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:ECDHE-ECDSA-AES128-SHA:" \
                      "ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES128-SHA:ECDHE-RSA-AES256-SHA:AES128-SHA:AES256-SHA:" \
                      "DES-CBC3-SHA:RSA+3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!DSS:!PSK:!SRP:!kECDH:!CAMELLIA:!IDEA:!SEED;\n"
SSL_PREFER_SERVER_CIPHERS = "\tssl_prefer_server_ciphers  on;\n"

DEFAULT_SSL_PATH = '/home/slb/control-proxy/tengine/conf/ssl'

DEFAULT_WEIGHT = 100
DEFAULT_CHECK_INTERVAL = 10 * 1000

DEFAULT_TUNNEL_ID = 0

PROXY_STOPPED = 0
PROXY_STARTING = 1
PROXY_RUNNING = 2

NEED_RELOAD = True
NEED_MODIFY = True

proxy_config = readConfig()

try:
    proxy_qps_capability = int(proxy_config['qps_cap'])
except:
    proxy_qps_capability = 35000

try:
    # TENGINE_WORKER_NR
    worker_nr = proxy_config['worker_nr']
except:
    worker_nr = 'auto'

try:
    # TENGINE_WORKERCONN_LIMIT
    worker_conns = proxy_config['worker_conns']
except:
    worker_conns = '100000'

try:
    max_peers = proxy_config['max_peers']
    if max_peers > 100000:
        max_peers = 100000
except:
    max_peers = '32768'

try:
    if 'enable_jumbo_frame' in proxy_config and proxy_config['enable_jumbo_frame'] == True:
        upstream_mtu = '8600'
        mtu = '8600'
    else:
        upstream_mtu = '1500'
        mtu = '1500'
except:
    upstream_mtu = '1500'
    mtu = '1500'

try:
    WILDCONF_SYNC = proxy_config['wildconf_sync']
except:
    WILDCONF_SYNC = 1

try:
    DEFAULT_QPS = proxy_config['default_qps']
    DEFAULT_QPS_SLA = DEFAULT_QPS*8
    if DEFAULT_QPS > 8111:
        DEFAULT_QPS = 8111
except:
    DEFAULT_QPS = 8111

try:
    MIN_QPS = proxy_config['min_qps']
    if MIN_QPS < 1000:
        MIN_QPS = 1000
except:
    MIN_QPS = 1000    
    
proxy_status = PROXY_STOPPED

proxy_service_info = None

lb_dict = {} # (loadbalancer_id, LoadbalancerMessage)
#lb_ver = 0
listen_dict = {} # (port, LayerSevenServiceMessage)
listennerid_vip = {} # (listener_id, port)
#listen_ver = 0
device_group = None
device_group_ver = 0
device_cfg = None
device_cfg_ver = 0
flow_switch = None
flow_switch_ver = 0

# [port number][server or upstream or cert or ndups]
proxy_conf_file = None

proxy_enabled = False

default_wild_config_dict = None

proxy_queue_item_id = 1
proxy_new_queue = []
proxy_new_prior_queue = []
proxy_process_queue = []
proxy_end_queue = []

# IP address for tengine binding (w/o mask)
bind_address_list = []
underlay_bind_address_list = []
ospf_network_list = []
dummy0_address_list = []

host = None

start_port = None
end_port = None
port_used_map = None

proxy_waf = {}
proxy_tmd = {}
proxy_http_config = {}
DEFAULT_WAF_MODULE_DSO_FILE = "/home/admin/aliwaf/conf/waf_dso.conf"

AGENT_ERR=500
AGENT_OK=200
AGENT_EXI=400
AGENT_NOT_FOUND=401 
AGENT_INV=402
AGENT_VA=403
AGENT_VB=404

lb_hash_tbl = [[] for i in range(32)]
lb_hash_tbl_buckets=32

#spawn a thead process session ticket key rotate 
rlock = threading.RLock()

#start porting from lvs
rotate_flag = False
last_rotate = None
rotate_thread = None

def is_ticketkey_rotate():
    return 'ticketkey_rotate' in config and config['ticketkey_rotate'] == 'enable'

def lock():
    if is_ticketkey_rotate():
        rlock.acquire()

def unlock():
    if is_ticketkey_rotate():
        rlock.release()

def parse_device_info(host):
    global proxy_http_config

    ipport_list = ''
    if len(proxy_http_config['device_info']) > 0:
        for proxy_addr in proxy_http_config['device_info']:
            if host == proxy_addr.device_addr:
                continue
            if proxy_addr.sync_session == 1:
                if ipport_list != '':
                    ipport_list += ','
                ipport_list += proxy_addr.device_addr
                ipport_list += ':65535'
    return ipport_list            

def push_proxylist(host):
    from proxy_template import sync_sessionid_temp
    global proxy_http_config
    global sync_sessionid_temp

    sync_sessionid_proxies = parse_device_info(host) 
    if len(sync_sessionid_proxies) == 0:
        sync_sessionid_proxies = 'nil'
    httpconf = sync_sessionid_temp.substitute(PROXY_LIST=sync_sessionid_proxies)
    ret = push_httpconf_to_shm("sync_sessionid", httpconf)
    if not ret:
        log_error('[Error][push_proxylist] push_httpconf_to_shm (sync_sessionid_proxies) error.')
    return ret

def push_ticketkey(rotate):
    from proxy_template import tengine_httpconf_temp
    global proxy_http_config
    global tengine_httpconf_temp
    ret = True

    if 'ssl_session_key' in proxy_http_config and proxy_http_config['ssl_session_key']:
        if rotate:
            encdec_key = proxy_http_config['ssl_session_key'].current_key
            dec_key = proxy_http_config['ssl_session_key'].previous_key
        else:
            encdec_key = proxy_http_config['ssl_session_key'].previous_key
            dec_key = proxy_http_config['ssl_session_key'].current_key
            
        httpconf = tengine_httpconf_temp.substitute(ENCDEC_KEY=encdec_key, DEC_KEY=dec_key)
        ret = push_httpconf_to_shm("httpconf", httpconf)
        if not ret:
            log_error('[Error][push_ticketkey] push_httpconf_to_shm (ticketkey) error.')
        ''' new dyaccept backend:dyups '''
        ret = push_httpconf_to_shm_dyups ("httpconf", httpconf)
        if not ret:
            log_error('[Error][push_ticketkey] push_httpconf_to_shm_dyups (ticketkey) error.')
    return ret

def push_device_count(device_count):
    cfg = {}
    cfg['servernew'] = 'server { device_count ' + str(device_count) + ';}'
    ret = update_dyX ("device_count", cfg) 
    if not ret:
        log_error('[Error][push_device_count] push_httpconf_to_shm_dyconf error.')
    return ret

        
def rotate_ticketkey():
    try:
        lock()
        if can_rotate():
            ret = push_ticketkey(True)              
            if ret:
                unset_rotate_flag()
        return
    except Exception,e:
        log_error('[Except][rotate_ticketkey] error: %s' % str(e), exc_info=True)
    finally:
        unlock()
        
class rotateThread(Thread):
    def __init__(self):
        Thread.__init__(self)
    def run(self):
        log_info('[ticket] start ticketkey rotate thread')
        
        while True:
            global last_rotate
            time.sleep(50)
            rotate_ticketkey()

def start_rotate_thread():
    global rotate_thread
    try:
        if not rotate_thread:
            rotate_thread = rotateThread()
            rotate_thread.setDaemon(True)
            rotate_thread.start()
    except Exception, e:        
        log_error("[Except][ticket] %s" % str(e), exc_info=True)

def set_rotate_flag():
    global rotate_flag
    global last_rotate
    try:
        lock()
        log_info("[ticket] set rotate")
        rotate_flag = True
        last_rotate = time.time()
    except Exception, e:        
        log_error("[Except][ticket] %s" % str(e), exc_info=True)
    finally:
        unlock()

def unset_rotate_flag():
    global rotate_flag

    try:
        lock()
        log_info("[ticket] unset rotate")
        rotate_flag = False
    except Exception, e:        
        log_error("[Except][ticket] %s" % str(e), exc_info=True)
    finally:
        unlock()

def can_rotate():
    global rotate_flag
    global last_rotate
    
    if 'ticketkey_rotate' in config:
        rotate_time = int(config['rotate_interval'])
    else:
        rotate_time = 1800

    try:
        lock()
        if rotate_flag:
            now = time.time()
            if is_ticketkey_rotate() and last_rotate is not None:
                delta = now - last_rotate
                if delta < rotate_time:
                    log_info("[ticket] test rotate is set but cannot rotate now")
                    return False
            log_info("[ticket] test rotate is set and rotate now")

        return rotate_flag
    except Exception, e:
        log_error("[Except][ticket] %s" % str(e), exc_info=True)
    finally:
        unlock()

def is_rotate_set():
    global rotate_flag
    try:
        lock()
        if rotate_flag:
            log_info("[ticket] test rotate is set")
        else:
            log_info("[ticket] test rotate is not set")
        return rotate_flag
    except Exception, e:
        log_error("[Except][ticket] %s" % str(e), exc_info=True)
    finally:
        unlock()
#end porting from lvs

start_rotate_thread()

def write_ticket_key_file():
    global proxy_http_config
    if proxy_http_config['ssl_session_key'].current_key is None:
        log_error("[Error][ticket] rcv session ticket key current_key is None, write failed!")
        proxy_http_config['ssl_session_key'] = None
        return False
    if proxy_http_config['ssl_session_key'].previous_key is None:
        log_error("[Error][ticket] rcv session ticket key previous_key is None, write failed!")
        proxy_http_config['ssl_session_key'] = None
        return False

    try:
        if not os.path.exists(PROXY_CONF_DIR):
            os.makedirs(PROXY_CONF_DIR, 0644)

        with open(RCV_TICKETKEY_ENCDEC_FILE, 'w') as keyfd:
            keyfd.write(proxy_http_config['ssl_session_key'].current_key)

        with open(RCV_TICKETKEY_DEC_FILE, 'w') as keyfd:
            keyfd.write(proxy_http_config['ssl_session_key'].previous_key)
            
        log_info("[ticket] <writeFile> session ticket key written")
        return True

    except Exception,e:
        log_error('[Except][ticket] write ticket_key to file error %s' % str(e))
        return False

def write_sync_sessionid_file():
    global proxy_config

    if not is_sslsync_enable():
        return True
        
    host = None
    # get lo.mgt ip addr
    if 'host' in proxy_config:
        host = proxy_config['host']

    sync_sessionid_proxies = parse_device_info(host) 

    try:
        if not os.path.exists(PROXY_CONF_DIR):
            os.makedirs(PROXY_CONF_DIR, 0644)

        with open(SSL_SESS_SYNC_IP_FILE, 'w') as fd:
            if len(sync_sessionid_proxies) == 0:
                # 0 file size 
                fd.close()
            else:
                fd.write(sync_sessionid_proxies)

        log_info("[sync_sessionid] <writeFile> sync_sessionid_proxies written")
        return True

    except Exception,e:
        log_error('[Except][sync_sessionid] write sync_sessionid_proxies to file error %s' % str(e))
        return False
def get_addr_list(addr_list):
    parsed_addr_list = []
    for ip in addr_list:
        if len(ip) == 0:
            continue
        if ip.find("-") == -1 and ip.find("/") == -1:
            # 1.1.1.1
            parsed_addr_list.append(ip)
        elif ip.find("/") != -1:
            # 1.1.1.0/28
            ip_list = list(IPNetwork(ip))
            for i in ip_list:
                # skip the broadcast address
                if i != IPNetwork(ip).broadcast:
                    parsed_addr_list.append(str(i))
        else:
            # 1.1.1.0-14
            # ('1.1.1.', '0', '14')
            g = re.match('(\d{1,3}\.\d{1,3}\.\d{1,3}\.)(\d{1,3})-(\d{1,3})', ip).groups()
            result = [g[0] + str(x) for x in range(int(g[1]), int(g[2]) + 1)]
            # calculate a network from range
            # Gyx: 24 at maximum for local address subnet mask
            for mask in range(31, 23, -1):
                nw1 = IPNetwork(g[0] + g[1] + "/" + str(mask)).network
                nw2 = IPNetwork(g[0] + g[2] + "/" + str(mask)).network
                if (nw1 == nw2):
                    break

            for i in result:
                parsed_addr_list.append(i)

    return parsed_addr_list

def add_ipv6_default_routes():
    log_info('add_ipv6_default_routes to dummy0')
    cmd = 'sudo route -A inet6 add ::/0 dev dummy0'
    ret = commands.getstatusoutput(cmd)
    cmd = 'ip -6 route show | grep default | wc -l'
    ret = commands.getstatusoutput(cmd)
    out = ret[1]
    if int(out.strip()) > 0:
        return 1
    else:
        return 0
'''
    cmd = "cat /etc/salt/grains | grep network_type | awk '{print $2}'"
    ret = commands.getstatusoutput(cmd)
    out = ret[1]
    if ret[0] != 0:
        log_error('add_ipv6_default_routes error')
        return 0
    if out.strip() != 'FortyGigabit' and out.strip() != 'FortyGigabit-w4h' and out.strip() != 'TenGigabit':
        log_error('add_ipv6_default_routes error: unknow device type')
        return 0
    network_type = out.strip()
    if network_type == 'FortyGigabit':
        cmd = 'sudo route -A inet6 add ::/0 dev eth4'
        ret = commands.getstatusoutput(cmd)
        cmd = 'sudo route -A inet6 add ::/0 dev eth5'
        ret = commands.getstatusoutput(cmd)
        cmd = 'sudo route -A inet6 add ::/0 dev eth6'
        ret = commands.getstatusoutput(cmd)
        cmd = 'sudo route -A inet6 add ::/0 dev eth7'
        ret = commands.getstatusoutput(cmd)
        cmd = 'ip -6 route show | grep default | wc -l'
        ret = commands.getstatusoutput(cmd)
        out = ret[1]
        if int(out.strip()) > 0: #in case of interface down
            return 1
        else:
            return 0
    elif network_type == 'FortyGigabit-w4h':
        cmd = 'sudo route -A inet6 add ::/0 dev eth4'
        ret = commands.getstatusoutput(cmd)
        cmd = 'sudo route -A inet6 add ::/0 dev eth5'
        ret = commands.getstatusoutput(cmd)
        cmd = 'ip -6 route show | grep default | wc -l'
        ret = commands.getstatusoutput(cmd)
        out = ret[1]
        if int(out.strip()) > 0:
            return 1
        else:
            return 0
    elif network_type == 'TenGigabit':
        cmd = 'sudo route -A inet6 add ::/0 dev T1'
        ret = commands.getstatusoutput(cmd)
        cmd = 'sudo route -A inet6 add ::/0 dev T2'
        ret = commands.getstatusoutput(cmd)
        cmd = 'ip -6 route show | grep default | wc -l'
        ret = commands.getstatusoutput(cmd)
        out = ret[1]
        if int(out.strip()) > 0:
            return 1
        else:
            return 0
    return 0
'''

def manipulate_laddr(device_cfg):
    global bind_address_list
    global underlay_bind_address_list
    dummy0_address_list = []
    dummy0_address_list_v6 = []
    new_bind_address_list = []
    new_bind_address_list_v6 = []
    new_network_list = []
    laddr = None
    laddr_o = None
    laddr_un = None
    laddr6_o = None
    laddr6_un = None
    # case 1: no original local addr,  overlay addr, underlay addr
    if device_cfg.local_address.network_addr == '0.0.0.0': 
        if (len(device_cfg.overlay_laddr) == 0):
            if (len(device_cfg.underlay_laddr) == 0):
               raise ValueError, 'no addrs to config.'
    else:
        laddr = device_cfg.local_address.network_addr + '/' +  str(device_cfg.local_address.mask)
    if (len(device_cfg.overlay_laddr) >= 1):
        # parse overlay ipv4 or overlay ipv6
        for item in device_cfg.overlay_laddr:
            addr = ipaddress.ip_network(item.network_addr + '/' +  str(item.mask))
            if addr.version == 4:
                #get ipv4 laddr
                laddr_o = item.network_addr + '/' +  str(item.mask)
            if addr.version == 6:
                #get ipv6 laddr
                laddr6_o = addr
    if (len(device_cfg.underlay_laddr) >= 1):
        for item in device_cfg.underlay_laddr:
            addr = ipaddress.ip_network(item.network_addr + '/' +  str(item.mask))
            if addr.version == 4:
                #get ipv4 laddr
                laddr_un = item.network_addr + '/' +  str(item.mask)
            if addr.version == 6:
                #get ipv6 laddr
                laddr6_un = addr
    # case 2: no original local addr, sanity check
    if device_cfg.local_address.network_addr == '0.0.0.0':
        if laddr_un is None and laddr6_un is None:
            raise ValueError, 'no underlay laddr to config.'
        if laddr_o is None and laddr6_o is None:
            raise ValueError, 'no overlay laddr to config.'
    # case 3.1 with local addr, no overlay and underlay 
    # case 3.2 with local addr, with overlay v4/v6  underlay v4/v6
    # case 3.3 without local addr, with overlay v4/v6  underlay v4/v6
    # case 3.3.1  without local addr, with overlay v4/v6  underlay v4/v6
    # for classic rs, we should use underlay addr as local address, which
    # which be handler later together with new nginx cmd 
    if laddr_o != None:
        if laddr != None:
            laddr = laddr + ',' + laddr_o
        else:
            laddr = laddr_o  
    else:
        laddr = device_cfg.local_address.network_addr + '/' +  str(device_cfg.local_address.mask)
   
    #ipv4 local address is a must for now 
    if laddr is None:
        bind_address_list = new_bind_address_list
        return
    #ipv6 parsing 
    helper = route_util()
    if laddr6_o != None:
        for ip6 in laddr6_o:
            #build ipv6 new_bind_address_list6
            new_bind_address_list_v6.append(str(ip6))
            #build ipv6 dummy0_address_list6
            dummy0_address_list_v6.append(str(ip6) + "/128")
        for lip6 in dummy0_address_list_v6:
            helper.add_network_dummy0_v6(lip6)

    #old way for ipv4 parsing, overlay only
    laddr_list = laddr.split(',')
    for ip in laddr_list:
        if len(ip) == 0:
            continue
        if ip.find("-") == -1 and ip.find("/") == -1:
            # 1.1.1.1
            dummy0_address_list.append(ip + "/32")
            new_bind_address_list.append(ip)
            #new_network_list.append(ip + "/32")
        elif ip.find("/") != -1:
            # 1.1.1.0/28
            #new_network_list.append(ip)
            ip_list = list(IPNetwork(ip))
            for i in ip_list:
                # skip the broadcast address
                if i != IPNetwork(ip).broadcast:
                    dummy0_address_list.append(str(i) + "/32")
                    new_bind_address_list.append(str(i))
        else:
            # 1.1.1.0-14
            # ('1.1.1.', '0', '14')
            g = re.match('(\d{1,3}\.\d{1,3}\.\d{1,3}\.)(\d{1,3})-(\d{1,3})', ip).groups()
            result = [g[0] + str(x) for x in range(int(g[1]), int(g[2]) + 1)]
            # calculate a network from range
            # Gyx: 24 at maximum for local address subnet mask
            for mask in range(31, 23, -1):
                nw1 = IPNetwork(g[0] + g[1] + "/" + str(mask)).network
                nw2 = IPNetwork(g[0] + g[2] + "/" + str(mask)).network
                if (nw1 == nw2):
                    #new_network_list.append(str(nw1) + "/" + str(mask))
                    break

            for i in result:
                dummy0_address_list.append(i + "/32")
                new_bind_address_list.append(i)

    if len(new_bind_address_list) < 1:
        raise ValueError, 'local address too few'

    #if len(new_network_list) < 1:
    #    raise ValueError, 'no network to announce.'

    if len(dummy0_address_list) < 1:
        raise ValueError, 'no dummy0 ip to config.'

    if device_cfg.local_address.network_addr == '0.0.0.0':
        new_network_list.append(laddr_un)
    elif laddr_un == None:
        new_network_list.append(device_cfg.local_address.network_addr + '/' +  str(device_cfg.local_address.mask))
    else:
        new_network_list.append(device_cfg.local_address.network_addr + '/' +  str(device_cfg.local_address.mask))
        new_network_list.append(laddr_un)

    underlay_bind_address_list = get_addr_list(new_network_list)
    if len(underlay_bind_address_list) == 0:
        log_error('[Error][laddr] failed to get underlay bind address')
        raise ValueError, 'failed to get underlay bind address'

    for underlay_addr in underlay_bind_address_list:
        if underlay_addr + '/32' in dummy0_address_list:
            continue
        dummy0_address_list.append(underlay_addr + '/32')

    helper = route_util()
    log_info("[laddr] announce ospf networks: %s" % str(new_network_list))
    for nw in new_network_list:
        # announce ospf network. NOTE we won't remove stale networks.
        # if we DO have stale networks to remove, involve PE team.
        ret, _, errmsg = helper.add_network(nw)
        if ret:
            # errmsg returned by vtysh
            log_error('[Error][laddr] failed to add network %s: %s' % (nw, errmsg))
            raise ValueError, 'failed to add network %s: %s' % (nw, errmsg)

    log_info("[laddr] add /32 local IP to dummy0 interface")
    for lip in dummy0_address_list:
        # add each /32 IPs to dummy0 interface
        # ignore return value since config dup ip will return non-zero
        log_info("[laddr] add IP to dummy0 interface: %s" % str(lip))
        helper.add_network_dummy0(lip)

    bind_address_list = new_bind_address_list + new_bind_address_list_v6

    # add default routes
    ret = add_ipv6_default_routes()
    if ret == 0:
        raise Exception, 'failed to configure ipv6 default routes.'

    if laddr_un != None: # use underlay, 1.1.1.0/28
        ip_list = list(IPNetwork(laddr_un))
        for i in ip_list:
            if i != IPNetwork(laddr_un).broadcast:
                break
        proxy_vxlan_saddr = i
    else:# in this case, overlay should be non, we get 1st ip in laddr
        proxy_vxlan_saddr = bind_address_list[0]
    log_info("[laddr] set net.ipv4.slbvsock.vxlan_saddr to %s" % proxy_vxlan_saddr)
    cmd = 'sudo sysctl -w net.ipv4.slbvsock.vxlan_saddr=%s' % proxy_vxlan_saddr
    ret, output = commands.getstatusoutput(cmd)
    if ret != 0:
        log_error("[Error][laddr] fatal: configure vsock fail:" + output)
        raise Exception, 'failed to configure vsock.'

def proxy_start():
    process = Popen(RECONF_PROXY_NET_PRE_SCRIPT, shell=True,
                    stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
    log_info("[proxy_start]" + process.stdout.read())
    if process.wait() != 0:
        raise Exception, 'reconf proxy net pre error'

    process = Popen(RECONF_PROXY_SCRIPT, shell=True,
              stdout=PIPE, stderr=PIPE, close_fds=True)
    (out, err) = process.communicate()
    log_info('[proxy_start] cmd: %s, ret: %s, out: %s, err: %s' % (RECONF_PROXY_SCRIPT, process.returncode, out, err))
    if process.returncode != 0:
        raise Exception, 'reconf proxy error'
    log_info("[proxy_start] reload proxy ok")

def proxy_start_after(state):
    process = Popen(RECONF_PROXY_AFTER_SCRIPT + ' ' + state, shell=True,
            stdout=PIPE, stderr=PIPE, close_fds=True)
    (out, err) = process.communicate()
    log_info('[proxy_start_after] cmd: %s, ret: %s, out: %s, err: %s' % (RECONF_PROXY_AFTER_SCRIPT + ' ' + state, process.returncode, out, err))
    if process.returncode != 0:
        raise Exception, 'switch proxy error'
    log_info("[proxy_start_after] switch proxy ok")

def get_vport(dispatcher, add_dispatcher):
    if add_dispatcher.HasField("vip_port"):
        return add_dispatcher.vip_port
    else:
        if is_eppu(dispatcher):
            port, ret = get_port_from_eppu(dispatcher)
            if port == None:
                log_error("get_vport [Eppu] can not get port")
            return port #ok for callers if port is None
        else:
            return dispatcher.port

def notfound_404(environ, start_response):
    start_response('404 Not Found', [ ('Content-type', 'text/plain') ])
    return ['Not Found']
    
class PathDispatcher:
    def __init__(self):
        self.pathmap = { }
        
    def __call__(self, environ, start_response):
        path = environ['PATH_INFO']
        #An input stream (file-like object) from which the HTTP request body can be read. 
        #params = cgi.FieldStorage(environ['wsgi.input'],
                    #environ=environ)
        #environ['params'] = { key: params.getvalue(key) for key in params }
        method = environ['REQUEST_METHOD'].lower()         
        handler = self.pathmap.get((method,path), notfound_404)
        return handler(environ, start_response)
            
    def register(self, method, path, function):
        self.pathmap[method.lower(), path] = function
        return function

def device_precheck(message):
    global device_cfg,device_cfg_ver
    is_incremental = message.is_incremental           
    log_info("[device][precheck] update device version check: current %d, target %d" % (device_cfg_ver, message.version)) 
    if message.version >= device_cfg_ver + 1:
        if is_incremental:
            if message.version == device_cfg_ver + 1:
                return AGENT_OK
            else:
                return AGENT_VA#VERSION_ADVANCE 
        else:
            return AGENT_OK
    else:
        return AGENT_VB  
        
def device_update(message):
    global device_cfg, device_cfg_ver  
    global NEED_RELOAD, NEED_MODIFY
    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[device][update] start")
    try:
        device_cfg = message
        device_cfg_ver = message.version
        NEED_MODIFY = True
    except Exception,e:        
        NEED_RELOAD = True
        log_error('[Except][device][update] error %s' % str(e))
        return AGENT_ERR 
    finally:
        log_info("[device][update] end")
        
def device_group_precheck(message):
    global device_group_ver
    is_incremental = message.is_incremental           
    log_info("[dgroup][precheck] current %d, target %d" % (device_group_ver, message.version)) 
    if message.version >= device_group_ver + 1:
        if is_incremental:
            if message.version == device_group_ver + 1:
                return AGENT_OK
            else:
                return AGENT_VA#VERSION_ADVANCE 
        else:
            return AGENT_OK
    else:
        return AGENT_VB   

def fswitch_precheck(message):
    global flow_switch,flow_switch_ver
    is_incremental = message.is_incremental           
    log_info("[fswitch][precheck] current %d, target %d" % (flow_switch_ver, message.version)) 
    if message.version >= flow_switch_ver + 1:
        if is_incremental:
            if message.version == flow_switch_ver + 1:
                return AGENT_OK
            else:
                return AGENT_VA#VERSION_ADVANCE 
        else:
            return AGENT_OK
    else:
        return AGENT_VB        

def update_dyX(vip,cblock):
    try:
        #dyconfc = httplib.HTTPConnection('127.0.0.1', DYCONF_PORT, timeout=3)
        url = 'http://127.0.0.1:8089/'+"config?vip=" + vip
        content = cblock['servernew']
        log_info('[update_dyX] curl -d "' + content.replace('\n', ' ') + '" ' + url)        
        rsp = requests.post(url=url, data=content)
        log_info("[update_dyX] return status" + str(rsp.status_code))
        result = dict()
        result['code'] = rsp.status_code
        if result['code'] != 200:
            log_error('[Error][update_dyX] status code: %s' % str(result['code']))
            return False 
    except Exception, e:
        log_error('[Except][update_dyX] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
    return True


def build_vip_file_path(listen):
    #name = str(listen.port)
    if is_eppu(listen):
        port, ret = get_port_from_eppu(listen)
        if port == None:
            log_error("build_vip_file_path [Eppu] can not get port")
            raise Exception, 'get_port_from_eppu [Eppu] error' 
        name = str(port)
    else:
        name = str(listen.port)    
    protocol = build_protocol(listen)
    if protocol == 'tcps':
        full_path = STREAM_VIP_CONF_DIR + name
    elif protocol == 'quic':
        full_path = QUIC_VIP_CONF_DIR + name
    else:
        full_path = VIP_CONF_DIR + name

    return full_path


def write_vip_conf_lite(listen):
    log_info("[write_vip_conf_lite]")
    global proxy_conf_file

    if is_eppu(listen):
        port, ret = get_port_from_eppu(listen)
        if port == None:
            log_error("write_vip_conf_lite [Eppu] can not get port")
            return ret
        name = str(port)
    else:
        name = str(listen.port)    

    full_path = build_vip_file_path(listen)
    
    proxy_conf_file[name] = gen_vip_section(listen)
    
    vipFile = open(full_path, 'w')
    vipFile.write(proxy_conf_file[name]["server"])
    vipFile.write(proxy_conf_file[name]["upstream"])
    vipFile.close()
    ret = update_dyX(name, proxy_conf_file[name])
   
    log_info("[write_vip_conf_lite] %s wrote" % name)        
    return ret

def device_group_update(message):
    global device_group, device_group_ver, proxy_http_config  
    global NEED_RELOAD, NEED_MODIFY
    global listen_dict
    global proxy_config
    version = 0
    dg = None

    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[dgroup][update] start")
    version = device_group_ver
    dg = device_group
    try:
        ret = verify_devicegroup(message)
        if ret == False:
            log_error("[Error][device_group_update] [verify_devicegroup] failed")
            return AGENT_ERR
        oldcount = device_group.device_count.plugged_count
        device_group = message
        device_group_ver = message.version
        '''
        if device_group.device_count.plugged_count != oldcount:
            log_info('[dgroup][update] plugged_count change old %d new %d' % (oldcount,device_group.device_count.plugged_count))
            #update all vip for qps
            for vip in listen_dict:
                #skip the one with no qps cfg
                if listen_dict[vip].config.sla_config.qps:
                    #refresh qps
                    ret = write_vip_conf_lite(listen_dict[vip])
                    if ret == False: 
                        device_group_ver = version
                        device_group = dg
                        log_error("[Error][dgroup][update] Error fatal: write dyconf failed for vip %d" % vip)
                        return AGENT_ERR 
        '''
        ret = push_device_count(device_group.device_count.plugged_count)
        if ret == False:
            log_error('[Error][dgroup][update] push_to_shm_new fail for device_count')
            return ret
 
        if device_group.HasField('ssl_session_key'):
            proxy_http_config['ssl_session_key'] = device_group.ssl_session_key
            write_ticket_key_file()
            ret = push_ticketkey(False)
            if ret:
                set_rotate_flag()

        proxy_http_config['device_info'] = device_group.device_info
        log_info('[dgroup][update]: get proxy ip device_info: %s' % str(device_group.device_info))
        write_sync_sessionid_file()

        if KEYSERVER_VIPS_SWITCH and device_group.HasField('keyserver_info'):
            proxy_http_config['keyserver_info'] = device_group.keyserver_info
            log_info('[dgroup][update]: get keyserver_info: %s' % str(device_group.keyserver_info))
            ret = process_keyserver_info()
            if ret:
                upstream_name = "keyserver_vips"
                protocol = "http"
                cblock = {}
                cblock["dups"] = proxy_http_config[upstream_name]
                ret = default_dyups_add(upstream_name, protocol, cblock)
                if ret != True:
                    log_error('[Error][PushShm] [default_dyups_add] [ADD] keyserver_vips upstream error')
            else:
                log_error("[Error][dgroup][update] Error fatal: process_keyserver_info")

        if is_sslsync_enable():
            host = None
            # get lo.mgt ip addr
            if 'host' in proxy_config:
                host = proxy_config['host']
                
            push_proxylist(host)

        NEED_MODIFY = True
        return AGENT_OK
    except Exception,e:        
        device_group_ver = version
        device_group = dg
        NEED_RELOAD = True
        log_error('[Except][dgroup][update] error %s' % str(e))
        return AGENT_ERR 
    finally:
        log_info("[dgroup][update] end")
        
def enable_service(message):
    global flow_switch,flow_switch_ver
    
    log_info("[enable_service] start")
    if proxy_status != PROXY_RUNNING:
        log_error("[Error][enable_service] before loading_proxy_service is not allowed.")
        return AGENT_ERR #"{'code':500,'msg':'enable before loading_proxy_service is not allowed'}"
    os.system(TENGINE_CTL + " enable_forwarding")
    log_info("[enable_service] end")
    proxy_enabled = True
    #gc should not handle device_cfg 
    flow_switch = message #ProxyDeviceConfigurationMessage 
    flow_switch_ver = message.version 
    return AGENT_OK#"{'code':200}"


def disable_service(message):
    global flow_switch,flow_switch_ver
    global proxy_enabled
    
    log_info("[disable_service] start")
    os.system(TENGINE_CTL + " disable_forwarding")
    log_info("[disable_service] end")
    proxy_enabled = False
    flow_switch = message #ProxyDeviceConfigurationMessage 
    flow_switch_ver = message.version
    return AGENT_OK#"{'code':200}"

def stub_precheck_func(message):
    return AGENT_OK
    
def stub_func(message):
    return AGENT_OK

def update_include_ups_conf():
    global listen_dict
    port_map = {}
    includeFile = None
    log_info("[dylisten] update upstreams conf")
    for vip in listen_dict:
        vipName = str(vip) 	    
        if vip in port_map:
            log_error("[Error][dylisten] Duplicate vip %d" % vip) 	    
        #only record one of dup item 
        port_map[vip] = vip           
    try:
        includeFile = open(UPSREAM_FILE_NEW, 'w')
        if includeFile is  None:
            log_error('[Error][dylisten] includeFile is None')
            return False
        for name in sorted(port_map.keys()):
            includeFile.write("include vip/%s;\n" % name)
        return True
    except Exception,e: 
        log_error('[Except][dylisten] error %s' % str(e))
        return False
    finally:
        if includeFile is not None:
            includeFile.close()
 
def get_rsp_str(code):
    if code == response_pb2.Response.OK:
        #response ok template
        rsp_ok = response_pb2.Response()
        rsp_ok.code = response_pb2.Response.OK
        s_str_ok = rsp_ok.SerializeToString()
        
        response_headers_ok = [
            ('Content-Type', 'text/html'),
            ('Content-Length', str(len(s_str_ok)))
        ]
        return (rsp_ok, s_str_ok, response_headers_ok)
    elif (code == response_pb2.Response.NOT_FOUND or
        code == response_pb2.Response.EXISTED or 
        code == response_pb2.Response.VERSION_BEHIND or 
        code == response_pb2.Response.VERSION_ADVANCE or
        code == response_pb2.Response.INVALID or 
        code == response_pb2.Response.ERROR) :
        #response fail template
        rsp_err = response_pb2.Response()
        rsp_err.code = code
        s_str_err = rsp_err.SerializeToString()
        
        response_headers_err = [
            ('Content-Type', 'text/html'),
            ('Content-Length', str(len(s_str_err)))
         ]
        return (rsp_err, s_str_err, response_headers_err)
    else:
        pass #interal API, suppose never enter here

#for performance consideration
rsp_ok, s_str_ok, response_headers_ok = get_rsp_str(response_pb2.Response.OK)
rsp_nf, s_str_nf, response_headers_nf = get_rsp_str(response_pb2.Response.NOT_FOUND)
rsp_exi, s_str_exi, response_headers_exi = get_rsp_str(response_pb2.Response.EXISTED)
rsp_vb, s_str_vb, response_headers_vb = get_rsp_str(response_pb2.Response.VERSION_BEHIND)
rsp_va, s_str_va, response_headers_va = get_rsp_str(response_pb2.Response.VERSION_ADVANCE)
rsp_inv, s_str_inv, response_headers_inv = get_rsp_str(response_pb2.Response.INVALID)
rsp_err, s_str_err, response_headers_err = get_rsp_str(response_pb2.Response.ERROR)

def check_ver_handler (receiveData, method, precheck_func, func, start_response):  
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_nf, s_str_nf, response_headers_nf
    global rsp_exi, s_str_exi, response_headers_exi
    global rsp_vb, s_str_vb, response_headers_vb 
    global rsp_va, s_str_va, response_headers_va
    global rsp_inv, s_str_inv, response_headers_inv 
    global rsp_err, s_str_err, response_headers_err 
    
    #version check logic only for update
    if method == 'update':
        result = precheck_func(receiveData)
    elif method == 'delete' or method == 'create':
        result = AGENT_OK
    else:
        result = AGENT_INV
        
    #evaluate the result     
    if result == AGENT_OK:
        en = func(receiveData)
        if en == AGENT_ERR:
            start_response('200 OK', response_headers_err)
            log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_err)))                           
            return s_str_err
            #raise StopIteration
        elif en == AGENT_EXI:
            start_response('200 OK', response_headers_exi)
            log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_exi)))                           
            return s_str_exi
        elif en == AGENT_NOT_FOUND:
            start_response('200 OK', response_headers_nf)
            log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_nf)))                           
            return s_str_nf
        elif en == AGENT_INV:
             start_response('200 OK', response_headers_inv)
             log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_inv)))                      
             return s_str_inv
        else:
            #log_info("message: %s" % str(receiveData))
            start_response('200 OK', response_headers_ok)
            log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_ok)))
            return s_str_ok
    elif result == AGENT_VA:
        start_response('200 OK', response_headers_va)
        log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_va)))                        
        return s_str_va
        #raise StopIteration
    elif result == AGENT_VB:
        #log_info("message: %s" % str(receiveData))
        start_response('200 OK', response_headers_vb)
        log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_vb)))
        return s_str_vb
    else:
       start_response('200 OK', response_headers_inv)
       log_info("[check_ver_handler][%s] response: %s" % (method,str(rsp_inv)))                      
       return s_str_inv
       #raise StopIteration
        
def query_lb_rsp(loadbalancer_id):
    global lb_dict
    
    if lb_dict != None and lb_dict.has_key(loadbalancer_id):
        rsp = response_pb2.QueryLoadbalancerResponse()
        rsp.response.code = response_pb2.Response.OK
        lb = rsp.data.add()        
        lb.CopyFrom(lb_dict[loadbalancer_id])
        
    else:    
        rsp = response_pb2.QueryLoadbalancerResponse()
        rsp.response.code = response_pb2.Response.NOT_FOUND
        lb = rsp.data.add()
        lb.address = "0.0.0.0"
        lb.loadbalancer_id = "no exist"
        lb.sla_config.qps = 0 
        lb.version = 0
    return rsp

def query_devicecfg_rsp():
    global device_cfg
    rsp = response_pb2.QueryProxyDeviceConfigurationResponse()
    if device_cfg == None:
        rsp.response.code = response_pb2.Response.NOT_FOUND       
        rsp.data.local_address.network_addr  = '0.0.0.0'
        rsp.data.local_address.mask  = 32
        rsp.data.version = 0
    else:
        rsp.response.code = response_pb2.Response.OK
        rsp.data.CopyFrom(device_cfg)
        rsp.data.version = device_cfg.version 
    return rsp

def query_fswitch_rsp():
    global flow_switch
    rsp = response_pb2.QueryFlowSwitchConfigurationResponse()
    if flow_switch == None:
        rsp.response.code = response_pb2.Response.NOT_FOUND   
        rsp.data.version =0
        rsp.data.flow_switch = common_pb2.OFF
    else:
        rsp.response.code = response_pb2.Response.OK
        rsp.data.CopyFrom(flow_switch)
        rsp.data.version = flow_switch.version 
    return rsp
    
def query_devicegrp_rsp():
    global device_group
    rsp = response_pb2.QueryProxyDeviceGroupConfigurationResponse() 
    if device_group == None:
        rsp.response.code = response_pb2.Response.OK
        #rsp.data.local_address.network_addr = '0.0.0.0'
        rsp.data.start_port = 0
        rsp.data.end_port =0
        rsp.data.device_count.plugged_count =0
        rsp.data.version =0
        rsp.data.site_name ="none"
    else:
        rsp.response.code = response_pb2.Response.OK
        rsp.data.CopyFrom(device_group)
        rsp.data.version = device_group.version     
    return rsp

def query_listen_rsp(lnid):
    global listen_dict,listennerid_vip
    rsp =  response_pb2.QueryLayerSevenServiceResponse()    
    if listen_dict != None:        
        if lnid in listennerid_vip:
            vip = listennerid_vip[lnid]  
            if listen_dict.has_key(vip):
                rsp.response.code = response_pb2.Response.OK
                li = rsp.data.add()
                li.CopyFrom(listen_dict[vip])           
                if is_eppu(li):
                   if not li.config.HasField("check"):
                       for rs in li.realserver:
                           rs.check_status = common_pb2.Realserver.UP
                       for rule in li.http_rule:
                           for rs in rule.realserver:
                               rs.check_status = common_pb2.Realserver.UP
                       return rsp
                   lnport,ret = get_port_from_eppu(li)
                   if lnport == None:
                       return rsp
                   #get listener' rs 
                   cmd = 'curl --connect-timeout 3 -s localhost/check_healthcheck_status?upstreams=%s' % str(lnport)
                   try:
                       process = Popen(cmd,
                                   shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
                   except Exception, e:
                       log_error("query runtime exception: %s" % str(e))
                   output = None
                   try:
                       (output, cmd_stderr) = process.communicate()
                   except Exception, e:
                       log_error("query runtime exception: %s" % str(e))
                       process.kill()#SIGKILL
                       (cmd_output, cmd_stderr) = process.communicate() #wait is called
                       output = None

                   for rs in li.realserver:
                       rs.check_status = common_pb2.Realserver.DOWN
                   if output != None:
                       output = output.strip()
                       output = output.split('\n')
                       for i in range(0, len(output)):
                           line = output[i].split(',')
                           #['100', '666', '100.82.209.26:8000', 'up', '0', '1', 'http', '0', '0']
                           if len(line) < 3: #protection code
                               continue
                           for rs in li.realserver:
                              if line[2] == rs.address + ":" + str(rs.port):
                                  if line[3] == 'up':
                                      rs.check_status = common_pb2.Realserver.UP
                                  else:
                                      rs.check_status = common_pb2.Realserver.DOWN
                   #get rule's rs status
                   for rule in li.http_rule:
                       ups = str(lnport)  + "_" + rule.name
                       cmd = 'curl -s localhost/check_healthcheck_status?upstreams=%s' % ups
                       try:
                           process = Popen(cmd,
                                       shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
                       except Exception, e:
                           log_error("query runtime exception: %s" % str(e))
                       output = None
                       try:
                           (output, cmd_stderr) = process.communicate()
                       except Exception, e:
                           log_error("query runtime exception: %s" % str(e))
                           process.kill()#SIGKILL
                           (cmd_output, cmd_stderr) = process.communicate() #wait is called
                           output = None

                       for rs in rule.realserver:
                           rs.check_status = common_pb2.Realserver.DOWN   
                       if output != None:                                  
                           output = output.strip()
                           output = output.split('\n')
                           for i in range(0, len(output)):
                               line = output[i].split(',')
                               if len(line) < 3: #protection code
                                   continue
                               #['100', '666', '100.82.209.26:8000', 'up', '0', '1', 'http', '0', '0']
                               for rs in rule.realserver:
                                  if line[2] == rs.address + ":" + str(rs.port):
                                      if line[3] == 'up':
                                          rs.check_status = common_pb2.Realserver.UP
                                      else:
                                          rs.check_status = common_pb2.Realserver.DOWN 
                return rsp
    #default
    rsp = response_pb2.QueryLayerSevenServiceResponse()
    rsp.response.code = response_pb2.Response.NOT_FOUND
    li = rsp.data.add()
    li.address = "0.0.0.0"
    li.port = 0
    li.protocol = 'http'
    li.loadbalancer_id  = 'fake'
    li.listener_id  = 'unknow'
    li.config.wild_config['name'] = 'none'
    li.config.sticky_session.sticky_session_type  = proxy_pb2.LayerSevenServiceConfig.StickySession.INSERT 
    li.config.sticky_session.timeout = 3#one of 
    #li.sla_config.cps =1#op 
    li.version = 0
    li.tunnel_id = 0
    return rsp
     
def get_value(result, key):
    kvs = result.split('\n')
    for kv in kvs:
        if not kv:
            continue
        kvarr = kv.split('=')
        if kvarr[0] == key:
            return kvarr[1]
    return ""

def wildconf_syncswitch_rsp(switch):
    global WILDCONF_SYNC
    rsp = response_pb2.Response()
    if switch == 'on':
        WILDCONF_SYNC = 1 
    else:
        WILDCONF_SYNC = 0
    log_info("[wildconf_syncswitch_rsp] set WILDCONF_SYNC to %s" %  str(WILDCONF_SYNC))
    #write to file
    with open(WILDCONF_SYNC_FILE, 'w') as fd:
        fd.truncate()
        fd.write("wildconf_sync: %d" % WILDCONF_SYNC)
    rsp.code = response_pb2.Response.OK
    return rsp
     
def query_runtime_rsp():
    global device_cfg_ver
    
    log_info("[query_runtime_rsp] start")
    rsp = response_pb2.QueryProxyRuntimeResponse()
    
    process = Popen(TENGINE_CTL + " status",
            shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
    output = process.stdout.read().rstrip('\n')

    log_info("[query_runtime_rsp] result: %s" % output.replace('\n', ' '))

    try:
        qps = int(get_value(output, "qps"))
    except:
        log_error("[Except][query_runtime_rsp]failed to read qps")
        qps = 0#""
    try:
        rscnt = int(get_value(output, "rscnt"))
    except:
        log_error("[Except][query_runtime_rsp]failed to read rscnt")
        rscnt = 0#""
    try:
        rsupcnt = int(get_value(output, "rsupcnt"))
    except:
        log_error("[Except][query_runtime_rsp]failed to read rsupcnt")
        rsupcnt = 0#""
    try:
        forwarding = get_value(output, "forwarding")
    except:
        log_error("[Except][query_runtime_rsp]failed to read forwarding")
        forwarding = ""

    qpscap = proxy_qps_capability
    
    rsp.response.code = response_pb2.Response.OK
    rsp.qps = qps
    rsp.rs_count = rscnt
    rsp.rs_up_count = rsupcnt
    rsp.status = forwarding
    rsp.qps_cap = qpscap
    rsp.version = device_cfg_ver#meaningless
    return rsp

def init_proxy_config():
    global lb_dict 
    global device_group,device_group_ver 
    global device_cfg, device_cfg_ver
    global listen_dict, listennerid_vip
    global flow_switch,flow_switch_ver
    global lb_hash_tbl
    lb_dict = {}
    listen_dict = {}
    listennerid_vip = {} # listenerid 2 vip map
    lb_hash_tbl = [[] for i in range(32)]#reinit the map
    device_group = None
    device_group_ver = 0
    device_cfg = None
    device_cfg_ver = 0
    flow_switch = None
    flow_switch_ver = 0 

def loading_proxy_service(message):
    global proxy_service_info #devided into three dicts for lb,dgroup,listenner
    global proxy_status
    global NEED_RELOAD
    global start_port, end_port, port_used_map
    global proxy_http_config

    global proxy_enabled
    global lb_dict 
    global device_group,device_group_ver 
    global device_cfg, device_cfg_ver
    global listen_dict, listennerid_vip
    global flow_switch,flow_switch_ver
    global lb_hash_tbl

    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[reload] loading_proxy_service start")
    # log_info("message : %s" %  message)
    # check if proxy is back from crash, while tengine is still running.
    process = Popen(TENGINE_CTL + " status",
            shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
    output = process.stdout.read().rstrip('\n')
    result = get_value(output, "forwarding")
    result = 'on'
    if result == "on":
        log_info("[reload] forwarding is already enabled, change proxy_enabled to true")
        proxy_enabled = True
    try:
        #clr config
        init_proxy_config()
        #lb parsing 
        lb_len = len(message.loadbalancer)
        device_group = message.device_group
        device_group_ver = message.device_group.version
        idx = 0
        while idx < lb_len:
            lbid = message.loadbalancer[idx].loadbalancer_id
            ret = verify_lb(message.loadbalancer[idx])
            if ret == False:
                log_error("[Error][reload] [verify_lb] failed %s" % lbid)
                return AGENT_ERR
            #create
            if not lb_dict.has_key(lbid):
                lb_dict[lbid] = message.loadbalancer[idx]
            else:    
            #update  
                pass
            idx += 1

        #listen parsing
        idx = 0
        service_len = len(message.service)       
        while idx < service_len:
            msg = message.service[idx] 
            #update 
            if msg.listener_id in listennerid_vip:
                pass
            else: #create   
                if (msg.HasField('port')):
                   if is_eppu(msg):
                       vip, ret = get_port_from_eppu(msg)
                       if vip == None:
                           log_error("loading_proxy_service [Eppu] can not get port")
                           idx += 1
                           continue#skip this listen
                   else:
                       vip = msg.port
                   ret = verify_listen(msg, vip, create=True)
                   if ret == False:
                       log_error("[Error][reload] [verify_listen] failed %d" % vip)
                       return AGENT_ERR
                   listen_dict[vip] = msg    
                   listennerid_vip[msg.listener_id] = vip
                   lb = lb_dict[msg.loadbalancer_id]
                   listen_dict[vip].config.sla_config.CopyFrom(lb.sla_config) 
                   set_hash_tbl_item(msg.loadbalancer_id, vip)#add case, put it in hash

                else:
                    log_info("[reload] loading_proxy service create but no port %s" % msg.listener_id)
            idx += 1
        
        #device group pasring, not gc
        ret = verify_devicegroup(message.device_group)
        if ret == False:
            log_error("[Error][reload] [verify_devicegroup] failed")
            return AGENT_ERR
        #device cfg parsing
        device_cfg = message.device
        device_cfg_ver = message.device.version 
        # load templates
        from proxy_template import reload
        if is_hotconf_enable():
            reload(True)
        else:
            reload(False)
        #tmd and waf bypass

        if device_group.HasField('proxy_http_version'):
            proxy_http_config['proxy_http_version'] = device_group.proxy_http_version
        if device_group.HasField('gzip_status'):
            proxy_http_config['gzip_status'] = device_group.gzip_status
        if device_group.HasField('ssl_session_key'):
            proxy_http_config['ssl_session_key'] = device_group.ssl_session_key
            write_ticket_key_file()

        proxy_http_config['device_info'] = device_group.device_info
        write_sync_sessionid_file()

        if KEYSERVER_VIPS_SWITCH and device_group.HasField('keyserver_info'):
            proxy_http_config['keyserver_info'] = device_group.keyserver_info

        #todo    
        manipulate_laddr(device_cfg)
        start_port = device_group.start_port 
        end_port = device_group.end_port
        port_used_map = dict((i, False) for i in range(start_port, end_port + 1))

        #portting from check_proxy_num
        if device_group.device_count.plugged_count < 1:
            log_error("[Error][reload] Error fatal: the value of proxy_num is < 1! set limit_req to default qps", exc_info=True)

        #update flowswitch
        flow_switch = None
        flow_switch_ver = 0

        proxy_status = PROXY_STARTING    
        return AGENT_OK
    except Exception,e:       
        log_error('[Except][reload] error %s' % str(e))
        return AGENT_ERR
    finally:
        NEED_RELOAD = True
        log_info("[reload] loading_proxy_service end")       


def write_http_conf_with_splice(port):
    listen = gen_fake_upstream(port)
    full_path = build_vip_file_path(listen)
    fake_file = gen_vip_section(listen)

    fake_file["server"] = fake_file["server"].replace("server {", "server {\n\t\t#splice on;\n", 1)

    vip_file = open(full_path, 'w')
    vip_file.write(fake_file["server"])
    vip_file.write(fake_file["upstream"])
    vip_file.close()


def write_http_conf_with_quic(port):
    listen = gen_fake_upstream(port)
    full_path = build_vip_file_path(listen)
    fake_file = gen_vip_section(listen)

    fake_file["server"] = fake_file["server"].replace("server {", "server {\n\t\t#quic on;\n", 1)

    vip_file = open(full_path, 'w')
    vip_file.write(fake_file["server"])
    vip_file.write(fake_file["upstream"])
    vip_file.close()


def write_vip_conf(listen, is_del, ndupslist, newadded, old_listen=None):
    log_info("[write_vip_conf] write one vip conf")
    global proxy_conf_file
    lport = None 

    if UT:
        return
    if is_eppu(listen):
        port, ret= get_port_from_eppu(listen)
        if port == None:
            log_error("write_vip_conf [Eppu] can not get port")
            raise Exception, 'get_port_from_eppu error'        
        name = str(port)
        lport = port
    else:
        name = str(listen.port)
        lport = listen.port
    protocol = build_protocol(listen)
    full_path = build_vip_file_path(listen)

    # hotconf, old_listen will be there for update and delete case.
    if is_hotconf_enable() and old_listen is not None:
        old_protocol = build_protocol(old_listen)
        if is_del or protocol != old_protocol:
            old_full_path = build_vip_file_path(old_listen)
            ret = push_to_shm_new(name, old_protocol, None, None, None)
            if ret is False:
                log_error("[Error][write_vip_conf] push_to_shm_new error")
                raise Exception, 'push_to_shm_new error'

            if old_protocol == 'tcps' or old_protocol == 'quic':
                if os.path.isfile(old_full_path):
                    try:
                        os.remove(old_full_path)
                    except:
                        log_error("[Error][write_vip_conf] delete file %s failed" % full_path)

                if old_protocol == 'tcps' and protocol == 'quic':
                    write_http_conf_with_quic(lport)
                elif old_protocol == 'quic' and protocol == 'tcps':
                    write_http_conf_with_splice(lport)
            else:
                if protocol == 'tcps':
                    write_http_conf_with_splice(lport)
                elif protocol == 'quic':
                    write_http_conf_with_quic(lport)

    proxy_conf_file[name] = gen_vip_section(listen)

    vipFile = open(full_path, 'w')
    vipFile.write(proxy_conf_file[name]["server"])
    vipFile.write(proxy_conf_file[name]["upstream"])
    vipFile.close()

    #hotconf
    if is_hotconf_enable():  
        # push new add or conf after del
        ret = push_to_shm_new(name, protocol, proxy_conf_file[name], ndupslist, newadded)
        if ret == False:
            log_error("[Error][write_vip_conf] push_to_shm_new error")
            raise Exception, 'push_to_shm_new error'       
             
    log_info("[write_vip_conf] %s wrote" % name)

def set_hash_tbl_item(lbid, vip):
    global lb_hash_tbl
    
    bucket = abs(hash(lbid)) % lb_hash_tbl_buckets
    lb_hash_tbl[bucket].append(vip)
        
                
def rm_hash_tbl_item(lbid, vip):
    global lb_hash_tbl

    bucket = abs(hash(lbid)) % lb_hash_tbl_buckets
    try:
        lb_hash_tbl[bucket].remove(vip)
    except ValueError:
        log_error("[Except][rm_hash_tbl_item]fail to get vip from hash tbl: lb %s, vip %d" % (lbid,vip))

def populate_lb_to_all_vips(lb, type):
    global listen_dict
    global NEED_RELOAD, NEED_MODIFY
    global lb_hash_tbl
    
    if not lb.HasField("sla_config"):
        return #qps only
    if not lb.sla_config.HasField('qps'):
        return
    #todo, if have perform issue
    qps = lb.sla_config.qps
    lbid = lb.loadbalancer_id
    action = False
    
    bucket = abs(hash(lbid)) % lb_hash_tbl_buckets
    for item in lb_hash_tbl[bucket]:
        if not listen_dict.has_key(item):
            log_error("listener not exist: %s" % str(item))
            continue
        if listen_dict[item].loadbalancer_id  == lbid:
            listen_dict[item].config.sla_config.CopyFrom(lb.sla_config) 
            #lightweight API to update qps
            write_vip_conf_lite(listen_dict[item])
            action = True
    if action == True:
        NEED_MODIFY = True

def update_lb_precheck(message):
    global lb_dict 
    lbid = message.loadbalancer_id
    if lbid not in lb_dict:
        return AGENT_OK
    is_incremental = message.is_incremental           
    log_info("[update_lb_precheck][precheck][LB]: current %d, target %d" % (lb_dict[lbid].version,message.version)) 
    if message.version >= lb_dict[lbid].version + 1:
        if is_incremental:
            if message.version == lb_dict[lbid].version + 1:
                return AGENT_OK
            else:
                return AGENT_VA#VERSION_ADVANCE 
        else:
            return AGENT_OK
    else:
        return AGENT_VB
        
def update_lb(message):
    global lb_dict     
    global NEED_RELOAD, NEED_MODIFY
    version = 0
    old_lb = None
    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[update_lb][LB] start")
    try: 
        lbid = message.loadbalancer_id            
        if lbid not in lb_dict:
            return AGENT_NOT_FOUND
        #do update(instead of config) 
        ret = verify_lb(message)
        if ret == False:
            log_error("[Error][update_lb] [verify_lb] failed %s" % lbid)
            return AGENT_ERR
        old_lb = copy.deepcopy(lb_dict[lbid])
        incr = message.is_incremental
        if not incr:
            lb_dict[lbid] = message            
        else:
            lb_dict[lbid].version = message.version
            if message.HasField('sla_config') and message.sla_config.qps > 0:
                lb_dict[lbid].sla_config.qps = message.sla_config.qps    
        if message.HasField('sla_config') and message.sla_config.qps > 0:
            log_info("[update_lb][LB] use qps: %d  in lb" % message.sla_config.qps)
            populate_lb_to_all_vips(message,'update')
        else:
            log_info("[update_lb][LB] use qps in agent mem")
        return AGENT_OK       
    except Exception,e:
        #restore lb cfg
        if old_lb != None:
             log_error('[update_lb][LB] rollback lb') 
             lb_dict[lbid] = old_lb
        NEED_RELOAD = True
        log_error('[Except][update_lb][LB] error %s' % str(e))
        return AGENT_ERR
    finally:
        log_info("[update_lb][LB] end")

def check_cert_type(in_cert):
    ret = -1 
    if in_cert == None:
        return ret
    try:
        cert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, in_cert)
        ret = cert.get_pubkey().type() #rsa 6, ecc 408
    except Exception,e:
        log_error("check_cert_type fail to load cert")
    return ret
       
def cert_cmp_type(ssni,dsni):
    if ssni.state == proxy_pb2.SniMessage.DELETED:
        if ssni.cert_key_id == dsni.cert_key_id:
            return 1 #equal
        else:
            return 0 #unequal
    stype = check_cert_type(ssni.cert)
    dtype = check_cert_type(dsni.cert)
    if stype <=0 or dtype <=0:
        return 0 #unequal
    if stype == dtype:
        return 1 #equal
    return 0

def check_sni(sni, sni_list):
    i = 0
    llen = len(sni_list)
    while i < llen:
        if sni.domain == sni_list[i].domain:
            #let's check cert type
            if (cert_cmp_type(sni, sni_list[i]) == 1):
                break
        i += 1
    return i, llen


def check_realservers(rs, rspool):
    i = 0   
    rsplen = len(rspool)
    while i < rsplen:
        if rs.address == rspool[i].address \
            and rs.tunnel_id == rspool[i].tunnel_id:
            if rs.port == rspool[i].port:
                break
        i += 1    
    return i,rsplen

def check_rs(realserver):
    if realserver.port <= 0:
        log_error('[Error][check_rs]rs check error for port: %d' % realserver.port)
        return False
    if realserver.HasField('tunnel_id') and realserver.tunnel_id != DEFAULT_TUNNEL_ID:    
        #basic check for vgw_ip:0.0.0.0
        #skip del rs case which won't have vgw_ip from yaochi
        if len(realserver.vgw_ip) < 7 and (realserver.state != common_pb2.Realserver.DELETED): 
            log_error('[Error][check_rs]rs check error for vgwip: %d' % len(realserver.vgw_ip))
            return False
    return True


def update_sni_list(src, dst):
    if len(src) > 0:
        for sni in src:
            type = sni.state
            i, llen = check_sni(sni, dst)
            if i == llen:
                if type == proxy_pb2.SniMessage.DELETED:
                    continue
                else:
                    new_sni = dst.add()
                    new_sni.CopyFrom(sni)
            else:
                if type == proxy_pb2.SniMessage.DELETED:
                    del dst[i]
                else:
                    dst[i].CopyFrom(sni)
    return True


def update_conditions(src, dst):
    # always overwrite dst by src
    if len(src) == 0:  # add protection code
        return
    del dst[:]
    for pi in src:
        newpi = dst.add()
        newpi.CopyFrom(pi)


def update_realservers(srcpool, dstpool) :
    if len(srcpool) > 0:
        #for rs in srcpool:#basic check
        #    ret = check_rs(rs)
        #    if ret == False:
        #        return ret
        for rs in srcpool:
            type = rs.state
            i,plen = check_realservers(rs, dstpool)            
            if i == plen: #i can be zero
                if type == common_pb2.Realserver.DELETED:
                    continue #skip
                else:#add
                    new_rs = dstpool.add()
                    new_rs.CopyFrom(rs)
            else:
                if type == common_pb2.Realserver.DELETED:
                    del dstpool[i]
                else:#config
                    dstpool[i].CopyFrom(rs)
    return True
              
def update_wildconfiginfolist(srclist, dstlist):
    #update wildconfiginfolist when update listen and rules
    if len(srclist) > 0:
        for wildconfig in srclist:
            status = wildconfig.state
            if not check_wildconf_type(wildconfig):
                if wildconf_types.has_key(wildconfig.key):
                    log_error("[Error][wildconf] wildconf key %s expect type %s real type %s" %
                          (wildconfig.key, wildconf_types[wildconfig.key], wildconfig.type))
                    return False  # error configuration.
                else:
                    log_info("[Warning][wildconf] wildconf key %s isn't registered" % wildconfig.key)

            i, llen = check_wildconf_exist(wildconfig, dstlist)
            if i == llen:
                #no exists in old config
                if status == proxy_pb2.WildConfigInfo.DELETED:
                    continue
                else:
                    new_wildconf = dstlist.add()
                    new_wildconf.CopyFrom(wildconfig)
            else:
                #exists in old config
                if status == proxy_pb2.WildConfigInfo.DELETED:
                    del dstlist[i]
                else:
                    dstlist[i].CopyFrom(wildconfig)
    return True

def check_wildconfiginfolist(srclist):
    #check the wildconfiginfolist when create listen.
    if len(srclist) > 0:
        for wildconfig in srclist:
            status = wildconfig.state
            if not check_wildconf_type(wildconfig):
                if wildconf_types.has_key(wildconfig.key):
                    log_error("[Error][wildconf] wildconf key %s expect type %s real type %s" %
                          (wildconfig.key, wildconf_types[wildconfig.key], wildconfig.type))
                    return False  # error configuration.
                else:
                    log_info("[Warning][wildconf] wildconf key %s isn't registered" % wildconfig.key)

            if status == proxy_pb2.WildConfigInfo.DELETED:
                log_error("[Error][wildconf] try to delete wildconf %s while create listen" % wildconfig.key)
                return False
    return True

def get_wildconfig(key, wildconfiginfolist):
    #interface to get a specific wildconf item
        for wildconfig in wildconfiginfolist:
            if wildconfig.key == key:
                return wildconfig
        return None

def check_wildconf_exist(wildconf, dstlist):
    i = 0
    llen = len(dstlist)
    while i < llen:
        if wildconf.key == dstlist[i].key:
            break
        i += 1
    return i, llen
def check_wildconf_type(wildconf):
    if wildconf_types.has_key(wildconf.key) and wildconf.type == wildconf_types[wildconf.key]:
        return True
    return False

def check_rules(rule, drule):
    i = 0
    drlen = len(drule)
    while i< drlen:
        if rule.name == drule[i].name:
            break
        i += 1
    return i,drlen
    
def update_rules(srule, drule, port, is_app_rule):
    global listen_dict
    upslist = []
    newadded = []
    ret = True
    try:
        if len(srule) > 0:
            #for rule in srule:#sanity check
            #    for rs in rule.realserver:
            #        ret = check_rs(rs)
            #        if ret == False:
            #            return ret,upslist
            for rule in srule:
                type = rule.state
                i,drlen = check_rules(rule, drule)
                if i == drlen: # a new rule
                    if type == proxy_pb2.HttpRule.DELETED:
                        continue
                    else:
                        if is_app_rule and not rule.HasField("priority"):
                            log_error("[Error][update_rules] no priority set for new app rule %s of port %d" % (rule.name, port))
                            return False, upslist, newadded
                        newrule = drule.add()
                        newrule.CopyFrom(rule)
                        newadded.append(str(port) + '_' + rule.name)
                else: # an existed rule
                    if type == proxy_pb2.HttpRule.DELETED:
                        upslist.append(str(port) + '_' + drule[i].name)                        
                        del drule[i]                        
                    else:#copy rule                    
                        update_realservers(rule.realserver, drule[i].realserver)
                        if len(rule.httpWildConfigInfoList) > 0:
                            update_wildconfiginfolist(rule.httpWildConfigInfoList, drule[i].httpWildConfigInfoList)
                        if rule.HasField("priority"):
                            drule[i].priority = rule.priority
                        update_conditions(rule.conditions, drule[i].conditions)
                        if rule.HasField("domain"):
                            drule[i].domain = rule.domain
                        if rule.HasField("url"):
                            drule[i].url = rule.url
                        if rule.HasField("cert_key"):
                            drule[i].cert_key.CopyFrom(rule.cert_key)
                        if rule.HasField("config"):#if no config, use value in agent local mem
                            drule[i].config.CopyFrom(rule.config)
                        if rule.HasField("is_url_regex"):
                            drule[i].is_url_regex = rule.is_url_regex
                        if rule.HasField("upstream_keepalive"):
                            if rule.upstream_keepalive.enable == common_pb2.OFF:
                                if drule[i].HasField("upstream_keepalive"):
                                    drule[i].ClearField("upstream_keepalive")
                            elif rule.upstream_keepalive.enable == common_pb2.ON:
                                drule[i].upstream_keepalive.CopyFrom(rule.upstream_keepalive)
                        if rule.HasField('ssl_dyn_rec'):
                            if rule.ssl_dyn_rec.state == proxy_pb2.SslDynRec.DELETED:
                                if drule[i].HasField("ssl_dyn_rec"):
                                    drule[i].ClearField("ssl_dyn_rec")
                            elif rule.ssl_dyn_rec.state == proxy_pb2.SslDynRec.CREATED:
                                drule[i].ssl_dyn_rec.CopyFrom(rule.ssl_dyn_rec)
                        if rule.HasField('ignore_client_abort'):
                            drule[i].ignore_client_abort = rule.ignore_client_abort
                        if rule.HasField("x_forwarded_client_port"):
                            drule[i].x_forwarded_client_port = rule.x_forwarded_client_port
                        if rule.HasField("x_forwarded_port"):
                            drule[i].x_forwarded_port = rule.x_forwarded_port
                        newadded.append(str(port) + '_' + drule[i].name)
    except Exception,e:
        log_error("[Except][update_rules] %s" % str(e))
        ret = False
        return ret, upslist, newadded    
    return ret, upslist, newadded    

def update_listen_ssl_dyn_rec_precheck(message):
    if message.HasField("ssl_dyn_rec") and message.ssl_dyn_rec.state == proxy_pb2.SslDynRec.DELETED and message.is_incremental == 0:
        return False
    return True


def update_listen_app_rule_precheck(old_listen, new_listen):
    if old_listen.HasField("is_app_rule") and old_listen.is_app_rule == 1:
        # controller will always pass is_app_rule field to us in updating case.
        if not new_listen.HasField("is_app_rule"):
            return -1
        if new_listen.is_app_rule != 1:
            return -1
    elif new_listen.HasField("is_app_rule") and new_listen.is_app_rule == 1:
        return 1

    return 0


def update_listen_precheck(message):
    global listen_dict,listennerid_vip 

    if message.listener_id not in listennerid_vip:
        return AGENT_OK# this is for create case
    vip = listennerid_vip[message.listener_id]    
    if vip not in listen_dict:
        log_info("[update_listen_precheck][precheck][LI] %s wo valid port" % message.listener_id)  
        return AGENT_OK# this should not happen

    # check ssl_dyn_rec
    if update_listen_ssl_dyn_rec_precheck(message) == False:
        return AGENT_INV

    app_rule_res = update_listen_app_rule_precheck(listen_dict[vip], message)
    if app_rule_res == 1:
        log_error("[Error][update_listen_precheck] trying to update from basic rule to app rule")
        return AGENT_INV
    elif app_rule_res == -1:
        log_error("[Error][update_listen_precheck] trying to update from app rule to basic rule")
        return AGENT_INV

    is_incremental = message.is_incremental           
    log_info("[update_listen_precheck][precheck][LI]: current %d, target %d" % (listen_dict[vip].version,message.version)) 
    if message.version >= listen_dict[vip].version + 1:
        if is_incremental:
            if message.version == listen_dict[vip].version + 1:
                return AGENT_OK
            else:
                return AGENT_VA#VERSION_ADVANCE 
        else:
            return AGENT_OK
    else:
        return AGENT_VB 

                   
def update_listen(message):
    """Update listener, incremental or not.

    Full Update is similar with create, will do flush fully. SLA config will be copied from LB SLA config.
    It seems only following fields can be updated in incremental message:
    1. SLA, aka. qps (optional)
    2. cert_key
    3. forward_port (slb_redirect_https)
    4. listen (full update)
    5. rule (full update)
    :param message:
    :return:
    """
    global listen_dict, listennerid_vip    
    global NEED_RELOAD, NEED_MODIFY
    version = 0
    ndupslist = None
    newadded = None
    flag = False 
    ret = True
    old_listen = None

    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[update_listen][LI] start")
    if message.HasField("is_app_rule") and message.is_app_rule == 1:
        is_app_rule = True
    else:
        is_app_rule = False

    try: 
        lnid = message.listener_id
        if lnid not in listennerid_vip:
            return AGENT_NOT_FOUND
            
        vip = listennerid_vip[lnid] #must update a valid vip
        incr = message.is_incremental
        ret = verify_listen(message, vip, incr)
        if ret == False:
            log_error("[Error][update_listen] [verify_listen] failed %d" % vip)
            return AGENT_ERR

        old_listen = copy.deepcopy(listen_dict[vip])
        if not incr:
            #update
            #in update listen case, old dyups may leak due to changed rules
            #record old upstream to deleted
            if len(listen_dict[vip].http_rule) > 0:
                port = vip
                dyups_list_old = []
                dyups_list_new = []
                dyups_list_remove = []
                for rule in listen_dict[vip].http_rule:
                    if rule.state != proxy_pb2.HttpRule.DELETED:
                        dyups_list_old.append(str(port) + '_' + rule.name)
                if len(message.http_rule) > 0:
                    for rule in message.http_rule:
                        if rule.state != proxy_pb2.HttpRule.DELETED:
                            dyups_list_new.append(str(port) + '_' + rule.name)
                #calc the upstream to be deleted
                for ups in dyups_list_old:
                    if ups not in dyups_list_new:
                        dyups_list_remove.append(ups)
                ndupslist = dyups_list_remove
            listen_dict[vip] = message
            listennerid_vip[message.listener_id] = vip
            lb = lb_dict[message.loadbalancer_id]
            listen_dict[vip].config.sla_config.CopyFrom(lb.sla_config) 
            log_info("[update_listen][LI] Full Update qps to %d" % lb.sla_config.qps)
        else:
            #config listen
            if message.HasField('config'):
                #qps is from lb only
                qps_bak = listen_dict[vip].config.sla_config.qps 
                listen_dict[vip].config.CopyFrom(message.config)
                log_info("[update_listen][LI] set qps back to %d" % qps_bak)
                listen_dict[vip].config.sla_config.qps = qps_bak
            if message.HasField('cert_key'):#cert_key can be None
                listen_dict[vip].cert_key.CopyFrom(message.cert_key) 
            if message.HasField('forward_port'):
                listen_dict[vip].forward_port = message.forward_port               
            if message.HasField('backend_protocol'):
                listen_dict[vip].backend_protocol = message.backend_protocol
            if message.HasField('address'):
                listen_dict[vip].address = message.address
            if message.HasField('upstream_keepalive'):
                if message.upstream_keepalive.enable == common_pb2.OFF:
                    if listen_dict[vip].HasField("upstream_keepalive"):
                        listen_dict[vip].ClearField("upstream_keepalive")
                elif message.upstream_keepalive.enable == common_pb2.ON:
                    listen_dict[vip].upstream_keepalive.CopyFrom(message.upstream_keepalive)
            if message.HasField('ssl_dyn_rec'):
                if message.ssl_dyn_rec.state == proxy_pb2.SslDynRec.DELETED:
                    if listen_dict[vip].HasField("ssl_dyn_rec"):
                        listen_dict[vip].ClearField("ssl_dyn_rec")
                elif message.ssl_dyn_rec.state == proxy_pb2.SslDynRec.CREATED:
                    listen_dict[vip].ssl_dyn_rec.CopyFrom(message.ssl_dyn_rec)
            if message.HasField('ignore_client_abort'):
                listen_dict[vip].ignore_client_abort = message.ignore_client_abort
            if message.HasField("x_forwarded_client_port"):
                listen_dict[vip].x_forwarded_client_port = message.x_forwarded_client_port
            if message.HasField("x_forwarded_port"):
                listen_dict[vip].x_forwarded_port = message.x_forwarded_port
            if message.HasField("quic_relation"):
                if message.quic_relation.switch == common_pb2.OFF:
                    if listen_dict[vip].HasField("quic_relation"):
                        listen_dict[vip].ClearField("quic_relation")
                elif message.quic_relation.switch == common_pb2.ON:
                    listen_dict[vip].quic_relation.CopyFrom(message.quic_relation)

            ret = update_sni_list(message.sni_list, listen_dict[vip].sni_list)
            if not ret:
                listen_dict[vip] = old_listen
                log_error('[Error][update_listen][LI] sni check error %s' % str(vip))
                return AGENT_ERR

            #config update realserver
            ret = update_realservers(message.realserver, listen_dict[vip].realserver)               
            if ret == False: 
                listen_dict[vip] = old_listen
                log_error('[Error][update_listen][LI] rs check error %s' % str(vip))
                return AGENT_ERR
            #config update xforwarded_certinfo
            ret = update_wildconfiginfolist(message.httpWildConfigInfoList, listen_dict[vip].httpWildConfigInfoList)
            if ret == False:
                listen_dict[vip] = old_listen
                log_error('[Error][update_listen][LI] wildconfig check error %s' % str(vip))
                return AGENT_ERR
            #config update httprule
            ret,ndupslist,newadded = update_rules(message.http_rule, listen_dict[vip].http_rule, vip, is_app_rule)
            if ret == False: 
                listen_dict[vip] = old_listen
                log_error('[Error][update_listen][LI] rule rs check error %s' % str(vip))
                return AGENT_ERR
            #config layer_seven_port_info
            update_l7port_infos(message.layer_seven_port_info, listen_dict[vip].layer_seven_port_info) 
            listen_dict[vip].version = message.version
        write_vip_conf(listen_dict[vip], False, ndupslist, newadded,  old_listen)
        if not is_hotconf_enable():
        	update_include_ups_conf()
        NEED_MODIFY = True
        return AGENT_OK           
    except Exception,e:        
        if old_listen != None:
            log_error('[update_listen][LI] rollback listen')
            listen_dict[vip] = old_listen
        NEED_RELOAD = True
        log_error('[Except][update_listen][LI] error %s' % str(e))
        return AGENT_ERR
    finally:
        log_info("[update_listen][LI] end")
        
def delete_lb(message):
    global lb_dict     
    global NEED_RELOAD, NEED_MODIFY
    
    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[delete_lb][LB] start")
    try:    
        lbid = message.loadbalancer_id
        if lbid not in lb_dict:
            return AGENT_NOT_FOUND
        else:
            #populate_lb_to_all_vips(message,'delete')
            lb_dict.pop(lbid)
            
        return AGENT_OK
    except Exception,e:
        NEED_RELOAD = True
        log_error('[Except][delete_lb][LB] error %s' % str(e))
        return AGENT_ERR
    finally:
        log_info("[delete_lb][LB] end")
        
def delete_listen(message):
    global listen_dict, listennerid_vip  
    global NEED_RELOAD, NEED_MODIFY

    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[delete_listen][LI] start")
    try:
        lid = message.listener_id 
        if lid not in listennerid_vip:
            return AGENT_NOT_FOUND
        vip = listennerid_vip[lid]
        if vip not in listen_dict:
            listennerid_vip.pop(lid)
            return AGENT_NOT_FOUND
        else:
            listen_to_be_deleted = listen_dict.pop(vip)
            listennerid_vip.pop(lid)
            rm_hash_tbl_item(message.loadbalancer_id, vip)
            write_vip_conf(gen_fake_upstream(vip), True, None, None, listen_to_be_deleted)
            if not is_hotconf_enable():
                update_include_ups_conf()
            NEED_MODIFY = True
        return AGENT_OK
    except Exception,e:
        NEED_RELOAD = True
        log_error('[Except][delete_listen][LI] error %s' % str(e))
        return AGENT_ERR
    finally:
        log_info("[delete_listen][LI] end")
        
def create_lb(message):
    global lb_dict     
    global NEED_RELOAD, NEED_MODIFY

    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[create_lb][LB] start")
    try:
        #add to lb_dict
        lbid = message.loadbalancer_id
        log_info("[create_lb][LB] creating LB ID %s" % lbid)
        if lb_dict.has_key(lbid):
            log_info("[create_lb][LB] LB ID %s exists already" % lbid)
            return AGENT_EXI
        else:
            ret = verify_lb(message)
            if ret == False:
                log_error("[Error][create_lb] [verify_lb] failed %s" % lbid)
                return AGENT_ERR
            lb_dict[lbid] = message           
            #populate_lb_to_all_vips(message,'create')
        return AGENT_OK
    except Exception,e:
        NEED_RELOAD = True
        log_error('[Error][create_lb][LB] error %s' % str(e))
        return AGENT_ERR
    finally:
        log_info("[create_lb][LB] end")
        
def create_listen(message):
    """

    :param message: LayerSevenServiceMessage
    :return: AGENT_OK or AGENT_ERR
    """
    global listen_dict, listennerid_vip    
    global device_group 
    global NEED_RELOAD, NEED_MODIFY
    
    if message.HasField('request_id'):
        set_request_id(message.request_id)
    log_info("[create_listen][LI] start")
    try:
        if not message.HasField('port'):
            log_info("[create_listen][LI]  without port info")
            return AGENT_ERR
        #check lb exist
        if not lb_dict.has_key(message.loadbalancer_id):
            log_info("[create_listen][LI] without LB")
            return AGENT_ERR
        if not is_eppu(message):
            vip = message.port
        else:#let's get vip according to device_group_name
            vip, ret = get_port_from_eppu(message)
            if vip == None:
               log_error("create_listen [Eppu] can not get port") 
               return AGENT_ERR
        lsid = message.listener_id
        lbid = message.loadbalancer_id
        log_info("[create_listen][LI] creating listener ID %s for LB ID %s on port %d" % (lsid, lbid, vip))
        if listen_dict.has_key(vip) : 
            log_info("[create_listen][LI] listen port %d exist" % vip)
            return AGENT_EXI#case delete and new create vip out of order
        else:
            ret = verify_listen(message, vip, create=True)
            if ret == False:
                log_error("[Error][create_listen] [verify_listen] failed %d" % vip)
                return AGENT_ERR
            listen_dict[vip] = message  
            listennerid_vip[lsid] = vip
            port_used_map[vip] = True
            lb = lb_dict[lbid]
            listen_dict[vip].config.sla_config.CopyFrom(lb.sla_config) 
            set_hash_tbl_item(lbid, vip)
        #write the conf
        if build_protocol(message) == 'tcps' or build_protocol(message) == 'quic':
            old_listen = gen_fake_upstream(vip)
        else:
            old_listen = None
        write_vip_conf(message, False, None, None, old_listen)
        if not is_hotconf_enable():
            update_include_ups_conf()
        NEED_MODIFY = True
        return AGENT_OK
    except Exception,e:
        NEED_RELOAD = True
        log_error('[Except][create_listen][LI]  error %s' % str(e))
        #rollback
        if listen_dict.has_key(vip):
            listen_dict.pop(vip)
        if listennerid_vip.has_key(lsid):
            listennerid_vip.pop(lsid)
        bucket = abs(hash(lbid)) % lb_hash_tbl_buckets
        for i in range(len(lb_hash_tbl[bucket])):    
            if lb_hash_tbl[bucket][i] == vip:
                lb_hash_tbl[bucket].pop(i)
        return AGENT_ERR
    finally:
        log_info("[create_listen][LI]  end")

def time_cost(t_begin, t_end, func, role):
    td = t_end - t_begin
    td_ms =  (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**3
    if td_ms > 10 * 1000:
        log_info("[%s]unexpected duration:[%s], Time:%d" % (func, role, td_ms))
    else:
        log_info("[%s] duration:[%s], Time:%d" % (func, role, td_ms) )

def create_handler(environ, start_response, roles):
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_nf, s_str_nf, response_headers_nf
    global rsp_exi, s_str_exi, response_headers_exi
    global rsp_vb, s_str_vb, response_headers_vb 
    global rsp_va, s_str_va, response_headers_va
    global rsp_inv, s_str_inv, response_headers_inv 
    global rsp_err, s_str_err, response_headers_err    
    global proxy_status
    global NEED_MODIFY, NEED_RELOAD
    
    log_info("[create_handler] start, role: %s" % roles) 
    t_begin = datetime.datetime.now()
    if proxy_status != PROXY_RUNNING:
        start_response('200 OK', response_headers_err)
        log_info("[create_handler] [%s] response: %s" % (roles,str(rsp_err)))
        return s_str_err
       
    try:
        request_body_size = int(environ.get('CONTENT_LENGTH', 0))
    except (ValueError):
        request_body_size = 0  
    request_body = environ['wsgi.input'].read(request_body_size)

    try:
        if roles == 'lb':
            receiveData =loadbalancer_pb2.LoadbalancerMessage()
            receiveData.ParseFromString(request_body)
            log_info("[create_handler][LB] message: %s" % str(receiveData).replace('\n', ' ')) 
            #top half
            s_str = check_ver_handler(receiveData, 'create', None, create_lb, start_response)
        elif roles == 'listen':
            receiveData = proxy_pb2.LayerSevenServiceMessage()
            receiveData.ParseFromString(request_body)
            log_info("[create_handler][LI] message: %s" % str(receiveData).replace('\n', ' ')) 
            #top half
            s_str = check_ver_handler(receiveData, 'create', None, create_listen, start_response)          
    
        log_info("[create_handler][%s] NEED_RELOAD:%s, NEED_MODIFY:%s" % (roles, NEED_RELOAD, NEED_MODIFY))
        if NEED_RELOAD:
            if is_hotconf_enable():
                log_info("[create_handler] [%s] NEED_RELOAD skip" % roles)
                raise Exception("exception raised due to cfg fail")
            else:        
                log_info("[create_handler] [%s] NEED_RELOAD" % roles)
                if not gen_all_conf_files():
                    raise Exception("gen conf files failed")
                proxy_start()
                proxy_start_after("success")

        elif NEED_MODIFY:
            if is_hotconf_enable():
                log_info("[create_handler] [%s] NEED_MODIFY skip" % roles)
            else:
                log_info("[create_handler] [%s] NEED_MODIFY" % roles)
                proxy_start()
                proxy_start_after("success")

        else:
            log_info("[create_handler] [%s] dyups,no reload" % roles)
    except Exception, e:
        proxy_start_after("failt")
        log_error('[Except][create_handler]: %s' % str(e).replace('\n', ' '))               
        return s_str_err         
    finally:
        NEED_RELOAD = False
        NEED_MODIFY = False
        log_info("[create_handler] end ")
        
    t_end = datetime.datetime.now()
    time_cost(t_begin,t_end,'create_handler',roles)

    return  s_str  
    
def delete_handler(environ, start_response, roles):
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_nf, s_str_nf, response_headers_nf
    global rsp_exi, s_str_exi, response_headers_exi
    global rsp_vb, s_str_vb, response_headers_vb 
    global rsp_va, s_str_va, response_headers_va
    global rsp_inv, s_str_inv, response_headers_inv 
    global rsp_err, s_str_err, response_headers_err    
    global proxy_status
    global NEED_MODIFY, NEED_RELOAD
    
    log_info("[delete_handler] start, role: %s" % roles)
    t_begin = datetime.datetime.now()
    if proxy_status != PROXY_RUNNING:
        start_response('200 OK', response_headers_err)
        log_info("[delete_handler] [%s] response: %s" % (roles,str(rsp_err)))                           
        return s_str_err
        
    try:
        request_body_size = int(environ.get('CONTENT_LENGTH', 0))
    except (ValueError):
        request_body_size = 0   
    request_body = environ['wsgi.input'].read(request_body_size)   

    try:
        if roles == 'lb':
            receiveData =loadbalancer_pb2.LoadbalancerMessage()
            receiveData.ParseFromString(request_body)        
            log_info("[delete_handler] [LB] message: %s" % str(receiveData).replace('\n', ' '))                
            s_str = check_ver_handler(receiveData, 'delete', None, delete_lb, start_response)
            
        elif roles == 'listen':        
            receiveData = proxy_pb2.LayerSevenServiceMessage()
            receiveData.ParseFromString(request_body)        
            log_info("[delete_handler] [LI] message: %s" % str(receiveData).replace('\n', ' '))  
            s_str = check_ver_handler(receiveData, 'delete', None, delete_listen, start_response)
                  
        log_info("[delete_handler] [%s] NEED_RELOAD:%s, NEED_MODIFY:%s" % (roles, NEED_RELOAD, NEED_MODIFY))
        if NEED_RELOAD:
            if is_hotconf_enable():
                log_info("[delete_handler] [%s] NEED_RELOAD skip" % roles) 
                raise Exception("exception raised due to cfg fail")
            else:
                log_info("[delete_handler] [%s] NEED_RELOAD" % roles)
                if not gen_all_conf_files():
                    raise Exception("gen conf files failed")
                proxy_start()
                proxy_start_after("success")

        elif NEED_MODIFY:
            if is_hotconf_enable():
                log_info("[delete_handler] [%s] NEED_MODIFY skip" % roles)
            else:
                log_info("[delete_handler] [%s] NEED_MODIFY" % roles)
                proxy_start()
                proxy_start_after("success")
        else:
            log_info("[delete_handler] [%s] dyups,no reload" % roles)
    except Exception,e:
        proxy_start_after("failt")
        log_error('[Except][delete_handler]: %s' % str(e).replace('\n', ' '))
        #start_response('200 OK', response_headers_err)
        log_info("[delete_handler] [%s] response: %s" % (roles,str(rsp_err)))                           
        return s_str_err         
    finally:
        NEED_RELOAD = False
        NEED_MODIFY = False
        log_info("end process delete msg")  

    t_end = datetime.datetime.now()
    time_cost(t_begin,t_end,'delete_handler',roles)
    return s_str    
    
def update_handler(environ, start_response, roles):
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_nf, s_str_nf, response_headers_nf
    global rsp_exi, s_str_exi, response_headers_exi
    global rsp_vb, s_str_vb, response_headers_vb 
    global rsp_va, s_str_va, response_headers_va
    global rsp_inv, s_str_inv, response_headers_inv 
    global rsp_err, s_str_err, response_headers_err
    global device_cfg_ver,device_group_ver
    global proxy_status
    global NEED_MODIFY, NEED_RELOAD
    
    log_info("[update_handler] start, role start: %s" % roles)  
    s_str = None
    t_begin = datetime.datetime.now()
    
    if proxy_status != PROXY_RUNNING:
        start_response('200 OK', response_headers_err)
        log_info("[update_handler] [%s] response: %s" % (roles,str(rsp_err)))                           
        return s_str_err
        
    try:
        request_body_size = int(environ.get('CONTENT_LENGTH', 0))
    except (ValueError):
        request_body_size = 0   
    request_body = environ['wsgi.input'].read(request_body_size)

    try:
        if roles == 'lb':
            receiveData =loadbalancer_pb2.LoadbalancerMessage()
            receiveData.ParseFromString(request_body) 
            log_info("[update_handler] [LB] message: %s" % str(receiveData).replace('\n', ' ')) 
            s_str = check_ver_handler(receiveData, 'update', update_lb_precheck, update_lb, start_response)
        elif roles == 'device_group':
            receiveData = proxy_pb2.ProxyDeviceGroupConfigurationMessage()
            receiveData.ParseFromString(request_body) 
            log_info("[update_handler] [DG] message: %s" % str(receiveData).replace('\n', ' ')) 
            s_str = check_ver_handler(receiveData, 'update', device_group_precheck, device_group_update,start_response)
        elif roles == 'listen':
            receiveData =  proxy_pb2.LayerSevenServiceMessage()
            receiveData.ParseFromString(request_body) 
            log_info("[update_handler] [LI] message: %s" % str(receiveData).replace('\n', ' ')) 
            s_str = check_ver_handler(receiveData, 'update', update_listen_precheck, update_listen, start_response)
        elif roles == 'device':
            receiveData = proxy_pb2.ProxyDeviceConfigurationMessage()
            receiveData.ParseFromString(request_body) 
            log_info("[update_handler] [DE] message: %s" % str(receiveData).replace('\n', ' ')) 
            s_str = check_ver_handler(receiveData, 'update', device_precheck, device_update, start_response)
        elif roles == 'fswitch': 
            receiveData = common_pb2.FlowSwitchConfigurationMessage()
            receiveData.ParseFromString(request_body) 
            log_info("[update_handler] [FS] message: %s" % str(receiveData).replace('\n', ' ')) 
            if receiveData.flow_switch == common_pb2.ON:
                s_str = check_ver_handler(receiveData, 'update', fswitch_precheck, enable_service, start_response)
            else:
                s_str = check_ver_handler(receiveData, 'update', fswitch_precheck, disable_service, start_response)                    

        log_info("[update_handler] [%s] NEED_RELOAD:%s, NEED_MODIFY:%s" % (roles, NEED_RELOAD, NEED_MODIFY))
        if NEED_RELOAD:
            if is_hotconf_enable():
                log_info("[update_handler] [%s] NEED_RELOAD skip" % roles)
                raise Exception("exception raised due to cfg fail")
            else:        
                log_info("[update_handler] [%s] NEED_RELOAD" % roles)
                if not gen_all_conf_files():
                    raise Exception("gen conf files failed")
                proxy_start()
                proxy_start_after("success")

        elif NEED_MODIFY:
            if is_hotconf_enable():
                log_info("[update_handler] [%s] NEED_MODIFY skip" % roles)
            else:
                log_info("[update_handler] [%s] NEED_MODIFY" % roles)
                proxy_start()
                proxy_start_after("success")

        else:
            log_info("[update_handler] [%s] dyups,no reload" % roles)
    except Exception,e:
        proxy_start_after("failt")
        log_error('[Except][update_handler]: %s' % str(e).replace('\n', ' '))
        if s_str != None:
            return s_str
        #start_response('200 OK', response_headers_err)
        log_info("[update_handler] [%s] response: %s" % (roles,str(rsp_err)))                           
        return s_str_err         
    finally:
        NEED_RELOAD = False
        NEED_MODIFY = False
        log_info("[update_handler] end") 

    t_end = datetime.datetime.now()
    time_cost(t_begin,t_end,'update_handler', roles)
    return s_str

def write_to_main_conf(content):
    log_info("[write_to_main_conf] write proxy conf")
    if content is None:
        log_error("[Error][write_to_main_conf] main conf is none")
        return False

    templateFile = None
    try:
        if not os.path.exists(PROXY_CONF_DIR):
            os.makedirs(PROXY_CONF_DIR, 0644)

        templateFile = open(DEFAULT_PROXY_FILE_NEW, 'w')
        templateFile.write(content)
        return True

    except Exception as e:
        log_error('[Except][write_to_main_conf] error %s' % str(e))
        return False

    finally:
        if templateFile is not None:
            templateFile.close()
            
def gen_fake_upstream(port=80):

    listen = proxy_pb2.LayerSevenServiceMessage()
    listen.address = host
    listen.port = int(port)
    listen.protocol = 'http'
    listen.config.x_forwarded_for = common_pb2.ON
    listen.config.scheduler = common_pb2.WRR
    rs = listen.realserver.add()
    rs.address = "127.0.0.1"
    rs.port= 503
    rs.weight = 100
    return listen

def update_merge_dict(src, dst):
    for key in src.keys():
        if key not in dst.keys():
            dst[key] = src[key]
    return dst

def isEmptyRspool(rslist):
    if not len(rslist):
        return True
    for rs in rslist:
        if rs.HasField('weight') and rs.weight > 0:
            return False
    return True   

def genEmptyUpstreamConfig(name):
    return "\n\tupstream %s { server 127.0.0.1:503 max_fails=0 weight=100;}\n" % name
def genEmptyUpstreamConfig_(name):
    return "\n\t server 127.0.0.1:503 max_fails=0 weight=100;\n" 
    
def isHstsEnabled(hsts_config):
    if hsts_config and hsts_config.HasField("enable") and hsts_config.enable == common_pb2.ON:
        return True
    return False

def genHstsConfig(hsts_config):
    # slb_hsts 31536000 on;
    hsts_line = ""
    if isHstsEnabled(hsts_config):
        hsts_line = "slb_hsts "
        if hsts_config.HasField("max_age"):
            hsts_line += str(hsts_config.max_age)
        else:
            hsts_line += str(0)
        if hsts_config.HasField("include_subdomains") and hsts_config.include_subdomains == common_pb2.ON:
            hsts_line += " on"
        hsts_line += ";\n"
    return hsts_line

def genHstsNginxConfig(hsts_config):
    # add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
    hsts_line = ""
    if isHstsEnabled(hsts_config):
        hsts_line = "add_header Strict-Transport-Security \""
        if hsts_config.HasField("max_age"):
            hsts_line += "max-age=%d" % hsts_config.max_age
        else:
            hsts_line += "max-age=0"
        if hsts_config.HasField("include_subdomains") and hsts_config.include_subdomains == common_pb2.ON:
            hsts_line += "; includeSubDomains"
        hsts_line += "\";\n"
    return hsts_line

def genCustHeadersConfig(custhd_config):
    custhd = ""
    subjectdn = get_wildconfig("X-Forwarded-Clientcert-subjectdn", custhd_config)
    if subjectdn != None:
        if subjectdn.switch == common_pb2.ON:
            if len(subjectdn.key_alias) > 0:
                custhd += "sdn:" + subjectdn.key_alias + "|"
            else:
                custhd += "sdn:X-Forwarded-Clientcert-subjectdn|"

    issuerdn = get_wildconfig("X-Forwarded-Clientcert-issuerdn", custhd_config)
    if issuerdn != None:
        if issuerdn.switch == common_pb2.ON:
            if len(issuerdn.key_alias) > 0:
                custhd += "idn:" + issuerdn.key_alias + "|"
            else:
                custhd += "idn:X-Forwarded-Clientcert-issuerdn|"

    fingerprint = get_wildconfig("X-Forwarded-Clientcert-fingerprint", custhd_config)
    if fingerprint != None:
        if fingerprint.switch == common_pb2.ON:
            if len(fingerprint.key_alias) > 0:
                custhd += "fgp:" + fingerprint.key_alias + "|"
            else:
                custhd += "fgp:X-Forwarded-Clientcert-fingerprint|"

    clientverify = get_wildconfig("X-Forwarded-Clientcert-clientverify", custhd_config)
    if clientverify != None:
        if clientverify.switch == common_pb2.ON:
            if len(clientverify.key_alias) > 0:
                custhd += "cvf:" + clientverify.key_alias + "|"
            else:
                custhd += "cvf:X-Forwarded-Clientcert-clientverify|"

    return custhd


def gen_forward_client_ip_port_via_toa(wildconfiginfolist):
    res = ""
    v = get_wildconfig("forward_client_ip_port_via_toa", wildconfiginfolist)
    if v is None:
        return res

    if (v.switch == common_pb2.ON) and v.value and (v.value.lower() == 'on'):
        res += "forward_client_ip_port_via_toa on;"
    else:
        res += "forward_client_ip_port_via_toa off;"

    return res


def genQuicRelationConfig(quic_config):
    # add_header Alt-Svc 'quic=":port"; v="46,43,39"; ma=3600';
    # dyconf: quic_relation port v ma
    quic_versions = "46,43,39"
    quic_maxage = 3600

    ret = "quic_relation {port} {ver} {ma}"
    ret = ret.format(port=quic_config.port, ver=quic_versions, ma=quic_maxage)

    return ret


def get_check_type(check_type):
    if check_type == common_pb2.HealthCheck.HTTP:
        return "http"
    elif check_type == common_pb2.HealthCheck.TCP:
        return "tcp"
    else:
        raise Exception("unknow check_type")

def genUpstreamConfig(name, upstream, server_address, server_name, vipport, ruleurl):   
    if ruleurl == None:
        url = '/'
    else:
        url = '/' 
    ucf = list()
    ucf.append("\n\tupstream " + name + "{\n")
    if "scheduler" in upstream and upstream['scheduler'] == common_pb2.WLC:
        ucf.append("\t\tleast_conn;\n")
    if "sticky_session" in upstream :
        if upstream['sticky_session'].sticky_session_type == proxy_pb2.LayerSevenServiceConfig.StickySession.INSERT:
            if  not upstream['sticky_session'].HasField("timeout") or upstream['sticky_session'].timeout < 0:
                ucf.append("\t\tsession_sticky cookie=SERVERID mode=insert path=" + url + " option=indirect;\n")
            else:
                ucf.append("\t\tsession_sticky cookie=SERVERID mode=insert path=" + url + " option=indirect maxidle=" + str(upstream['sticky_session'].timeout)+";\n")
        elif upstream['sticky_session'].sticky_session_type == proxy_pb2.LayerSevenServiceConfig.StickySession.REWRITE:
            ucf.append("\t\tsession_sticky cookie=" + upstream['sticky_session'].cookie + " mode=rewrite;\n")
 
    if "check" in upstream and upstream['check']:
        check_type = "http"
        if upstream['check'].HasField("check_type"):
            check_type = get_check_type(upstream['check'].check_type)
        ucf.append("\t\tcheck type=%s default_down=false" % check_type)
        if upstream['check'].HasField("timeout"):
            ucf.append(" timeout=" + str(upstream['check'].timeout * 1000))
        if upstream['check'].HasField("up"):
            ucf.append(" rise=" + str(upstream['check'].up))
        if upstream['check'].HasField("down"):
            ucf.append(" fall=" + str(upstream['check'].down))
        if upstream['check'].HasField("interval"):
            ucf.append(" interval=" + str(upstream['check'].interval * 1000))
        else:
            ucf.append(" interval=" + str(DEFAULT_CHECK_INTERVAL))
        if upstream['check'].HasField('port'):
            ucf.append(" port=" + str(upstream['check'].port))
        if server_address is not None:
            ucf.append(" server_address=" + server_address)
        if vipport is not None:
            ucf.append(":" + str(vipport))
        if server_name is not None:
            ucf.append(" server_name=" + server_name)
        ucf.append(";\n")
        if check_type == "http":
            if upstream['check'].HasField("http_status_code"):
                ucf.append("\t\tcheck_http_expect_alive " + upstream['check'].http_status_code + ";\n")
            hc_method = 'HEAD'
            if upstream['check'].HasField("http_check_method") and upstream['check'].http_check_method == common_pb2.HealthCheck.GET:
                hc_method = 'GET'
            if upstream['check'].HasField("uri"):
                ucf.append("\t\tcheck_http_send \"" + hc_method + " " + upstream['check'].uri + " HTTP/1.0")
            if upstream['check'].HasField("domain"):
                ucf.append("\\r\\nHost: " + upstream['check'].domain)
            ucf.append("\\r\\n\\r\\n\";\n")

    port = None
    for realserver in upstream['realservers']:
        if not realserver.HasField('weight') or realserver.weight == 0:
            continue
        #add logic for site check: no site name, just pass, with name, let' check it
        #if realserver.HasField('site_name'):
        #    if realserver.site_name != device_group.site_name:
        #        continue
        rs_port = realserver.port
        ucf.append("\t\tserver " + realserver.address + ":" + str(rs_port) + " max_fails=0")
        weight = realserver.weight 
        if "scheduler" in upstream and upstream['scheduler'] == common_pb2.RR:
            weight = DEFAULT_WEIGHT
        ucf.append(" weight=" + str(weight))
        if realserver.HasField('tunnel_id') and realserver.tunnel_id != DEFAULT_TUNNEL_ID:
            ucf.append(" tunnel_id=" + str(realserver.tunnel_id) + " vgw_ip=" + realserver.vgw_ip)
        ucf.append(";\n")
    ucf.append("\t}\n")
    return "".join(ucf)

def get_ip_faimily(inaddr):
    try:
        add = ipaddress.ip_address(unicode(str(inaddr),"utf-8"))
    except Exception,e:
        return 0
    return add.version

def genUpstreamConfig_(name, upstream, server_address, server_name, vipport, lb_tunnel_id, listener_id, protocol, ruleurl, rule_id, pool_id):
    ucf = list()

    if ruleurl == None:
        url = '/'
    else:
        # for regex url case, we can't use this url for cookie path
        if upstream.has_key('is_url_regex') and upstream['is_url_regex'] == common_pb2.ON:
            url = '/'
        else:
            url = '/'#ruleurl

    ucf.append("\n\t " + "\n")
    if "scheduler" in upstream:
        if upstream['scheduler'] == common_pb2.WLC:
            ucf.append("\t\tleast_conn;\n")
        elif upstream['scheduler'] == common_pb2.SCH and protocol == 'tcps':
            ucf.append("\t\thash $remote_addr consistent;\n")

    if "sticky_session" in upstream and protocol != 'tcps':
        if upstream['sticky_session'].sticky_session_type == proxy_pb2.LayerSevenServiceConfig.StickySession.INSERT:
            if  not upstream['sticky_session'].HasField("timeout") or upstream['sticky_session'].timeout < 0:
                ucf.append("\t\tsession_sticky cookie=SERVERID mode=insert path=" + url + " option=indirect;\n")
            else:
                ucf.append("\t\tsession_sticky cookie=SERVERID mode=insert path=" + url + " option=indirect maxidle=" + str(upstream['sticky_session'].timeout)+";\n")
        elif upstream['sticky_session'].sticky_session_type == proxy_pb2.LayerSevenServiceConfig.StickySession.REWRITE:
            ucf.append("\t\tsession_sticky cookie=" + upstream['sticky_session'].cookie + " mode=rewrite;\n")
 
    if "keepalive" in upstream and upstream["keepalive"] > UPS_KEEPALIVE_DEFAULT and protocol != 'tcps':
        ucf.append("\t\tkeepalive " + str(upstream["keepalive"]) + ";\n")
        # 0 is never timeout
        if "keepalive_timeout" in upstream and upstream["keepalive_timeout"] > UPS_KEEPALIVE_TIMEOUT_NEVER:
            ucf.append("\t\tkeepalive_timeout " + str(upstream["keepalive_timeout"]) + ";\n")
        if "keepalive_requests" in upstream:
            ucf.append("\t\tkeepalive_requests " + str(upstream["keepalive_requests"]) + ";\n")

    if "check" in upstream and upstream['check']:
        check_type = "http"
        if upstream['check'].HasField("check_type"):
            check_type = get_check_type(upstream['check'].check_type)
        ucf.append("\t\tcheck type=%s default_down=false" % check_type)
        if upstream['check'].HasField("timeout"):
            ucf.append(" timeout=" + str(upstream['check'].timeout * 1000))
        if upstream['check'].HasField("up"):
            ucf.append(" rise=" + str(upstream['check'].up))
        if upstream['check'].HasField("down"):
            ucf.append(" fall=" + str(upstream['check'].down))
        if upstream['check'].HasField("interval"):
            ucf.append(" interval=" + str(upstream['check'].interval * 1000))
        else:
            ucf.append(" interval=" + str(DEFAULT_CHECK_INTERVAL))
        if upstream['check'].HasField('port'):
            ucf.append(" port=" + str(upstream['check'].port))
        if server_address is not None:
            ucf.append(" server_address=" + server_address)
        if vipport is not None:
            ucf.append(":" + str(vipport))
        if server_name is not None:
            ucf.append(" server_name=" + server_name)
        if listener_id is not None:
            ucf.append(" listener_id=" + listener_id)
        if lb_tunnel_id is not None:
            ucf.append(" lb_tunnel_id=" + str(lb_tunnel_id))
        if protocol != 'tcps':
            if rule_id is not None:
                ucf.append(" slb_rule_id=" + str(rule_id))
            if pool_id is not None:
                ucf.append(" slb_pool_id=" + str(pool_id))
        ucf.append(";\n")
        if check_type == "http":
            if upstream['check'].HasField("http_status_code"):
                ucf.append("\t\tcheck_http_expect_alive " + upstream['check'].http_status_code + ";\n")
            hc_method = 'HEAD'
            if upstream['check'].HasField("http_check_method") and upstream['check'].http_check_method == common_pb2.HealthCheck.GET:
                hc_method = 'GET'
            if upstream['check'].HasField("uri"):
                if upstream['check'].HasField("http_check_version") and upstream['check'].http_check_version == common_pb2.HealthCheck.HTTP11:
                    ucf.append("\t\tcheck_http_send \"" + hc_method + " " + upstream['check'].uri + " HTTP/1.1")
                else:
                    ucf.append("\t\tcheck_http_send \"" + hc_method + " " + upstream['check'].uri + " HTTP/1.0")

            if upstream['check'].HasField("domain"):
                ucf.append("\\r\\nHost: " + upstream['check'].domain)
            ucf.append("\\r\\n\\r\\n\";\n")

    port = None
    for realserver in upstream['realservers']:
        if not realserver.HasField('weight') or realserver.weight == 0:
            continue
        family = get_ip_faimily(realserver.address)
        if family == 0:
            continue
        #add logic for site check: no site name, just pass, with name, let' check it
        #if realserver.HasField('site_name'):
        #    if realserver.site_name != device_group.site_name:
        #        continue
        rs_port = realserver.port
        if family == 4:
            ucf.append("\t\tserver " + realserver.address + ":" + str(rs_port) + " max_fails=0")
        else:
            ucf.append("\t\tserver " + "[" + realserver.address + "]" + ":" + str(rs_port) + " max_fails=0")
        weight = realserver.weight 
        if "scheduler" in upstream and upstream['scheduler'] == common_pb2.RR:
            weight = DEFAULT_WEIGHT
        ucf.append(" weight=" + str(weight))
        if realserver.HasField('tunnel_id') and realserver.tunnel_id != DEFAULT_TUNNEL_ID:
            ucf.append(" tunnel_id=" + str(realserver.tunnel_id) + " vgw_ip=" + realserver.vgw_ip)
        ucf.append(";\n")
    ucf.append("\t\n")
    return "".join(ucf)


def parse_private_header_stream(wildconf, stripped_header):
    #turn off private header if private headers were config via wildconf
    for wild_key in wildconf.keys():
        if 'proxy_set_header' in wild_key and wildconf[wild_key]=='off':
            if stripped_header != None:
                stripped_header.append(wild_key)
            wildconf.pop(wild_key)

def parse_secure_cookie_from_wildconf(wildconf):
    #turn off slb_secure_cookie & slb_httponly_cookie
    flag1 = 0
    flag2 = 0
    for wild_key in wildconf.keys():
        if 'slb_secure_cookie' in wild_key: 
           if wildconf[wild_key]=='on':
               flag1 = SLB_SECURE_COOKIE
           wildconf.pop(wild_key)
        if 'slb_httponly_cookie' in wild_key:
           if wildconf[wild_key]=='on':
               flag2 = SLB_HTTPONLY_COOKIE
           wildconf.pop(wild_key)

    if flag1 and flag2:
        return SLB_SECURE_HTTPONLY_COOKIE
    elif flag1:
        return flag1
    elif flag2:
        return flag2
    else:
        return 0

'''
start gen_vip_section refactoring
'''


def build_xff(listen):
    x_forwarded_for = ""
    protocol = build_protocol(listen)
    if listen.config.HasField("x_forwarded_for"):
        if protocol == 'tcps':
            pass
        elif listen.config.x_forwarded_for == common_pb2.ON:
            x_forwarded_for = "proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;"
    return x_forwarded_for

def build_vip(listen):
    vip = "0.0.0.0"
    if listen.HasField("address"):
        vip = listen.address
    return vip

def build_vport(listen):
    vport = "0"
    if listen.HasField("vip_port"):
        vport = str(listen.vip_port)
    return vport


def build_backend_protocol(listen):
    if listen.HasField("backend_protocol"):
        _backend_protocol = listen.backend_protocol.lower()
        if _backend_protocol == "https":
            return "https"
        elif _backend_protocol == "http":
            return "http"
        else:
            raise Exception("unknown backend_protocol")
    else:
        return "http"


def build_protocol(listen):
    protocol = ""
    if listen.HasField("protocol"):
        protocol = listen.protocol

    return protocol


def build_tunnelid(listen):
    tunnel_id = 0
    if listen.HasField("tunnel_id"):
        tunnel_id = listen.tunnel_id
    return tunnel_id

def build_slbinfo(listen, tunnel_id, vip, vport, lb_id, protocol, listener_id):
    slb_info = ""
    if listener_id != "":
        slb_info = "\t\t\tset $slb_info \"" + str(tunnel_id) + "_" + vip + ":" + vport + "#" + \
                   lb_id + "#" + protocol + "#" + listener_id + "\";\n"
    return slb_info

'''
input:
    listen, path for cert
output:
    ssl_ca_cert,ssl_ca_cert_new:verify client related
'''
def build_ca_cert(listen,ssl_conf_hash_path):
    use_ca_cert = False
    cacertid = None
    cacert = None

    if listen.cert_key.HasField("ca_cert_id") and listen.cert_key.HasField("ca_cert"):
        cacertid = listen.cert_key.ca_cert_id
        cacert = listen.cert_key.ca_cert
        log_info("[build_ca_cert] using CA cert id: %s" % cacertid)
        use_ca_cert = True

        ca_crt_path = ssl_conf_hash_path + "/%s.crt" % cacertid
        log_info("[build_ca_cert] using CA crt path: %s" % ca_crt_path)
        if not os.path.exists(ca_crt_path):
            os.mknod(ca_crt_path, 0644)

        cert_file = open(ca_crt_path, "w")
        cacert = cacert.replace("\\n", "\n")
        cert_file.write(cacert)
        cert_file.close()

    if use_ca_cert:
        ssl_ca_cert = "\tssl_verify_client on;\n\tssl_verify_depth 3;\n\tssl_client_certificate %s;\n" % ca_crt_path
        ssl_ca_cert_new = "\tssl_verify_client on;\n\tssl_client_certificate %s;\n" % ca_crt_path
    else:
        ssl_ca_cert = ""
        ssl_ca_cert_new = ""

    return ssl_ca_cert,ssl_ca_cert_new


def build_sni_cert(sni_item):
    cert = sni_item.cert.replace("\\n", "\n")
    cert_str = sni_item.domain + ";" + cert + ";"

    return cert_str


def build_sni_list_agent_conf(listen):
    ssl_certificate_vip = ""
    if listen.HasField("sni_list_enable") and listen.sni_list_enable == 1:
        for sni_item in listen.sni_list:
            cert_key_id = sni_item.cert_key_id
            ssl_conf_hash_path = DEFAULT_SSL_PATH + "/%s" % cert_key_id[0]
            if not os.path.exists(ssl_conf_hash_path):
                os.makedirs(ssl_conf_hash_path, 0644)
            crt_path = ssl_conf_hash_path + "/%s.crt" % cert_key_id
            if not os.path.exists(crt_path):
                os.mknod(crt_path, 0644)
            cert = sni_item.cert.replace("\\n", "\n")
            cert_file = open(crt_path, "w")
            cert_file.write(cert)
            cert_file.close()
            ssl_certificate_vip += "\tsni_certificate %s %s;\n" % (sni_item.domain, crt_path)

    return ssl_certificate_vip


'''
input:
    listen
output:
    ssl_ca_cert_vip,ssl_ca_cert_new_vip #verify client
    ssl_certificate_vip # cert
    ssl_keyless_server #keyless server addr
    ssl_on, http2_on, ssl_keyless_server, cert
    ssl_config_vip # all ssl except cert and cacert
    ssl_config_new # all ssl for hotconf
    ssl_config #all ssl related
'''
def build_https_cfg(listen):
    #build cert
    certkeyid = listen.cert_key.cert_key_id  #requird
    keyserverurl = listen.cert_key.key_server_url #required
    log_info("[build_https_cfg] receive certkeyid: %s" % certkeyid)
    ssl_conf_hash_path = DEFAULT_SSL_PATH + "/%s" % certkeyid[0]
    if not os.path.exists(ssl_conf_hash_path):
        os.makedirs(ssl_conf_hash_path, 0644)
    crt_path = ssl_conf_hash_path + "/%s.crt" % certkeyid
    log_info("[build_https_cfg] store crt path: %s" % crt_path)
    if not os.path.exists(crt_path):
        os.mknod(crt_path, 0644)
    cert = listen.cert_key.cert.replace("\\n", "\n")
    cert_file = open(crt_path, "w")
    cert_file.write(cert)
    cert_file.close()
    log_info("[build_https_cfg] receive keyserverurl: %s" % keyserverurl)
    cert = ";" + cert + ";"

    ssl_on = DEFAULT_SSL_ON

    #http2
    http2_on = ""
    http2_on_conf_file = ""
    if is_hotconf_enable and is_http2_enable():
        if listen.config.HasField("http2") and listen.config.http2 == common_pb2.OFF:
            http2_on = ""
        else:
            http2_on_conf_file = "\thttp2_enable on;\n"
            http2_on = "\thttp2 on;\n"

    ssl_certificate_vip = build_sni_list_agent_conf(listen)
    ssl_certificate_vip += "\tssl_certificate      %s;\n" % crt_path
    ssl_keyless_server = "\tssl_keyless_server %s;\n" % keyserverurl

    #tls
    tls_ver_dy = False
    if listen.config.HasField("tls_protocols"):
        protocols = listen.config.tls_protocols
        pros_l = protocols.split(',')
        tls_ver_dy = True
        protocols = " ".join(pros_l)
        log_info("[build_https_cfg] customized protocols:%s" % protocols)
        ssl_protocols = "\tssl_protocols " + protocols + ";\n"
    else:
        log_info("[build_https_cfg] default protocols")
        ssl_protocols = DEFAULT_SSL_PROTOCOLS
    if listen.config.HasField("tls_ciphers"):
        ciphers = listen.config.tls_ciphers
        log_info("[build_https_cfg] customized ciphers:%s" % ciphers)
        ssl_ciphers = gen_ssl_ciphers(ciphers)
    else:
        log_info("[build_https_cfg] default ciphers")
        ssl_ciphers = DEFAULT_SSL_CIPHERS

    #build ca cert
    ssl_ca_cert_vip,ssl_ca_cert_new_vip = build_ca_cert(listen, ssl_conf_hash_path)

    ssl_config_vip = ssl_on + http2_on_conf_file + SSL_KEYLESS_ON + ssl_keyless_server + SSL_KEYLESS_CERTIFICATE + SSL_KEYLESS_CERTIFICATE_KEY + \
    SSL_KEYLESS_VARIFY + SSL_KEYLESS_SERVER_CA + SSL_KEYLESS_SESSION_REUSE + SSL_LEYLESS_KEEPALIVE + \
    DEFAULT_SSL_SESSION_CACHE + ssl_protocols + ssl_ciphers + SSL_PREFER_SERVER_CIPHERS

    if tls_ver_dy == True:
        ssl_config_new= ssl_on + http2_on + ssl_keyless_server + ssl_ca_cert_new_vip + ssl_protocols + ssl_ciphers
    else:
        ssl_config_new= ssl_on + http2_on + ssl_keyless_server + ssl_ca_cert_new_vip
    ssl_config = ssl_config_vip + ssl_certificate_vip + ssl_ca_cert_vip
    return ssl_config, ssl_config_new, ssl_on, http2_on, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip


def build_tcps_cfg(listen):
    #build cert
    certkeyid = listen.cert_key.cert_key_id  #requird
    keyserverurl = listen.cert_key.key_server_url #required
    log_info("receive certkeyid: %s" % certkeyid)
    ssl_conf_hash_path = DEFAULT_SSL_PATH + "/%s" % certkeyid[0]
    if not os.path.exists(ssl_conf_hash_path):
        os.makedirs(ssl_conf_hash_path, 0644)
    crt_path = ssl_conf_hash_path + "/%s.crt" % certkeyid
    log_info("store crt path: %s" % crt_path)
    if not os.path.exists(crt_path):
        os.mknod(crt_path, 0644)
    cert = listen.cert_key.cert.replace("\\n", "\n")
    cert_file = open(crt_path, "w")
    cert_file.write(cert)
    cert_file.close()
    log_info("receive keyserverurl: %s" % keyserverurl)
    cert = ";" + cert + ";"

    ssl_on = DEFAULT_SSL_ON

    ssl_certificate_vip = build_sni_list_agent_conf(listen)
    ssl_certificate_vip += "\tssl_certificate      %s;\n" % crt_path
    ssl_keyless_server = "\tssl_keyless_server %s;\n" % keyserverurl

    #tls
    tls_ver_dy = False
    if listen.config.HasField("tls_protocols"):
        protocols = listen.config.tls_protocols
        pros_l = protocols.split(',')
        tls_ver_dy = True
        protocols = " ".join(pros_l)
        log_info("customized protocols:%s" % protocols)
        ssl_protocols = "\tssl_protocols " + protocols + ";\n"
    else:
        log_info("default protocols")
        ssl_protocols = DEFAULT_SSL_PROTOCOLS
    if listen.config.HasField("tls_ciphers"):
        ciphers = listen.config.tls_ciphers
        log_info("customized ciphers:%s" % ciphers)
        ssl_ciphers = gen_ssl_ciphers(ciphers)
    else:
        log_info("default ciphers")
        ssl_ciphers = DEFAULT_SSL_CIPHERS

    #build ca cert
    ssl_ca_cert_vip,ssl_ca_cert_new_vip = build_ca_cert(listen, ssl_conf_hash_path)

    ssl_config_vip = SSL_KEYLESS_ON + ssl_keyless_server + SSL_KEYLESS_CERTIFICATE + SSL_KEYLESS_CERTIFICATE_KEY + \
    SSL_KEYLESS_VARIFY + SSL_KEYLESS_SERVER_CA + SSL_KEYLESS_SESSION_REUSE + SSL_LEYLESS_KEEPALIVE + \
    DEFAULT_SSL_SESSION_CACHE + ssl_protocols + ssl_ciphers + SSL_PREFER_SERVER_CIPHERS

    if tls_ver_dy == True:
        ssl_config_new = ssl_keyless_server + ssl_ca_cert_new_vip + ssl_ciphers
    else:
        ssl_config_new = ssl_keyless_server + ssl_ca_cert_new_vip
    ssl_config = ssl_config_vip + ssl_certificate_vip + ssl_ca_cert_vip
    return ssl_config, ssl_config_new, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip


'''
output:rule_config[server_name]["ssl_config"]
'''
def build_rule_https_cfg(listen, rule, rule_config, ssl_on, http2_on, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip):
    if rule.HasField('domain'):
        server_name = rule.domain
    else:
        server_name = ""

    #tls
    ssl_protocols = ""
    ssl_ciphers = ""
    if rule.config.HasField("tls_protocols"):
        protocols = rule.config.tls_protocols
        pros_l = protocols.split(',')
        protocols = " ".join(pros_l)
        log_info("customized protocols:%s" % protocols)
        ssl_protocols = "\tssl_protocols " + protocols + ";\n"
    if rule.config.HasField("tls_ciphers"):
        ciphers = rule.config.tls_ciphers
        log_info("customized ciphers:%s" % ciphers)
        ssl_ciphers = gen_ssl_ciphers(ciphers)

    if rule.HasField("cert_key"):
        certkeyid = rule.cert_key.cert_key_id
        rule_cert = rule.cert_key.cert.replace("\\n", "\n")

        # certkeyid: <userid>_<timestamp>
        ssl_conf_hash_path = DEFAULT_SSL_PATH + "/%s" % certkeyid[0]
        if not os.path.exists(ssl_conf_hash_path):
            os.makedirs(ssl_conf_hash_path, 0644)

        crt_path = ssl_conf_hash_path + "/%s.crt" % certkeyid
        log_info("[build_rule_https_cfg] store crt path: %s" % crt_path)
        if not os.path.exists(crt_path):
            os.mknod(crt_path, 0644)

        # if not is_hotconf_enable():
        cert_file = open(crt_path, "w")
        cert_file.write(rule_cert)
        cert_file.close()

        cert += server_name + ";" + rule_cert + ";"

        ssl_certificate = "\tssl_certificate      %s;\n" % crt_path

        rule_config[server_name]["ssl_config"] = ssl_config_vip + ssl_certificate + ssl_ca_cert_vip
        rule_config[server_name]["ssl_config_new"] = ssl_on + http2_on + ssl_keyless_server + ssl_ca_cert_new_vip + ssl_protocols + ssl_ciphers
    elif listen.HasField("cert_key"):# inherit from listen
        cert += server_name + ";" + listen.cert_key.cert.replace("\\n", "\n") + ";"
        rule_config[server_name]["ssl_config"] = ssl_config_vip + ssl_certificate_vip + ssl_ca_cert_vip
        rule_config[server_name]["ssl_config_new"] = ssl_on + http2_on + ssl_keyless_server + ssl_ca_cert_new_vip + ssl_protocols + ssl_ciphers

    return cert

'''
merge default_wild_config_dict with listen.config.wild_config
'''
def build_listen_wildconf_phase1(listen):
    #this part is no use anymore
    new_wild_config_dict = {}
    for key in listen.config.wild_config:
        new_wild_config_dict[key] = listen.config.wild_config[key]
    new_wild_config_dict = update_merge_dict(default_wild_config_dict, new_wild_config_dict)
    return new_wild_config_dict

'''
default_server_backend, loc for vip
default_server_backend_new, loc for vip of hotconf
backend_section,  upstream
default_backend_section, upstream for vip
'''


def build_default_server_backend1(**kwargs):
    """ build configuration for listen which has no real servers, will use 127.0.0.1:503 instead.
    :param listen: listen.
    :param slb_info: prepared slb_info string.
    :return:
        default_server_backend: location block for disk persistence.
        default_server_backend_new: location block for dyconf.
        backend_section: upstream block for disk persistence.
        default_backend_section: content part in upstream block for dyups.
    """
    listen = kwargs["listen"]
    slb_info = kwargs["slb_info"]

    backend_protocol = build_backend_protocol(listen)
    lnport = listen.port
    slb_rule_id = DEFAULT_ID_VALUE
    slb_pool_id = DEFAULT_ID_VALUE

    if listen.HasField("rs_pool_name"):
        slb_pool_id =  listen.rs_pool_name

    if is_eppu(listen):
        lnport,ret = get_port_from_eppu(listen)
        if lnport == None: #just logging this case 
            log_error("gen_vip_section [Eppu] can not get port for fake backend")
            raise Exception, 'get_port_from_eppu [Eppu] error' 
        default_rs_pool_name = str(lnport) #must have, we have check in create listen
    else:
        default_rs_pool_name = str(listen.port) #must have, we have check in create listen
    protocol = build_protocol(listen)
    log_info("[build_default_server_backend1] default_rs_pool not in %s %s:%s" % (protocol, listen.address, lnport))
    if protocol == 'tcps':
        default_server_backend = slb_info
        default_server_backend_new = ""
        backend_section = genEmptyUpstreamConfig(default_rs_pool_name)
        default_backend_section = genEmptyUpstreamConfig_(default_rs_pool_name)
    else:
        if listen.HasField("is_app_rule") and listen.is_app_rule == 1:
            default_server_backend = "prio_location 2147483647 {\n"
        else:
            default_server_backend = "location / {\n"
        default_server_backend += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
        default_server_backend += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend += slb_info
        default_server_backend += "\t\t\tset $slbups " + default_rs_pool_name + ";\n"
        default_server_backend += "\t\t\tproxy_pass %s://$slbups;\n" % backend_protocol
        default_server_backend += "\t\t\tsession_sticky_hide_cookie upstream=" + default_rs_pool_name + ";\n"
        default_server_backend += "\t\t}\n"

        if listen.HasField("is_app_rule") and listen.is_app_rule == 1:
            default_server_backend_new = "prio_location 2147483647 {\n"
        else:
            default_server_backend_new = "location / {\n"
        if backend_protocol != "http":
            default_server_backend_new += "\t\t\tups_scheme %s;\n" % backend_protocol
        default_server_backend_new += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
        default_server_backend_new += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend_new += "\t\t\tups " + default_rs_pool_name + ";\n"
        default_server_backend_new += "\t\t\tslb_hide_cookie upstream=" + default_rs_pool_name + ";\n"
        default_server_backend_new += "\t\t}\n"

        backend_section = genEmptyUpstreamConfig(default_rs_pool_name)
        default_backend_section = genEmptyUpstreamConfig_(default_rs_pool_name)

    result = {
        'loc_for_vip' : default_server_backend,
        'hotconf_loc_for_vip' : default_server_backend_new,
        'upstream_for_vip' : backend_section,
        'hotconf_upstream_for_vip' : default_backend_section
    }
    return result

'''
backend_section = backend_section_rule + backend_section(default_backend_section),ups part
default_server_backend/default_server_backend_new, loc part
frontend_section, server part (include loc part)
'''


def build_default_server_backend2(**kwargs):
    """ build configuration for listen which has real servers.
    :param listen: listen.
    :param slb_info: prepared slb_info string.
    :param flag: secure and httponly cookie flag.
    :param lb_tunnel_id: lb_tunnel_id is needed for upstream healthcheck logging function.
    :param listener_id: listener_id is needed for upstream healthcheck logging function.
    :return:
        default_server_backend: location block for disk persistence.
        default_server_backend_new: location block for dyconf.
        backend_section: upstream block for disk persistence.
        default_backend_section: content part in upstream block for dyups.
    """
    #log_info("build_default_server_backend2")

    listen   = kwargs["listen"]
    rs_pool  = kwargs["rs_pool"]
    slb_info = kwargs["slb_info"]
    flag = kwargs["secure_cookie_flag"]
    lb_tunnel_id = kwargs["lb_tunnel_id"]
    listener_id  = kwargs["listener_id"]

    protocol = build_protocol(listen)
    if is_eppu(listen):
        lnport, ret = get_port_from_eppu(listen)
        if lnport == None:#just logging this case
            log_error("gen_vip_section [Eppu] can not get port for listen")
            raise Exception, 'get_port_from_eppu [Eppu] error' 
        default_rs_pool_name = str(lnport) #must have, we have check in create listen
    else:
        default_rs_pool_name = str(listen.port) #must have, we have check in create listen
    default_check = None
    default_scheduler = None
    default_server_backend = ""
    default_server_backend_new = ""
    backend_section = ""
    default_backend_section = ""
    backend_protocol = build_backend_protocol(listen)
    proxy_keepalive = 'off'
    proxy_ignore_client_abort = 'off'
    slb_rule_id = DEFAULT_ID_VALUE
    slb_pool_id = DEFAULT_ID_VALUE

    if listen.config.HasField("scheduler"):
        default_scheduler = listen.config.scheduler

    if listen.config.HasField("check") and \
            (common_pb2.HealthCheck.HTTP == listen.config.check.check_type or
             common_pb2.HealthCheck.TCP == listen.config.check.check_type):
        default_check = listen.config.check
        if not default_check.HasField('uri'):
            default_check.uri = "/"

    if default_rs_pool_name not in rs_pool:
        rs_pool[default_rs_pool_name] = {
            'check': default_check,
            'realservers': listen.realserver
        }
    else:
        rs_pool[default_rs_pool_name]['check'] = default_check
        rs_pool[default_rs_pool_name]['realservers'] = listen.realserver

    if listen.config.HasField("scheduler"):
        rs_pool[default_rs_pool_name]['scheduler'] = default_scheduler
    else:
        rs_pool[default_rs_pool_name]['scheduler'] = None #default

    if listen.HasField("rs_pool_name"):
        slb_pool_id =  listen.rs_pool_name

    if protocol == 'tcps':
        default_server_backend += slb_info
        default_server_backend_new += ""
    else:
        if listen.HasField("ignore_client_abort") and listen.ignore_client_abort == common_pb2.ON:
            proxy_ignore_client_abort = 'on'

        if listen.HasField('upstream_keepalive') and listen.upstream_keepalive.enable == common_pb2.ON: 
            if listen.upstream_keepalive.HasField("keepalive") and listen.upstream_keepalive.keepalive > UPS_KEEPALIVE_DEFAULT:
                proxy_keepalive = 'on'
                rs_pool[default_rs_pool_name]["keepalive"] = listen.upstream_keepalive.keepalive
            else:
                rs_pool[default_rs_pool_name]["keepalive"] = UPS_KEEPALIVE_DEFAULT

            if listen.upstream_keepalive.HasField("keepalive_timeout") and listen.upstream_keepalive.keepalive_timeout > UPS_KEEPALIVE_TIMEOUT_NEVER:
                rs_pool[default_rs_pool_name]["keepalive_timeout"] = listen.upstream_keepalive.keepalive_timeout
            else:
                rs_pool[default_rs_pool_name]["keepalive_timeout"] = UPS_KEEPALIVE_TIMEOUT_DEFAULT
            if listen.upstream_keepalive.HasField("keepalive_requests"):
                rs_pool[default_rs_pool_name]["keepalive_requests"] = listen.upstream_keepalive.keepalive_requests
            else:
                rs_pool[default_rs_pool_name]["keepalive_requests"] = UPS_KEEPALIVE_MAX_REQUESTS

        if listen.config.HasField("sticky_session"):
            rs_pool[default_rs_pool_name]['sticky_session'] = listen.config.sticky_session
        else:
            if "sticky_session" in rs_pool[default_rs_pool_name]:
                rs_pool[default_rs_pool_name].pop('sticky_session')

        if listen.HasField("is_app_rule") and listen.is_app_rule == 1:
            default_server_backend = "prio_location 2147483647 {\n"
        else:
            default_server_backend = "location / {\n"
        if proxy_ignore_client_abort == 'on':
            default_server_backend += "\t\t\tslb_ignore_client_abort on;\n"
        if proxy_keepalive == 'on':
            default_server_backend += "\t\t\tslb_upstream_keepalive on;\n"
        else:
            default_server_backend += "\t\t\tslb_upstream_keepalive off;\n"
        default_server_backend += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
        default_server_backend += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend += slb_info
        default_server_backend += "\t\t\tset $slbups " + default_rs_pool_name + ";\n"
        default_server_backend += "\t\t\tproxy_pass %s://$slbups;\n" % backend_protocol
        default_server_backend += "\t\t\tsession_sticky_hide_cookie upstream=" + default_rs_pool_name + ";\n"
        if flag == SLB_SECURE_HTTPONLY_COOKIE:
            default_server_backend += "\t\t\tslb_secure_cookie on;\n"
            default_server_backend += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_HTTPONLY_COOKIE:
            default_server_backend += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_SECURE_COOKIE:
            default_server_backend += "\t\t\tslb_secure_cookie on;\n"
        default_server_backend += "\t\t}\n"

        if listen.HasField("is_app_rule") and listen.is_app_rule == 1:
            default_server_backend_new = "prio_location 2147483647 {\n"
        else:
            default_server_backend_new = "location / {\n"
        if backend_protocol != "http":
            default_server_backend_new += "\t\t\tups_scheme %s;\n" % backend_protocol
        if proxy_ignore_client_abort == 'on':
            default_server_backend_new += "\t\t\tslb_ignore_client_abort on;\n"
        if proxy_keepalive == 'on':
            default_server_backend_new += "\t\t\tslb_upstream_keepalive on;\n"
        else:
            default_server_backend_new += "\t\t\tslb_upstream_keepalive off;\n"
        default_server_backend_new += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
        default_server_backend_new += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend_new += "\t\t\tups " + default_rs_pool_name + ";\n"
        default_server_backend_new += "\t\t\tslb_hide_cookie upstream=" + default_rs_pool_name + ";\n"
        if flag == SLB_SECURE_HTTPONLY_COOKIE:
            default_server_backend_new += "\t\t\tslb_secure_cookie on;\n"
            default_server_backend_new += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_HTTPONLY_COOKIE:
            default_server_backend_new += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_SECURE_COOKIE:
            default_server_backend_new += "\t\t\tslb_secure_cookie on;\n"
        default_server_backend_new += "\t\t}\n"

    if isEmptyRspool(listen.realserver):
        default_backend_section += genEmptyUpstreamConfig_(default_rs_pool_name)
        backend_section += genEmptyUpstreamConfig(default_rs_pool_name)
    else:
        default_backend_section += genUpstreamConfig_(default_rs_pool_name,
                                             rs_pool[default_rs_pool_name],
                                             listen.address, None,
                                             get_vport(listen, listen),
                                             lb_tunnel_id, listener_id, protocol, None, slb_rule_id, slb_pool_id)
        backend_section +=  "\n\tupstream " + default_rs_pool_name + "{\n" + default_backend_section + "\t}\n"

    result = {
        'loc_for_vip' : default_server_backend,
        'hotconf_loc_for_vip' : default_server_backend_new,
        'upstream_for_vip' : backend_section,
        'hotconf_upstream_for_vip' : default_backend_section
    }
    return result

'''
merge rule wildconf with
    if servername rule_config[server_name]['wild_config']
    else default_server_rule_config['wild_config']
output: default_server_rule_config['wild_config'] or rule_config[server_name]['wild_config']
'''
def build_rule_wilconf_phase1(rule, rule_config, default_server_rule_config):
    flag = 0
    if rule.HasField('domain'):
        server_name = rule.domain
    else:
        server_name = ""
    new_wild_config = rule.config.wild_config
    if server_name != "":
        if 'wild_config' not in rule_config[server_name]:
            rule_config[server_name]['wild_config'] = {}
        prev_wild_config = rule_config[server_name]['wild_config']
        rule_config[server_name]['wild_config'] = update_merge_dict(prev_wild_config, new_wild_config)
        flag = parse_secure_cookie_from_wildconf(rule_config[server_name]['wild_config'])
        parse_private_header_stream(rule_config[server_name]['wild_config'], None)
    else:
        if 'wild_config' not in default_server_rule_config:
            default_server_rule_config['wild_config'] = {}
        prev_wild_config = default_server_rule_config['wild_config']
        default_server_rule_config['wild_config'] = update_merge_dict(prev_wild_config, new_wild_config)
        flag = parse_secure_cookie_from_wildconf(default_server_rule_config['wild_config'])
        parse_private_header_stream(default_server_rule_config['wild_config'], None)
    return flag 

def build_forward_port_conf_file(forward_port, code):
    if forward_port == "443":
        return "\n\t\treturn %s https://$host$request_uri;" % code
    else:
        return "\n\t\treturn %s https://$host:%s$request_uri;" % (code, forward_port)

rendering_callbacks = {}
def register_rendering_callbacks(rendering_callbacks,k,v):
    if rendering_callbacks.has_key(k):
        return
    else:
        rendering_callbacks[k] = v
        log_info("[register_rendering_callbacks] %s" % k)

#example, new added feature should register callback here
def idle_timeout_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if rule.config.HasField("idle_timeout") and rule.config.idle_timeout > 0:
        if server_name != "":
            rule_config[server_name]["idle_timeout"] = str(rule.config.idle_timeout)
        else:
            default_server_rule_config["idle_timeout"] = str(rule.config.idle_timeout)

def read_timeout_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if rule.config.HasField("read_timeout") and rule.config.read_timeout > 0:
        if server_name != "":
            rule_config[server_name]["read_timeout"] = str(rule.config.read_timeout)
        else:
            default_server_rule_config["read_timeout"] = str(rule.config.read_timeout)
'''
def cust_headers_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if len(rule.httpWildConfigInfoList) > 0:
        if server_name != "":
            rule_config[server_name]["httpWildConfigInfoList"] = rule.httpWildConfigInfoList
        else:
            default_server_rule_config["httpWildConfigInfoList"] = rule.httpWildConfigInfoList
'''

def wildconfiginfolist_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if len(rule.httpWildConfigInfoList) > 0:
        if server_name != "":
            rule_config[server_name]["httpWildConfigInfoList"] = rule.httpWildConfigInfoList
        else:
            default_server_rule_config["httpWildConfigInfoList"] = rule.httpWildConfigInfoList

def ssl_dyn_rec_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if rule.HasField("ssl_dyn_rec") and rule.ssl_dyn_rec.HasField("timeout") and rule.ssl_dyn_rec.HasField("size_lo") \
       and rule.ssl_dyn_rec.HasField("size_hi") and rule.ssl_dyn_rec.HasField("threshold") and rule.ssl_dyn_rec.HasField("ssl_buffer_size"):
        if server_name != "":
            rule_config[server_name]["ssl_dyn_rec_timeout"] = str(rule.ssl_dyn_rec.timeout);
            rule_config[server_name]["ssl_dyn_rec_size_lo"] = str(rule.ssl_dyn_rec.size_lo);
            rule_config[server_name]["ssl_dyn_rec_size_hi"] = str(rule.ssl_dyn_rec.size_hi);
            rule_config[server_name]["ssl_buffer_size"] = str(rule.ssl_dyn_rec.ssl_buffer_size);
            rule_config[server_name]["ssl_dyn_rec_threshold"] = str(rule.ssl_dyn_rec.threshold);
        else:
            if listen.HasField("ssl_dyn_rec") and listen.ssl_dyn_rec.HasField("timeout") \
               and listen.ssl_dyn_rec.HasField("size_lo") and listen.ssl_dyn_rec.HasField("size_hi") \
               and listen.ssl_dyn_rec.HasField("threshold") and listen.ssl_dyn_rec.HasField("ssl_buffer_size"):
                default_server_rule_config["ssl_dyn_rec_timeout"] = str(listen.ssl_dyn_rec.timeout);
                default_server_rule_config["ssl_dyn_rec_size_lo"] = str(listen.ssl_dyn_rec.size_lo);
                default_server_rule_config["ssl_dyn_rec_size_hi"] = str(listen.ssl_dyn_rec.size_hi);
                default_server_rule_config["ssl_buffer_size"] = str(listen.ssl_dyn_rec.ssl_buffer_size);
                default_server_rule_config["ssl_dyn_rec_threshold"] = str(listen.ssl_dyn_rec.threshold);

def xfp_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    #xff is same as qps, we don't support rule level config
    if rule.HasField("x_forwarded_client_port") and rule.x_forwarded_client_port == common_pb2.ON:
        if server_name != "":
            rule_config[server_name]["x_forwarded_client_port"] = str(rule.x_forwarded_client_port)
        else:
            default_server_rule_config["x_forwarded_client_port"] = str(rule.x_forwarded_client_port)
    if rule.HasField("x_forwarded_port") and rule.x_forwarded_client_port == common_pb2.ON:
        if server_name != "":
            rule_config[server_name]["x_forwarded_port"] = str(rule.x_forwarded_port)
        else:
            default_server_rule_config["x_forwarded_port"] = str(rule.x_forwarded_port)

register_rendering_callbacks(rendering_callbacks,"idle_timeout", idle_timeout_rendering_callback)
register_rendering_callbacks(rendering_callbacks,"read_timeout", read_timeout_rendering_callback)
register_rendering_callbacks(rendering_callbacks,"ssl_dyn_rec", ssl_dyn_rec_rendering_callback)
register_rendering_callbacks(rendering_callbacks,"wildconfiginfolist", wildconfiginfolist_rendering_callback)
#register_rendering_callbacks(rendering_callbacks,"cust_headers", cust_headers_rendering_callback)
register_rendering_callbacks(rendering_callbacks,"xfp", xfp_rendering_callback)

def hsts_rendering_callback(listen, server_name,rule,default_server_rule_config,rule_config):
    if rule.config.HasField("hsts"):
        if server_name != "":
            rule_config[server_name]["hsts"] = rule.config.hsts
        else:
            default_server_rule_config["hsts"] = rule.config.hsts

register_rendering_callbacks(rendering_callbacks,"hsts", hsts_rendering_callback)

'''
output:rule,default_server_rule_config[feature], rule_config[servername][feature]
'''
def run_rendering_callbacks(rendering_callbacks,listen, server_name, rule,default_server_rule_config, rule_config):
    for k,v in rendering_callbacks.items():
        v(listen, server_name,rule,default_server_rule_config, rule_config)
        #log_info("run_rendering_callbacks %s" % k)

def build_actions(listen, rule):
    cmd = ""

    actions = sorted(rule.actions, lambda x, y: cmp(x.order, y.order))
    for action in actions:
        if action.type == proxy_pb2.Action.FORWARD:
            pass

        elif action.type == proxy_pb2.Action.REDIRECT:
            scheme = ""
            host = ""
            port = ""
            uri = ""
            query_string = ""

            redirect = action.redirect
            if redirect.HasField('protocol'):
                if redirect.protocol == proxy_pb2.Action.HTTP:
                    scheme = "http"
                elif redirect.protocol == proxy_pb2.Action.HTTPS:
                    scheme = "https"
                if scheme == "${protocol}":
                    scheme = ""

            if redirect.HasField('host'):
                host = redirect.host
                if host == "${host}":
                    host = ""

            if redirect.HasField('port'):
                port = redirect.port
                if port == "${port}":
                    port = ""

            if redirect.HasField('path'):
                uri = redirect.path
                if uri == "${path}":
                    uri = ""
                uri = uri.replace("${protocol}", "$\{scheme\}").\
                    replace("${host}", "$\{host\}").\
                    replace("${port}", "$\{slb_vport\}").\
                    replace("${path}", "$\{uri\}").\
                    replace("${query}", "$\{query_string\}")

            if redirect.HasField('query_string'):
                query_string = redirect.query_string
                if query_string == "${query}":
                    query_string = ""
                query_string = query_string.replace("${protocol}", "$\{scheme\}").\
                    replace("${host}", "$\{host\}").\
                    replace("${port}", "$\{slb_vport\}").\
                    replace("${path}", "$\{uri\}").\
                    replace("${query}", "$\{query_string\}")

            if scheme =="" and host == "" and port == "" \
                and uri == "" and query_string == "":
                log_error("[Error][build_actions] one in [protocol, host, port, path, query_string] when redirect must be changed")
                return ""

            http_code = redirect.http_code
            cmd += '\t\t\tslb_redirect "%s" "%s" "%s" "%s" "%s" %s;\n' % (scheme, host, port, uri, query_string, http_code)

        elif action.type == proxy_pb2.Action.FIXED_RESPONSE:
            fixed_response = action.fixed_response
            case_type = fixed_response.case_type
            http_code = fixed_response.http_code

            content_type = ""
            if fixed_response.HasField("content_type"):
                content_type = fixed_response.content_type

            content = ""
            file_name = ""
            if fixed_response.HasField("content"):
                content = fixed_response.content
                #write content to file
                fdir = "/etc/proxy/conf/fixed_response"
                if not os.path.exists(fdir):
                    os.mkdir(fdir)
                file_name = "%s/%s_%s" % (fdir, listen.port, rule.name)
                with open(file_name, 'w') as f:
                    f.write(content)

            cmd += '\t\t\tslb_fixed_response %s "%s" "%s";\n' % (http_code, content_type, file_name)

        elif action.type == proxy_pb2.Action.REWRITE:
            host = ""
            uri = ""
            query_string = ""

            rewrite = action.rewrite
            if rewrite.HasField("host"):
                host = rewrite.host
                if host == "${host}":
                    host = ""

            if rewrite.HasField("path"):
                uri = rewrite.path
                if uri == "${path}":
                    uri = ""
                uri = uri.replace("${host}", "$\{host\}").\
                        replace("${path}", "$\{uri\}").\
                        replace("${query}", "$\{query_string\}")

            if rewrite.HasField("query_string"):
                query_string = rewrite.query_string
                if query_string == "${query}":
                    query_string = ""
                query_string = query_string.replace("${host}", "$\{host\}").\
                        replace("${path}", "$\{uri\}").\
                        replace("${query}", "$\{query_string\}")

            if host == "" and uri == "" and query_string == "":
                log_error("[Error][build_actions] one in [host, path, query_string] when rewrite must be changed")
                return ""

            cmd += '\t\t\tslb_rewrite "%s" "%s" "%s";\n' % (host, uri, query_string)

        elif action.type == proxy_pb2.Action.INSERT_HEADER:
            ih = action.insertHeader
            case_type = ih.case_type
            header_key = ih.header_key
            value_type = ih.value_type
            if ih.cover_type == common_pb2.ON:
                cover_type = '1'
            else:
                cover_type = '0'
            if value_type == proxy_pb2.Action.USER_DEFINED:
                value = ih.value
            elif value_type == proxy_pb2.Action.REFERENCE_HEADER:
                value = "$\{%s\}" % ('http_' + ih.value.lower().replace('-', '_'))
            else:
                value = "$\{%s\}" % (ih.value)

            cmd += "\t\t\tslb_insert_req_header %s %s %s;\n" % (
                header_key, value, cover_type)

        elif action.type == proxy_pb2.Action.REMOVE_HEADER:
            rh = action.removeHeader
            cmd += "\t\t\tslb_remove_req_header %s;\n" % (
                rh.header_key)

        else:
            log_info('[Warning] unsupported action type %d for rule %s' % (
                action.type, rule.name))
            continue

    log_info('[build_actions] cmd of actions: %s' % (cmd.strip()))
    return cmd

def _value_encode(value, is_and=False):
    tag = 0
    if is_and == True:
        tag = 1

    tag_str = "%s" % tag
    len_str = "%s" % len(value)
    return tag_str.rjust(1, '0') + len_str.rjust(4, '0') + value.replace('\\', '\\\\').replace('"', '\\"')

def build_conditions(rule):

    cmd = ""
    query_string_cmd = ""
    cookie_cmd = ""
    for condition in rule.conditions:
        if condition.type == proxy_pb2.Condition.DOMAIN:
            case_sensitive = 0
            header_key = 'host'
            value = ""
            for val in condition.value:
                value += _value_encode(val)

        elif condition.type == proxy_pb2.Condition.URL:
            case_sensitive = 1
            header_key = 'uri'
            value = ""
            for val in condition.value:
                value += _value_encode(val)

        elif condition.type == proxy_pb2.Condition.HEADER:
            case_sensitive = 0
            header_key = 'http_' + condition.header_key.lower().replace('-', '_')
            value = ""
            for val in condition.value:
                value += _value_encode(val)

        elif condition.type == proxy_pb2.Condition.COOKIE:
            header_key = 'cookie'
            value = ""
            i = 0
            for val in condition.value:
                arg_dict = json.loads(val)
                if i == 0 and cookie_cmd != "":
                    value += _value_encode(arg_dict['key'] + "=" + arg_dict['value'], True)
                else:
                    value += _value_encode(arg_dict['key'] + "=" + arg_dict['value'])
                i += 1

            cookie_cmd += value

        elif condition.type == proxy_pb2.Condition.QUERY_STRING:
            header_key = "query_string"
            value = ""
            i = 0
            for val in condition.value:
                arg_dict = json.loads(val)
                if i == 0 and query_string_cmd != "":
                    value += _value_encode(arg_dict['key'] + "=" + arg_dict['value'], True)
                else:
                    value += _value_encode(arg_dict['key'] + "=" + arg_dict['value'])
                i += 1
            query_string_cmd += value

        elif condition.type == proxy_pb2.Condition.METHOD:
            case_sensitive = 1
            header_key = 'request_method'
            value = ""
            for val in condition.value:
                value += _value_encode(val)
        else:
            log_info('[Warning] unsupported condition type %d for rule %s' % (condition.type, rule.name))
            continue

        if header_key != 'query_string' and header_key != 'cookie':
            cmd += '\t\t\tmatch_variables ' + str(case_sensitive) + ' "' + header_key + '" "' + value + '";\n'

    if query_string_cmd.strip():
        case_sensitive = 0
        header_key = "query_string"
        cmd += '\t\t\tmatch_variables ' + \
            str(case_sensitive) + ' "' + header_key + \
            '" "' + query_string_cmd + '";\n'

    if cookie_cmd.strip():
        case_sensitive = 0
        header_key = "cookie"
        cmd += '\t\t\tmatch_variables ' + \
            str(case_sensitive) + ' "' + header_key + \
            '" "' + cookie_cmd + '";\n'

    log_info('[build_conditions] cmd of conditions: %s' % (cmd.strip()))
    return cmd


'''
rule_config, rule config stored in dict
backend_section_rule, ups for rule
backend_section_rule_hotconf[servername],ups for rule(hotconf)i
default_server_backend, default_server_backend_new,#server backends without servername
rule_backend, rule_backend_new, #server backends with servername
'''
def build_rule_backend(**kwargs):
    #log_info("build_rule_backend")
    listen = kwargs["listen"]
    slb_info = kwargs["slb_info"]
    rule = kwargs["rule"]
    rule_config = kwargs["rule_config_with_servername"]
    default_server_rule_config = kwargs["rule_config_without_servername"]
    backend_section_rule_hotconf = kwargs["hotconf_upstream_for_rule"]
    rule_backend = kwargs["loc_for_rule_with_servername"]
    rule_backend_new = kwargs["hotconf_loc_for_rule_with_servername"]
    rs_pool = kwargs["rs_pool"]
    ssl_on = kwargs["ssl_switch"]
    http2_on = kwargs["http2_switch"]
    ssl_keyless_server = kwargs["ssl_keyless_server"]
    cert = kwargs["cert"]
    ssl_config_vip = kwargs["ssl_config_vip"]
    ssl_certificate_vip = kwargs["ssl_certificate_vip"]
    ssl_ca_cert_vip = kwargs["ssl_ca_cert_vip"]
    ssl_ca_cert_new_vip = kwargs["ssl_ca_cert_new_vip"]
    lb_tunnel_id = kwargs["lb_tunnel_id"]
    listener_id = kwargs["listener_id"]

    proxy_ignore_client_abort = 'off'
    proxy_keepalive = 'off'
    flag = 0
    protocol = build_protocol(listen)

    if is_eppu(listen):
        lnport, ret = get_port_from_eppu(listen)
        if lnport == None:#just logging this case
            log_error("gen_vip_section [Eppu] can not get port for rule")
            raise Exception, 'get_port_from_eppu [Eppu] error' 
        rs_pool_name = str(lnport)
    else:
        rs_pool_name = str(listen.port) #port + rule name
    rs_pool_port =  None
    realservers = rule.realserver

    pool_check = None
    sticky = None
    scheduler = None

    backend_section_rule = ""
    default_server_backend = ""
    default_server_backend_new = ""
    backend_protocol = build_backend_protocol(listen)
    slb_rule_id = DEFAULT_ID_VALUE
    slb_pool_id = DEFAULT_ID_VALUE

    if rule.HasField('domain'):
        server_name = rule.domain
    else:
        server_name = ""

    if rule.HasField('url'):
        url = rule.url
    else:
        url = "/"

    if rule.HasField("rule_global_id"):
        slb_rule_id = rule.rule_global_id
    if rule.HasField("rs_pool_name"):
        slb_pool_id = rule.rs_pool_name

    if rule.config.HasField('sticky_session'):
        sticky = rule.config.sticky_session

    if rule.config.HasField('scheduler'):
        scheduler = rule.config.scheduler

    if rule.config.HasField('check') and rule.config.check.HasField('check_type') and \
            (common_pb2.HealthCheck.HTTP == rule.config.check.check_type or
             common_pb2.HealthCheck.TCP == rule.config.check.check_type):
        pool_check = rule.config.check
        if not pool_check.HasField('uri'):
            pool_check.uri = "/"

    rs_pool_name = rs_pool_name + "_" + rule.name

    if rs_pool_name not in rs_pool:
        rs_pool[rs_pool_name] = {'realservers': realservers}
    else:
        rs_pool[rs_pool_name]['realservers'] = realservers

    if rule.HasField('is_url_regex'):
        rs_pool[rs_pool_name]['is_url_regex'] = rule.is_url_regex
    else:
        rs_pool[rs_pool_name]['is_url_regex'] = common_pb2.OFF
        #pass

    if rule.config.HasField('sticky_session'):
        rs_pool[rs_pool_name]['sticky_session'] = sticky
    else:
        if "sticky_session" in rs_pool[rs_pool_name]:
            rs_pool[rs_pool_name].pop('sticky_session')

    if rule.config.HasField('check') and rule.config.check.HasField('check_type') and \
            (common_pb2.HealthCheck.HTTP == rule.config.check.check_type or
             common_pb2.HealthCheck.TCP == rule.config.check.check_type):
        rs_pool[rs_pool_name]['check'] = pool_check
    else:
        if "check" in rs_pool[rs_pool_name]:
            rs_pool[rs_pool_name].pop('check')

    if rule.config.HasField('scheduler'):
        rs_pool[rs_pool_name]['scheduler'] = scheduler
    else:
        rs_pool[rs_pool_name]['scheduler'] = None

    if rule.HasField("ignore_client_abort") and rule.ignore_client_abort == common_pb2.ON:
        proxy_ignore_client_abort = 'on'

    if rule.HasField("upstream_keepalive") and rule.upstream_keepalive.enable == common_pb2.ON:
        if rule.upstream_keepalive.HasField("keepalive") and rule.upstream_keepalive.keepalive > UPS_KEEPALIVE_DEFAULT:
            proxy_keepalive = 'on'
            rs_pool[rs_pool_name]["keepalive"] = rule.upstream_keepalive.keepalive
        else:
            rs_pool[rs_pool_name]["keepalive"] = UPS_KEEPALIVE_DEFAULT

        if rule.upstream_keepalive.HasField("keepalive_timeout") and rule.upstream_keepalive.keepalive_timeout > UPS_KEEPALIVE_TIMEOUT_DEFAULT:
            rs_pool[rs_pool_name]["keepalive_timeout"] = rule.upstream_keepalive.keepalive_timeout
        else:
            rs_pool[rs_pool_name]["keepalive_timeout"] = UPS_KEEPALIVE_TIMEOUT_DEFAULT
        if rule.upstream_keepalive.HasField("keepalive_requests"):
            rs_pool[rs_pool_name]["keepalive_requests"] = rule.upstream_keepalive.keepalive_requests
        else:
            rs_pool[rs_pool_name]["keepalive_requests"] = UPS_KEEPALIVE_MAX_REQUESTS

    ''' !!!!!!'''
    ''' new added features rendering default_server_rule_config or rule_config for agent backend '''
    if server_name != "" and server_name not in rule_config:
        rule_config[server_name] = {}
        if protocol == 'https':
            cert = build_rule_https_cfg(listen, rule, rule_config, ssl_on, http2_on, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip)

    flag = build_rule_wilconf_phase1(rule, rule_config, default_server_rule_config)    

    run_rendering_callbacks(rendering_callbacks, listen, server_name, rule, default_server_rule_config, rule_config)

    vipserver_backend = ""

    if isEmptyRspool(realservers):
        log_info("[build_rule_backend] upstream{ %s } " % rs_pool_name)
        backend_section_rule += genEmptyUpstreamConfig(rs_pool_name)
        backend_section_rule_hotconf[rs_pool_name] = genEmptyUpstreamConfig_(rs_pool_name)
    else:

        if server_name != "":
            backend_section_rule_hotconf[rs_pool_name] = genUpstreamConfig_(rs_pool_name, rs_pool[rs_pool_name],
                                                      listen.address, server_name,
                                                      get_vport(listen, listen),
                                                      lb_tunnel_id, listener_id, protocol, url, slb_rule_id, slb_pool_id)
            backend_section_rule +=  "\n\tupstream " + rs_pool_name + "{\n" + backend_section_rule_hotconf[rs_pool_name] + "\t}\n"
        else:
            backend_section_rule_hotconf[rs_pool_name] = genUpstreamConfig_(rs_pool_name, rs_pool[rs_pool_name],
                                                      listen.address, None,
                                                      get_vport(listen, listen),
                                                      lb_tunnel_id, listener_id, protocol, url, slb_rule_id, slb_pool_id)
            backend_section_rule +=  "\n\tupstream " + rs_pool_name + "{\n" + backend_section_rule_hotconf[rs_pool_name] + "\t}\n"
    if server_name == "":
        if rs_pool[rs_pool_name].has_key('is_url_regex') and (rs_pool[rs_pool_name]['is_url_regex'] == common_pb2.ON):
            tmpurl = '~' + url
        else:
            tmpurl = url
        if listen.HasField("is_app_rule") and listen.is_app_rule == 1 and rule.HasField("priority"):
            default_server_backend += "\t\tprio_location %d {\n" % rule.priority
            default_server_backend += build_conditions(rule)
            default_server_backend += build_actions(listen, rule)
        else:
            default_server_backend += ("location %s {\n" % tmpurl) if default_server_backend == "" else ("\t\tlocation %s {\n" % tmpurl)
        if proxy_ignore_client_abort == 'on':
            default_server_backend += "\t\t\tslb_ignore_client_abort on;\n"

        if proxy_keepalive == 'on':
            default_server_backend += "\t\t\tslb_upstream_keepalive on;\n"
        else:
            default_server_backend += "\t\t\tslb_upstream_keepalive off;\n"
        default_server_backend += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"

        default_server_backend += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend += slb_info
        default_server_backend += "\t\t\tset $slbups " + rs_pool_name + ";\n"
        default_server_backend += "\t\t\tproxy_pass http://$slbups;\n"
        default_server_backend += "\t\t\tsession_sticky_hide_cookie upstream=" + rs_pool_name + ";\n"
        if flag == SLB_SECURE_HTTPONLY_COOKIE:
            default_server_backend += "\t\t\tslb_secure_cookie on;\n"
            default_server_backend += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_HTTPONLY_COOKIE:
            default_server_backend += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_SECURE_COOKIE:
            default_server_backend += "\t\t\tslb_secure_cookie on;\n"
        default_server_backend += "\t\t}\n"

        if listen.HasField("is_app_rule") and listen.is_app_rule == 1 and rule.HasField("priority"):
            default_server_backend_new += "\t\tprio_location %d {\n" % rule.priority
            default_server_backend_new += build_conditions(rule)
            default_server_backend_new += build_actions(listen, rule)
        else:
            default_server_backend_new += ("location %s {\n" % tmpurl) if default_server_backend == "" else ("\t\tlocation %s {\n" % tmpurl)

        if backend_protocol != "http":
            default_server_backend_new += "\t\t\tups_scheme %s;\n" % backend_protocol
        if proxy_ignore_client_abort == 'on':
            default_server_backend_new += "\t\t\tslb_ignore_client_abort on;\n"

        if proxy_keepalive == 'on':
            default_server_backend_new += "\t\t\tslb_upstream_keepalive on;\n"
        else:
            default_server_backend_new += "\t\t\tslb_upstream_keepalive off;\n"
        default_server_backend_new += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"

        default_server_backend_new += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
        default_server_backend_new += "\t\t\tups " + rs_pool_name + ";\n"
        default_server_backend_new += "\t\t\tslb_hide_cookie upstream=" + rs_pool_name + ";\n"
        if flag == SLB_SECURE_HTTPONLY_COOKIE:
            default_server_backend_new += "\t\t\tslb_secure_cookie on;\n"
            default_server_backend_new += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_HTTPONLY_COOKIE:
            default_server_backend_new += "\t\t\tslb_httponly_cookie on;\n"
        if flag == SLB_SECURE_COOKIE:
            default_server_backend_new += "\t\t\tslb_secure_cookie on;\n"
        default_server_backend_new += "\t\t}\n"
    else:
        tmp_backend = ""
        tmp_backend_new = ""
        if server_name in rule_backend:
            tmp_backend = rule_backend[server_name]
            tmp_backend_new = rule_backend_new[server_name]
        if vipserver_backend == "":
            #if rs_pool[rs_pool_name].has_key('is_url_regex'):
            if rs_pool[rs_pool_name].has_key('is_url_regex') and (rs_pool[rs_pool_name]['is_url_regex'] == common_pb2.ON):
                tmpurl = '~' + url
            else:
                tmpurl = url
            tmp_backend += ("location %s {\n" % tmpurl) if tmp_backend == "" else ("\t\tlocation %s {\n" % tmpurl)
            if proxy_ignore_client_abort == 'on':
                tmp_backend += "\t\t\tslb_ignore_client_abort on;\n"
            if proxy_keepalive == 'on':
                tmp_backend += "\t\t\tslb_upstream_keepalive on;\n"
            else:
                tmp_backend += "\t\t\tslb_upstream_keepalive off;\n"
            tmp_backend += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
            tmp_backend += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
            tmp_backend += slb_info
            tmp_backend += "\t\t\tset $slbups " + rs_pool_name + ";\n"
            tmp_backend += "\t\t\tproxy_pass %s://$slbups;\n" % backend_protocol
            tmp_backend += "\t\t\tsession_sticky_hide_cookie upstream=" + rs_pool_name + ";\n"
            if flag == SLB_SECURE_HTTPONLY_COOKIE:
                tmp_backend  += "\t\t\tslb_secure_cookie on;\n"
                tmp_backend  += "\t\t\tslb_httponly_cookie on;\n"
            if flag == SLB_HTTPONLY_COOKIE:
                tmp_backend  += "\t\t\tslb_httponly_cookie on;\n"
            if flag == SLB_SECURE_COOKIE:
                tmp_backend  += "\t\t\tslb_secure_cookie on;\n"
            tmp_backend += "\t\t}\n"

            tmp_backend_new += ("location %s {\n" % tmpurl) if tmp_backend == "" else ("\t\tlocation %s {\n" % tmpurl)             
            if backend_protocol != "http":
                tmp_backend_new += "\t\t\tups_scheme %s;\n" % backend_protocol
            if proxy_ignore_client_abort == 'on':
                tmp_backend_new += "\t\t\tslb_ignore_client_abort on;\n"
            if proxy_keepalive == 'on':
                tmp_backend_new += "\t\t\tslb_upstream_keepalive on;\n"
            else:
                tmp_backend_new += "\t\t\tslb_upstream_keepalive off;\n"
            tmp_backend_new += "\t\t\tslb_rule_id " + slb_rule_id + ";\n"
            tmp_backend_new += "\t\t\tslb_pool_id " + slb_pool_id + ";\n"
            tmp_backend_new += "\t\t\tups " + rs_pool_name + ";\n"
            tmp_backend_new += "\t\t\tslb_hide_cookie upstream=" + rs_pool_name + ";\n"
            if flag == SLB_SECURE_HTTPONLY_COOKIE:
                tmp_backend_new  += "\t\t\tslb_secure_cookie on;\n"
                tmp_backend_new  += "\t\t\tslb_httponly_cookie on;\n"
            if flag == SLB_HTTPONLY_COOKIE:
                tmp_backend_new  += "\t\t\tslb_httponly_cookie on;\n"
            if flag == SLB_SECURE_COOKIE:
                tmp_backend_new  += "\t\t\tslb_secure_cookie on;\n"
            tmp_backend_new += "\t\t}\n"
        else:
            tmp_backend += vipserver_backend
        rule_backend[server_name] = tmp_backend
        rule_backend_new[server_name] = tmp_backend_new

    #log_info("build_rule_backend end ")
    result = {"upstream_for_rule" : backend_section_rule,
              "loc_for_rule_without_servername" : default_server_backend,
              "hotconf_loc_for_rule_without_servername" : default_server_backend_new,
              "cert" : cert}
    return result

wildconf_callbacks = {}
wildconf_rule_callbacks = {}
def reg_wilconf_callbacks(wilddict,k,v):
    if wilddict.has_key(k):
        return
    else:
        wilddict[k]=v
        log_info("[reg_wilconf_callbacks] %s" % k)

wildconf_types = {}
#wildconf_position = {}
def reg_wilconf_attr(wildconf_dict, k,v):
    #register the attributes of wildconf , such as types and locations of config block.
    if wildconf_dict.has_key(k):
        return
    else:
        wildconf_dict[k] = v
    log_info("[reg_wilconf_attr] %s %s" % (k,v))

def xfp_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""
    #sanity check
    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new
    #xff is write to config file already
    if listen.config.HasField("x_forwarded_for") and listen.config.x_forwarded_for == common_pb2.ON:
        wild_config_new += "\n\t\tproxy_set_header X-Forwarded-For on;"
    #x_forwarded_client_port for client port
    if rule != None and rule.has_key("x_forwarded_client_port") and protocol != 'tcps':
        if rule.has_key("x_forwarded_client_port"): #only addkey when switch is ON in rendering callback
            wild_config += "\n\t\tproxy_set_header X-Forwarded-Client-Port $remote_port;"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-Client-Port on;"
    elif listen is not None:
        if listen.HasField("x_forwarded_client_port") and listen.x_forwarded_client_port  == common_pb2.ON:
            wild_config += "\n\t\tproxy_set_header X-Forwarded-Client-Port $remote_port;"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-Client-Port on;"
    #x_forwarded_port for vport
    if rule != None and rule.has_key("x_forwarded_port") and protocol != 'tcps':
        if rule.has_key("x_forwarded_port"):
            wild_config += "\n\t\tproxy_set_header X-Forwarded-Port $slb_vport;"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-Port on;"
    elif listen is not None:
        if listen.HasField("x_forwarded_port") and listen.x_forwarded_port == common_pb2.ON:
            wild_config += "\n\t\tproxy_set_header X-Forwarded-Port $slb_vport;"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-Port on;"

    return wild_config, wild_config_new

def quic_relation_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        log_info('[Warning] Alt-Svc is set for %s, listener %s' % (protocol, listen.listener_id))
        return wild_config, wild_config_new

    if listen is not None:
        if listen.HasField("quic_relation") and listen.quic_relation.switch == common_pb2.ON:
            config = genQuicRelationConfig(listen.quic_relation)
            wild_config += "\n\t\t" + config + ";"
            wild_config_new += "\n\t\t" + config + ";"

    return wild_config, wild_config_new

def qps_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    if listen is not None:
        vip = "0.0.0.0"
        if listen.HasField("address"):
            vip = listen.address
    else:
        return wild_config, wild_config_new

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if listen.config.sla_config.HasField('qps'):
        try:
            if is_eppu(listen):
                dc = get_dc_from_l7portinfos(listen, True)
                if dc < 1:
                    log_error("gen_vip_section [Eppu] wrong dc value")
            else:
                dc = int(device_group.device_count.plugged_count)
            if dc < 1:
                wild_config += "\n\t\tset $vip_addr " + vip + "qpsfailed;"
                rate_pool_proxy = DEFAULT_QPS_SLA
            else:
                if dc > 1:
                    dc = dc - 1
                if int(listen.config.sla_config.qps) > 0:
                    rate_pool_proxy = int(listen.config.sla_config.qps) 
                else:
                    rate_pool_proxy = DEFAULT_QPS_SLA
                wild_config += "\n\t\tset $vip_addr " + vip + ";"
        except:
            wild_config += "\n\t\tset $vip_addr " + vip + "qpsfailed;"
            rate_pool_proxy = DEFAULT_QPS_SLA

        wild_config += "\n\t\tslb_limit_req zone=slb_req5k rate=" + str(rate_pool_proxy) + "r/s nobucket;"
        wild_config_new += "\n\t\tslb_limit_req_rate " + str(rate_pool_proxy) + ";"
    else:
        wild_config += "\n\t\tset $vip_addr " + vip + "qpsfailed;"
        rate_pool_proxy = DEFAULT_QPS_SLA
        wild_config += "\n\t\tslb_limit_req zone=slb_req5k rate=" + str(rate_pool_proxy) + "r/s nobucket;"
        wild_config_new += "\n\t\tslb_limit_req_rate " + str(rate_pool_proxy) + ";"
    return wild_config, wild_config_new


def hsts_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck 
    if rule != None and listen != None:
        if not rule.has_key("hsts") and listen.config.HasField("hsts"):
            log_info("[hsts_callback] fail to Sync between rule and listen")
            return wild_config, wild_config_new
    if rule != None and rule.has_key("hsts"):
        if isHstsEnabled(rule["hsts"]):
            wild_config_new += "\n\t\t" + genHstsConfig(rule["hsts"])
            wild_config += "\n\t\t" + genHstsNginxConfig(rule["hsts"])
    elif listen != None:
        if listen.config.HasField("hsts") and isHstsEnabled(listen.config.hsts):
            wild_config_new += "\n\t\t" + genHstsConfig(listen.config.hsts)
            wild_config += "\n\t\t" + genHstsNginxConfig(listen.config.hsts)
    return wild_config, wild_config_new


def idle_timeout_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)

    # precheck 
    if rule != None and listen != None and protocol != 'tcps':
        if not rule.has_key("idle_timeout") and listen.config.HasField("idle_timeout"):
            log_info("[idle_timeout_callback] fail to Sync between rule and listen")
            return wild_config, wild_config_new

    if rule != None and rule.has_key("idle_timeout") and protocol != 'tcps':
        wild_config += "\n\t\tkeepalive_timeout " + str(rule["idle_timeout"]) + ";"
        wild_config_new += "\n\t\tslb_keepalive_timeout " + str(rule["idle_timeout"]) + ";"
    elif listen is not None:
        if listen.config.HasField("idle_timeout") and listen.config.idle_timeout > 0:
            if protocol == 'tcps':
                wild_config += "\n\t\tproxy_timeout " + str(listen.config.idle_timeout) + ";"
            else:
                wild_config += "\n\t\tkeepalive_timeout " + str(listen.config.idle_timeout) + ";"
            wild_config_new += "\n\t\tslb_keepalive_timeout " + str(listen.config.idle_timeout) + ";"
    return wild_config, wild_config_new


def cust_headers_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck
    if rule != None and listen != None and len(listen.httpWildConfigInfoList) > 0:
        if not rule.has_key("httpWildConfigInfoList") and len(listen.httpWildConfigInfoList) > 0:
            log_info("[cust_headers_callback] fail to Sync between rule and listen")
            return wild_config, wild_config_new

    if rule != None and rule.has_key("httpWildConfigInfoList"):
        hdconf = genCustHeadersConfig(rule["httpWildConfigInfoList"])
        if len(hdconf) > 0:
            wild_config += "\n\t\tcust_headers " + str(hdconf) + ";"
    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        hdconf = genCustHeadersConfig(listen.httpWildConfigInfoList)
        if len(hdconf) > 0:
            wild_config += "\n\t\tcust_headers " + str(hdconf) + ";"

    return wild_config, wild_config_new

def slb_xtrace_type_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""
    wild_node = None
    wildconf_key = "slb_xtrace_type"

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if rule != None and rule.has_key("httpWildConfigInfoList"):
        wild_node = get_wildconfig(wildconf_key,rule["httpWildConfigInfoList"])
    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        wild_node = get_wildconfig(wildconf_key, listen.httpWildConfigInfoList)

    if wild_node != None:
        if (wild_node.switch == common_pb2.ON) and (wild_node.value):
            wild_config += "\n\t\tslb_xtrace_type " + str(wild_node.value.lower()) + ";"
            wild_config_new += "\n\t\tslb_xtrace_type " + str(wild_node.value.lower()) + ";"
        else:
            wild_config += "\n\t\tslb_xtrace_type none;"
            wild_config_new += "\n\t\tslb_xtrace_type none;"

    return wild_config, wild_config_new

def slb_xtrace_sample_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""
    wild_node = None
    wildconf_key = "slb_xtrace_sample"

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck
    if rule != None and rule.has_key("httpWildConfigInfoList"):
        wild_node = get_wildconfig(wildconf_key,rule["httpWildConfigInfoList"])
    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        wild_node = get_wildconfig(wildconf_key, listen.httpWildConfigInfoList)

    if wild_node != None:
        if (wild_node.switch == common_pb2.ON) and (wild_node.value) and (wild_node.value > 0):
            wild_config += "\n\t\tslb_xtrace_sample " + str(wild_node.value) + ";"
            wild_config_new += "\n\t\tslb_xtrace_sample " + str(wild_node.value) + ";"

    return wild_config, wild_config_new

def customize_header_log_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if rule != None and rule.has_key("httpWildConfigInfoList"):
        on = get_wildconfig("customize_header_log",rule["httpWildConfigInfoList"])
        if on != None:
            if (on.switch == common_pb2.ON) and (on.value) and (on.value.lower() == 'on'):
                wild_config += "\n\t\tslb_customized_headers on;"
                wild_config_new += "\n\t\tslb_customized_headers on;"
            else:
                wild_config += "\n\t\tslb_customized_headers off;"
                wild_config_new += "\n\t\tslb_customized_headers off;"

    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        on = get_wildconfig("customize_header_log", listen.httpWildConfigInfoList)
        if on != None:
            if (on.switch == common_pb2.ON) and (on.value) and (on.value.lower() == 'on'):
                wild_config += "\n\t\tslb_customized_headers on;"
                wild_config_new += "\n\t\tslb_customized_headers on;"
            else:
                wild_config += "\n\t\tslb_customized_headers off;"
                wild_config_new += "\n\t\tslb_customized_headers off;"

    return wild_config, wild_config_new

def upstream_timeout_and_retries_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if rule != None and rule.has_key("httpWildConfigInfoList"):
        time = get_wildconfig("backend_connect_timeout",rule["httpWildConfigInfoList"])
        if time != None and time.switch == common_pb2.ON:
            wild_config += "\n\t\tbackend_connect_timeout " + time.value + ";"
            wild_config_new += "\n\t\tbackend_connect_timeout " + time.value + ";"

        retries = get_wildconfig("backend_connect_retries",rule["httpWildConfigInfoList"])
        if retries != None and retries.switch == common_pb2.ON:
            wild_config += "\n\t\tbackend_connect_retries " + retries.value + ";"
            wild_config_new += "\n\t\tbackend_connect_retries " + retries.value + ";"

    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        time = get_wildconfig("backend_connect_timeout", listen.httpWildConfigInfoList)
        if time != None and time.switch == common_pb2.ON:
            wild_config += "\n\t\tbackend_connect_timeout " + time.value + ";"
            wild_config_new += "\n\t\tbackend_connect_timeout " + time.value + ";"

        retries = get_wildconfig("backend_connect_retries",listen.httpWildConfigInfoList)
        if retries != None and retries.switch == common_pb2.ON:
            wild_config += "\n\t\tbackend_connect_retries " + retries.value + ";"
            wild_config_new += "\n\t\tbackend_connect_retries " + retries.value + ";"
    return wild_config, wild_config_new

def x_forwarded_eip_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if rule != None and rule.has_key("httpWildConfigInfoList"):
        x_forwarded_eip = get_wildconfig("x_forwarded_eip",rule["httpWildConfigInfoList"])
        if x_forwarded_eip != None and x_forwarded_eip.switch == common_pb2.ON:
            wild_config += "\n\t\tproxy_set_header X-Forwarded-EIP " + x_forwarded_eip.value + ";"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-EIP " + x_forwarded_eip.value + ";"

    elif listen != None and len(listen.httpWildConfigInfoList) > 0:
        x_forwarded_eip = get_wildconfig("x_forwarded_eip", listen.httpWildConfigInfoList)
        if x_forwarded_eip != None and x_forwarded_eip.switch == common_pb2.ON:
            wild_config += "\n\t\tproxy_set_header X-Forwarded-EIP " + x_forwarded_eip.value + ";"
            wild_config_new += "\n\t\tproxy_set_header X-Forwarded-EIP " + x_forwarded_eip.value + ";"
            
    return wild_config, wild_config_new

def http1_max_request_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck
    if listen != None:
        if listen.config.HasField("http1_max_request") and listen.config.http1_max_request >= 0:
            wild_config += "\n\t\tkeepalive_requests" + str(listen.config.http1_max_request) + ";"
    return wild_config, wild_config_new


def http2_max_request_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck
    if listen != None:
        if listen.config.HasField("http2_max_request") and listen.config.http2_max_request >= 0:
            wild_config += "\n\t\thttp2_max_requests" + str(listen.config.http2_max_request) + ";"
    return wild_config, wild_config_new


def read_timeout_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    # precheck
    if rule != None and listen != None:
        if not rule.has_key("read_timeout") and listen.config.HasField("read_timeout"):
            log_info("[read_timeout_callback] fail to Sync between rule and listen")
    if rule != None and rule.has_key("read_timeout"):
            wild_config += "\n\t\tproxy_read_timeout " + str(rule["read_timeout"]) + ";"
            wild_config_new += "\n\t\tslb_proxy_read_timeout " + str(rule["read_timeout"]) + ";"
    elif listen != None:
        if listen.config.HasField("read_timeout") and listen.config.read_timeout > 0:
            wild_config += "\n\t\tproxy_read_timeout " + str(listen.config.read_timeout) + ";"
            wild_config_new += "\n\t\tslb_proxy_read_timeout " + str(listen.config.read_timeout) + ";"
    return wild_config, wild_config_new

'''
def proxy_http_version_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""
    if listen != None:
        if listen.config.HasField("proxy_http_version") and \
                (listen.config.proxy_http_version == 1.1 or \
                listen.config.proxy_http_version == 1.0 or \
                listen.config.proxy_http_version == "auto"):
            wild_config += "\n\t\tproxy_http_version " + str(listen.config.proxy_http_version) + ";"
            wild_config_new += "\n\t\tproxy_http_version " + str(listen.config.proxy_http_version) + ";"
    return wild_config, wild_config_new

def gzip_clear_etag_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""
    if listen != None and listen.config.HasField("gzip_clear_etag"):
        if listen.config.gzip_clear_etag == common_pb2.OFF:
            gzip_etag = "\n\t\tgzip_clear_etag off;"
        elif listen.config.gzip_clear_etag == common_pb2.ON:
            gzip_etag = "\n\t\tgzip_clear_etag on;"
        if len(gzip_etag) > 0:
            wild_config += "\n\t\tgzip_clear_etag" + str(listen.config.read_timeout) + ";"
            wild_config_new += "\n\t\tgzip_clear_etag" + str(listen.config.read_timeout) + ";"
    return wild_config, wild_config_new
'''


def forward_port_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    if protocol == 'tcps':
        return wild_config, wild_config_new

    if listen != None and listen.HasField("forward_port"):
        rcode = 302
        if len(listen.httpWildConfigInfoList) > 0:
            tcode = get_wildconfig("redirect_code", listen.httpWildConfigInfoList)
            if tcode != None:
                if int(tcode.value) == 301 or int(tcode.value) == 302 or int(tcode.value) == 303 or int(tcode.value) == 307 or int(tcode.value) == 308:
                    rcode = int(tcode.value)
        if listen.forward_port > 0 and listen.forward_port < 65536:
            wild_config += build_forward_port_conf_file(str(listen.forward_port), str(rcode))
            wild_config_new += "\n\t\tslb_redirect_https " + str(listen.forward_port) + " " + str(rcode) + ";"

    elif rule != None and rule.has_key("forward_port"):
        rcode = 302
        if rule.has_key("httpWildConfigInfoList"):
            tcode = get_wildconfig("redirect_code", rule["httpWildConfigInfoList"])
            if tcode != None:
                if int(tcode.value) == 301 or int(tcode.value) == 302 or int(tcode.value) == 303 or int(tcode.value) == 307 or int(tcode.value) == 308:
                    rcode = int(tcode.value)
        wild_config += build_forward_port_conf_file(str(rule["forward_port"]), str(rcode))
        wild_config_new += "\n\t\tslb_redirect_https " + str(rule["forward_port"]) + " " + str(rcode) + ";"
    return wild_config, wild_config_new


def ssl_dyn_rec_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)

    # precheck 
    if rule != None and listen != None and protocol != 'tcps':
        if not (rule.has_key("ssl_dyn_rec_timeout") and rule.has_key("ssl_dyn_rec_size_lo") \
           and rule.has_key("ssl_dyn_rec_size_hi") and rule.has_key("ssl_dyn_rec_threshold") and rule.has_key("ssl_buffer_size")) \
           and listen.HasField("ssl_dyn_rec"):
            log_info("[ssl_dyn_rec_callback] fail to Sync between rule and listen")
    if protocol != 'tcps' and rule is not None and rule.has_key("ssl_dyn_rec_timeout") and rule.has_key("ssl_dyn_rec_size_lo") \
           and rule.has_key("ssl_dyn_rec_size_hi") and rule.has_key("ssl_dyn_rec_threshold") and rule.has_key("ssl_buffer_size"):
            wild_config += "\n\t\tssl_dyn_rec_timeout " + str(rule["ssl_dyn_rec_timeout"]) + ";"
            wild_config += "\n\t\tssl_dyn_rec_size_lo " + str(rule["ssl_dyn_rec_size_lo"]) + ";"
            wild_config += "\n\t\tssl_dyn_rec_size_hi " + str(rule["ssl_dyn_rec_size_hi"]) + ";"
            wild_config += "\n\t\tssl_buffer_size " + str(rule["ssl_buffer_size"]) + ";"
            wild_config += "\n\t\tssl_dyn_rec_threshold " + str(rule["ssl_dyn_rec_threshold"]) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_timeout " + str(rule["ssl_dyn_rec_timeout"]) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_size_lo " + str(rule["ssl_dyn_rec_size_lo"]) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_size_hi " + str(rule["ssl_dyn_rec_size_hi"]) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_threshold " + str(rule["ssl_dyn_rec_threshold"]) + ";"
    elif listen is not None:
        if listen.HasField("ssl_dyn_rec") and listen.ssl_dyn_rec.HasField("timeout") \
           and listen.ssl_dyn_rec.HasField("size_lo") and listen.ssl_dyn_rec.HasField("size_hi") \
           and listen.ssl_dyn_rec.HasField("threshold"):
            wild_config += "\n\t\tssl_dyn_rec_timeout " + str(listen.ssl_dyn_rec.timeout) + ";"
            wild_config += "\n\t\tssl_dyn_rec_size_lo " + str(listen.ssl_dyn_rec.size_lo) + ";"
            wild_config += "\n\t\tssl_dyn_rec_size_hi " + str(listen.ssl_dyn_rec.size_hi) + ";"
            wild_config += "\n\t\tssl_buffer_size " + str(listen.ssl_dyn_rec.ssl_buffer_size) + ";"
            wild_config += "\n\t\tssl_dyn_rec_threshold " + str(listen.ssl_dyn_rec.threshold) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_timeout " + str(listen.ssl_dyn_rec.timeout) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_size_lo " + str(listen.ssl_dyn_rec.size_lo) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_size_hi " + str(listen.ssl_dyn_rec.size_hi) + ";"
            #wild_config_new += "\n\t\tssl_dyn_rec_threshold " + str(listen.ssl_dyn_rec.threshold) + ";"
    return wild_config, wild_config_new


def client_ip_port_via_toa_callback(listen, rule):
    wild_config = ""
    wild_config_new = ""

    if listen is None:
        log_info("invalid listen in client_ip_port_via_toa_callback")
        return wild_config, wild_config_new

    if len(listen.httpWildConfigInfoList) < 0:
        return wild_config, wild_config_new

    on = get_wildconfig("forward_client_ip_port_via_toa", listen.httpWildConfigInfoList)
    if on is None:
        return wild_config, wild_config_new

    protocol = build_protocol(listen)
    if protocol != 'tcps':
        log_info("forward_client_ip_port_via_toa directive received for protocol %s" % protocol)
        return wild_config, wild_config_new

    if (on.switch == common_pb2.ON) and on.value and (on.value.lower() == 'on'):
        wild_config += "\n\t\tforward_client_ip_port_via_toa on;"
    else:
        wild_config += "\n\t\tforward_client_ip_port_via_toa off;"

    return wild_config, wild_config_new


reg_wilconf_callbacks(wildconf_callbacks,'qps',qps_callback)
reg_wilconf_callbacks(wildconf_callbacks,'hsts',hsts_callback)
reg_wilconf_callbacks(wildconf_callbacks,'http1_max_request',http1_max_request_callback)
reg_wilconf_callbacks(wildconf_callbacks,'http2_max_request',http2_max_request_callback)
reg_wilconf_callbacks(wildconf_callbacks,'idletimeout',idle_timeout_callback)
reg_wilconf_callbacks(wildconf_callbacks,'readtimeout',read_timeout_callback)
#reg_wilconf_callbacks(wildconf_callbacks,'httpver',proxy_http_version_callback)
#reg_wilconf_callbacks(wildconf_callbacks,'gzipclretag',gzip_clear_etag_callback)
reg_wilconf_callbacks(wildconf_callbacks,'fwdport',forward_port_callback)
reg_wilconf_callbacks(wildconf_callbacks,'ssl_dyn_rec',ssl_dyn_rec_callback)
reg_wilconf_callbacks(wildconf_callbacks,'xfp',xfp_callback)
reg_wilconf_callbacks(wildconf_callbacks,'cust_headers',cust_headers_callback)
reg_wilconf_callbacks(wildconf_callbacks,'customize_header_log',customize_header_log_callback)
reg_wilconf_callbacks(wildconf_callbacks,'upstream_timeout_and_retries',upstream_timeout_and_retries_callback)
reg_wilconf_callbacks(wildconf_callbacks, 'forward_client_ip_port_via_toa', client_ip_port_via_toa_callback)
reg_wilconf_callbacks(wildconf_callbacks,'slb_xtrace_type',slb_xtrace_type_callback)
reg_wilconf_callbacks(wildconf_callbacks,'slb_xtrace_sample',slb_xtrace_sample_callback)
#for quic_relation
reg_wilconf_callbacks(wildconf_callbacks,'quic_relation', quic_relation_callback)
reg_wilconf_callbacks(wildconf_callbacks,'x_forwarded_eip',x_forwarded_eip_callback)

#when a callback added here, we need add the
#corresponding  register_rendering_callbacks
reg_wilconf_callbacks(wildconf_rule_callbacks,'qps',qps_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'hsts',hsts_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'idletimeout',idle_timeout_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'readtimeout',read_timeout_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'fwdport',forward_port_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'ssl_dyn_rec',ssl_dyn_rec_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'xfp',xfp_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'cust_headers',cust_headers_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'customize_header_log',customize_header_log_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'upstream_timeout_and_retries',upstream_timeout_and_retries_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'slb_xtrace_type', slb_xtrace_type_callback)
reg_wilconf_callbacks(wildconf_rule_callbacks,'slb_xtrace_sample', slb_xtrace_sample_callback)
=======
reg_wilconf_callbacks(wildconf_rule_callbacks,'x_forwarded_eip',x_forwarded_eip_callback)

>>>>>>> add header x_forwarded_eip
reg_wilconf_attr(wildconf_types,"customize_header_log","string")
reg_wilconf_attr(wildconf_types,"backend_connect_retries","integer")
reg_wilconf_attr(wildconf_types,"backend_connect_timeout","integer")
reg_wilconf_attr(wildconf_types,"redirect_code","integer")
<<<<<<< HEAD
reg_wilconf_attr(wildconf_types, "forward_client_ip_port_via_toa", "string")
reg_wilconf_attr(wildconf_types,"slb_xtrace_type","string")
reg_wilconf_attr(wildconf_types,"slb_xtrace_sample","integer")
=======
reg_wilconf_attr(wildconf_types,"x_forwarded_eip","string")
>>>>>>> add header x_forwarded_eip
'''
new_wild_config_dict, build_listen_wildconf_phase1
general_wild_config, can be default_server_rule_config['wild_config']
    or rule_config[server_name]['wild_config'] in
    build_rule_wilconf_phase1
wil_callbacks, can be listen's registed callbacks or rule's
'''
def build_wildconf(listen, rule, default_wild_config,  wil_callbacks):
    #log_info("build_wildconf start")
    wild_config = ""
    wild_config_new = ""

    protocol = build_protocol(listen)
    #run callbacks, k should not in wildconf or dup item will be created 
    for k,v in wil_callbacks.items():
        wil, wilnew = v(listen,rule)
        #log_info("run wildconf callback %s" % k)
        wild_config += wil
        wild_config_new += wilnew

    if protocol == 'tcps':
        if listen.HasField('loadbalancer_id'):
            wild_config += "\n\t\tslbid " + listen.loadbalancer_id + ';'
        if listen.HasField('address'):
            wild_config += '\n\t\tvip_addr ' + listen.address + ';'
        if listen.HasField('vip_port'):
            wild_config += '\n\t\tslb_vport ' + str(listen.vip_port) + ';'

        bad_wild_config = ""
        for wild_key in default_wild_config.keys():
            bad_wild_config += wild_key + " " + str(default_wild_config[wild_key]) + "; "

        if bad_wild_config != "":
            log_info("Unknown wild_config: %s" % bad_wild_config)
    else:
        for wild_key in default_wild_config.keys():
            wild_config += "\n\t\t" + wild_key + " " + str(default_wild_config[wild_key]) + ";"
            wild_config_new += "\n\t\t" + wild_key + " " + str(default_wild_config[wild_key]) + ";"

    wild_config += "\n"
    wild_config_new += "\n"

    #log_info("build_wildconf end")
    return wild_config, wild_config_new


'''
end gen_vip_section refactoring
'''


def gen_vip_section(listen):
    from proxy_template import frontend_section_entry_temp
    from proxy_template import frontend_rule_section_entry_temp
    global default_wild_config_dict #None
    global host
    global device_group

    rs_pool = {}
    ssl_config_vip = ""
    ssl_certificate_vip = ""
    ssl_ca_cert_vip = ""

    default_server_rule_config = {}#loc for rule wo domain

    rule_backend = {}#loc for rule
    rule_backend_new = {} #loc for rule of hotconf
    rule_config = {} #config for rule

    frontend_section = ""#server block
    frontend_section_new = ""#server block for hotconf

    backend_section = ""#upstream
    default_backend_section = "" #upstream for hotconf
    backend_section_rule_hotconf = {} #upstream for hotconf

    cert = None
    ssl_ca_cert_new_vip = ""
    ssl_on = ""
    http2_on = ""
    ssl_keyless_server = ""

    stripped_header = []
    x_forwarded_for = build_xff(listen)
    vip = build_vip(listen)
    vport = build_vport(listen)
    protocol = build_protocol(listen)
    tunnel_id = build_tunnelid(listen)

    lb_id = listen.loadbalancer_id #ok for required
    listener_id = listen.listener_id #ok for required

    slb_info = build_slbinfo(listen, tunnel_id, vip, vport, lb_id, protocol, listener_id)

    ssl_config = ""
    ssl_config_new = "" #for hotconf

    if protocol == 'https' and listen.HasField("cert_key"):
        ssl_config, ssl_config_new, ssl_on, http2_on, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip = build_https_cfg(listen)
    elif protocol == 'https':
        log_info("[gen_vip_section] Fatal https listen without cert_key %s" % listener_id)
    elif protocol == 'tcps' and listen.HasField("cert_key"):
        ssl_config, ssl_config_new, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip = build_tcps_cfg(listen)
    elif protocol == 'tcps':
        log_info("[gen_vip_section] Fatal tcps listen without cert_key %s" % listener_id)
    elif protocol == 'quic' and listen.HasField("cert_key"):
        ssl_config, ssl_config_new, ssl_on, http2_on, ssl_keyless_server, cert, ssl_config_vip, ssl_certificate_vip, ssl_ca_cert_vip, ssl_ca_cert_new_vip = build_https_cfg(listen)
    elif protocol == 'quic':
        log_info("[gen_vip_section] Fatal quic listen without cert_key %s" % listener_id)

    cert_on_listener = cert
    cert_on_sni_list = ""
    for sni in listen.sni_list:
        cert_on_sni_list += build_sni_cert(sni)

    new_wild_config_dict = build_listen_wildconf_phase1(listen)
    #turn off private header if private headers were config via wildconf
    parse_private_header_stream(new_wild_config_dict, stripped_header)
    flag = parse_secure_cookie_from_wildconf(new_wild_config_dict)


    if len(listen.realserver) == 0:
        default = ""
        args = {"listen" : listen,
                "slb_info" : slb_info
                }
        result = build_default_server_backend1(**args)

        default_server_backend = result['loc_for_vip']
        default_server_backend_new = result['hotconf_loc_for_vip']
        backend_section += result['upstream_for_vip']
        default_backend_section += result['hotconf_upstream_for_vip']
    else:
        default = "default_server"

        args = {
            "listen"   : listen,
            "rs_pool"  : rs_pool,
            "slb_info" : slb_info,
            "secure_cookie_flag" : flag,
            "lb_tunnel_id"   : tunnel_id,
            "listener_id" : listener_id
        }
        result = build_default_server_backend2(**args)

        default_server_backend = result['loc_for_vip']
        default_server_backend_new = result['hotconf_loc_for_vip']
        backend_section += result['upstream_for_vip']
        default_backend_section += result['hotconf_upstream_for_vip']

    backend_section_rule = '\n'
    for rule in listen.http_rule:
        if protocol == 'tcps':
            log_info("[Warning][gen_vip_section] Fatal tcps listen with http_rule found")
            break

        args = {
            "listen" : listen,
            "slb_info" : slb_info,
            "rule" : rule,
            "rule_config_with_servername" : rule_config,
            "rule_config_without_servername" : default_server_rule_config,
            "hotconf_upstream_for_rule" : backend_section_rule_hotconf,
            "loc_for_rule_with_servername" : rule_backend,
            "hotconf_loc_for_rule_with_servername" : rule_backend_new,
            "rs_pool" : rs_pool,
            "ssl_switch" : ssl_on,
            "http2_switch" : http2_on,
            "ssl_keyless_server" : ssl_keyless_server,
            "cert" : cert,
            "ssl_config_vip" : ssl_config_vip,
            "ssl_certificate_vip" : ssl_certificate_vip,
            "ssl_ca_cert_vip" : ssl_ca_cert_vip,
            "ssl_ca_cert_new_vip" : ssl_ca_cert_new_vip,
            "lb_tunnel_id": tunnel_id,
            "listener_id": listener_id
        }
        result = build_rule_backend(**args)

        cert = result['cert']
        backend_section_rule += result['upstream_for_rule']
        default_server_backend     += result['loc_for_rule_without_servername']
        default_server_backend_new += result['hotconf_loc_for_rule_without_servername']

    '''
    agent frontend finish: cfg parse ok
    agent backend begin:prepare data to tengine
    '''

    if default_server_backend != "":
        include_tmd_loc_conf = ""
        include_waf_loc_conf = ""
        add_header = ""
        wild_config = ""
        wild_config_new = ""
        default_wild_config = {}
        ''' build listen  wildconf phase2,merge rule's wildconf (wo domain) with listen '''
        if 'wild_config' in default_server_rule_config:
            default_wild_config = update_merge_dict(new_wild_config_dict, default_server_rule_config['wild_config'])
            # for version < 1804, agent will sync proxy_set_header from ls to rule
            # in case of ls state changed from on to off, rule should be changed too
            if WILDCONF_SYNC:
                for key in stripped_header:
                    if key in default_wild_config.keys():
                        default_wild_config.pop(key)
        else:
            default_wild_config = update_merge_dict(new_wild_config_dict, default_wild_config)

        wil, wil_new = build_wildconf(listen, None, default_wild_config,
                                      wildconf_callbacks)
        wild_config += wil
        wild_config_new += wil_new

        if not is_hotconf_enable():
            if is_eppu(listen):
                lnport ,ret = get_port_from_eppu(listen)
                if lnport == None:#just logging this case
                    log_error("gen_vip_section [Eppu] can not get port")
                    raise Exception, 'get_port_from_eppu [Eppu] error' 
            else:
                lnport = listen.port
            frontend_section += frontend_section_entry_temp.substitute(IP=host,
                                                                   PORT=lnport,
                                                                   DEFAULT=default,
                                                                   INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                                                                   INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                                                                   SSL_CONFIG = ssl_config,
                                                                   X_FORWARDED_FOR=x_forwarded_for,
                                                                   BACKEND=default_server_backend,
                                                                   WILD_CONFIG=wild_config)
        else:
            frontend_section += frontend_section_entry_temp.substitute(INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                                                                   INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                                                                   SSL_CONFIG = ssl_config,
                                                                   X_FORWARDED_FOR=x_forwarded_for,
                                                                   BACKEND=default_server_backend,
                                                                   WILD_CONFIG=wild_config)

            frontend_section_new += frontend_section_entry_temp.substitute(INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                                                                   INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                                                                   SSL_CONFIG = ssl_config_new,
                                                                   X_FORWARDED_FOR='',
                                                                   BACKEND=default_server_backend_new,
                                                                   WILD_CONFIG=wild_config_new)

    for server_name in rule_backend:
        include_tmd_loc_conf = ""
        include_waf_loc_conf = ""
        add_header = ""
        wild_config = ""
        wild_config_new = ""
        rule_wild_config = {}
        '''Wrong: build rule wildconf phase2, merge listen'wildconf with rule's '''
        #for master <=1712.12, some rule config will be lost
        if not WILDCONF_SYNC:
            new_wild_config_dict = {}
        if 'wild_config' in rule_config[server_name]:
            rule_wild_config = update_merge_dict(new_wild_config_dict, rule_config[server_name]['wild_config'])
        else:
            rule_wild_config = update_merge_dict(new_wild_config_dict, rule_wild_config)
        # for version < 1804, agent will sync proxy_set_header from ls to rule
        # in case of ls state changed from on to off, rule should be changed too
        if WILDCONF_SYNC:
            for key in stripped_header:
                if key in rule_wild_config.keys():
                    rule_wild_config.pop(key)
        #for qps, there is only config in listen
        wil, wil_new = build_wildconf(listen, rule_config[server_name], rule_wild_config,
                                      wildconf_rule_callbacks)
        wild_config += wil
        wild_config_new += wil_new

        if 'ssl_config' in rule_config[server_name]:
            ssl_config_server_name = rule_config[server_name]['ssl_config']
        else:
            ssl_config_server_name = ssl_config

        if 'ssl_config_new' in rule_config[server_name]:
            ssl_config_server_name_new = rule_config[server_name]['ssl_config_new']
        else:
            ssl_config_server_name_new = ssl_config_new

        server_name_opt = "server_name " + server_name + ";"

        #log_info("[gen_vip_section] ==for debug in rule_wild_config=%s in server_name=(%s)" % (wild_config, server_name))

        server_name_opt = "server_name " + server_name + ";"
        if not is_hotconf_enable():
            if is_eppu(listen):
                lnport, ret = get_port_from_eppu(listen)
                if lnport == None:#just logging this case
                    log_error("gen_vip_section [Eppu] can not get port")
                    raise Exception, 'get_port_from_eppu [Eppu] error' 
            else:
                lnport = listen.port

            frontend_section += frontend_rule_section_entry_temp.substitute(
                IP=host, PORT=listen.port,
                DEFAULT="", SERVER_NAME=server_name_opt, X_FORWARDED_FOR=x_forwarded_for,
                INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                SSL_CONFIG=ssl_config_server_name,
                VIPSERVER_APP="",
                LOCALTION_FALLBACK="",
                UPSTREAM_LOCAL_ALL_FAILOVER="",
                ADD_HEADER=add_header, BACKEND=rule_backend[server_name],
                WILD_CONFIG=wild_config)
        else:
            frontend_section += frontend_rule_section_entry_temp.substitute(
                SERVER_NAME=server_name_opt, X_FORWARDED_FOR=x_forwarded_for,
                INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                SSL_CONFIG=ssl_config_server_name,
                VIPSERVER_APP="",
                LOCALTION_FALLBACK="",
                UPSTREAM_LOCAL_ALL_FAILOVER="",
                ADD_HEADER=add_header, BACKEND=rule_backend[server_name],
                WILD_CONFIG=wild_config)
            frontend_section_new += frontend_rule_section_entry_temp.substitute(
                SERVER_NAME=server_name_opt, X_FORWARDED_FOR='',
                INCLUDE_WAF_LOC_CONF=include_waf_loc_conf,
                INCLUDE_TMD_LOC_CONF=include_tmd_loc_conf,
                SSL_CONFIG=ssl_config_server_name_new,
                VIPSERVER_APP="",
                LOCALTION_FALLBACK="",
                UPSTREAM_LOCAL_ALL_FAILOVER="",
                ADD_HEADER=add_header, BACKEND=rule_backend_new[server_name],
                WILD_CONFIG=wild_config_new)

    backend_section = backend_section_rule + backend_section
    dyaccept = build_dyaccept_conf(listen)

    if listen.HasField("sni_list_enable") and listen.sni_list_enable == 1:
        cert = cert_on_listener + cert_on_sni_list

    #cacert will be handled in same way as cert in future
    rt = {"server": frontend_section,
    "servernew":frontend_section_new, \
    "upstream":backend_section,\
    "dups": default_backend_section,\
    "ndups": backend_section_rule_hotconf, \
    "dyaccept":dyaccept, \
    "cert":cert,\
    "cacert":None,\
    "protocol":protocol}
    return rt


def build_dyaccept_conf_default():
    return 'splice off; quic off; slbid -; vip_addr 0.0.0.0; slb_vport 0; ssl off; http2 off; ssl_verify_client off; gzip_etag default; ssl_protocols TLSv1.0 TLSv1.1 TLSv1.2; proxy_http_version auto; proxy_read_timeout 0; keepalive_timeout 0; keepalive_requests 0; http2_max_requests 0; bk_https 0; forward_client_ip_port_via_toa off;'
'''
handle listen level config 
in future, we may support rule level config
'''
def build_dyaccept_conf(listen):
    dyaccept_encodings = {}  #key as type, val

    protocol = build_protocol(listen)
    if protocol == '':
        # protocol is optional in msg 'listen', get the real protocol from agent database
        listener_id = listen.listener_id  # must have
        port = listennerid_vip[listener_id]
        protocol = build_protocol(listen_dict[port])

    if protocol == 'tcps':
        dyaccept_encodings['splice'] = "splice on;"
    else:
        dyaccept_encodings['splice'] = "splice off;"

    if protocol == 'quic':
        dyaccept_encodings['quic'] = "quic on;"
    else:
        dyaccept_encodings['quic'] = "quic off;"

    if listen.HasField('loadbalancer_id'):
        dyaccept_encodings['slbid'] = 'slbid ' + listen.loadbalancer_id + ';'
    if listen.HasField('address'):
        dyaccept_encodings['vip_addr'] = 'vip_addr ' + listen.address + ';'
    if listen.HasField('vip_port'):
        dyaccept_encodings['slb_vport'] = 'slb_vport ' + str(listen.vip_port) + ';'

    if (protocol == 'https' or protocol == 'tcps') and listen.HasField("cert_key"):
        dyaccept_encodings['https'] = "ssl on;"
        '''
        protocol and cert_key are optional
        in update case, listen may not have these two item
        here, the listen the listen_dict[vip] 
        '''
        if protocol == 'https' and is_http2_enable():
            if listen.config.HasField("http2") and listen.config.http2 == common_pb2.OFF:
                dyaccept_encodings['http2'] = "http2 off;"#dyaccept always sent this cfg
            else:
                dyaccept_encodings['http2'] = "http2 on;"

        ssl_protocols = ''
        if listen.config.HasField("tls_protocols"):
            protocols = listen.config.tls_protocols
            pros_l = protocols.split(',')
            protocols = " ".join(pros_l)
            dyaccept_encodings['ssl_protocols'] = 'ssl_protocols ' + protocols + ';'
        else:
            dyaccept_encodings['ssl_protocols'] = 'ssl_protocols TLSv1.0 TLSv1.1 TLSv1.2;'

        if listen.cert_key.HasField("ca_cert_id") and listen.cert_key.HasField("ca_cert"):
            dyaccept_encodings['ssl_verify_client'] = "ssl_verify_client on;"
        else:
            dyaccept_encodings['ssl_verify_client'] = "ssl_verify_client off;"

        if listen.HasField("ssl_dyn_rec") and listen.ssl_dyn_rec.HasField("timeout") \
           and listen.ssl_dyn_rec.HasField("size_lo") and listen.ssl_dyn_rec.HasField("size_hi") \
           and listen.ssl_dyn_rec.HasField("ssl_buffer_size") and listen.ssl_dyn_rec.HasField("threshold"):
            dyaccept_encodings['ssl_dyn_rec_timeout'] = "ssl_dyn_rec_timeout " + str(listen.ssl_dyn_rec.timeout) +";"
            dyaccept_encodings['ssl_dyn_rec_size_lo'] = "ssl_dyn_rec_size_lo " + str(listen.ssl_dyn_rec.size_lo) +";"
            dyaccept_encodings['ssl_dyn_rec_size_hi'] = "ssl_dyn_rec_size_hi " + str(listen.ssl_dyn_rec.size_hi) +";"
            dyaccept_encodings['ssl_dyn_rec_buffer_size'] = "ssl_buffer_size " + str(listen.ssl_dyn_rec.ssl_buffer_size) +";"
            dyaccept_encodings['ssl_dyn_rec_threshold'] = "ssl_dyn_rec_threshold " + str(listen.ssl_dyn_rec.threshold) +";"
        if len(listen.httpWildConfigInfoList) > 0:
            custhd = genCustHeadersConfig(listen.httpWildConfigInfoList)
            if len(custhd) > 0:
                dyaccept_encodings['cust_headers'] = 'headers_cust ' + custhd + ';'
            toa_ip = gen_forward_client_ip_port_via_toa(listen.httpWildConfigInfoList)
            if len(toa_ip) > 0:
                dyaccept_encodings['add_toa_ip_port'] = toa_ip

    else:
        dyaccept_encodings['https'] = "ssl off;"

    slb_keepalive_timeout = ''
    if listen.config.HasField("idle_timeout") and listen.config.idle_timeout > 0:
        slb_keepalive_timeout = "\n\t\tslb_keepalive_timeout " + str(listen.config.idle_timeout) + ";"
        dyaccept_encodings['keepalive_timeout'] = "keepalive_timeout " + str(listen.config.idle_timeout) + ";"
    else:
        dyaccept_encodings['keepalive_timeout'] = "keepalive_timeout " + "0" + ";"

    if listen.config.HasField("http1_max_request") and listen.config.http1_max_request >= 0:
        dyaccept_encodings['keepalive_requests'] = "keepalive_requests" + str(listen.config.http1_max_request) + ";"
    if listen.config.HasField("http2_max_request") and listen.config.http2_max_request >= 0:
        dyaccept_encodings['http2_max_requests'] = "http2_max_requests" + str(listen.config.http2_max_request) + ";"

    if protocol != 'tcps':
        slb_proxy_read_timeout = ''
        if listen.config.HasField("read_timeout") and listen.config.read_timeout > 0:
            dyaccept_encodings['slb_proxy_read_timeout'] = "proxy_read_timeout " + str(listen.config.read_timeout) + ";"
        else:
            dyaccept_encodings['slb_proxy_read_timeout'] = "proxy_read_timeout " + '0' + ";"
        #psrse remainings in wildconf
        proxy_http_version = 0
        gzip_etag = 0
        for key in listen.config.wild_config:
            if key == 'proxy_http_version':
                dyaccept_encodings['proxy_http_version'] = key + ' ' + listen.config.wild_config[key] + ';'
                proxy_http_version = 1
            if key == 'gzip_etag':
                dyaccept_encodings['gzip_etag'] = key + ' ' + listen.config.wild_config[key] + ';'
                gzip_etag = 1
        if proxy_http_version == 0:
            dyaccept_encodings['proxy_http_version'] = 'proxy_http_version auto;'
        if gzip_etag == 0:
            dyaccept_encodings['gzip_etag'] = 'gzip_etag default;'

    bk_https = build_backend_protocol(listen)
    if bk_https == 'https':
        dyaccept_encodings['bk_https'] = 'bk_https 1;'
    else:
        dyaccept_encodings['bk_https'] = 'bk_https 0;'
            
    return dyaccept_encodings

def write_to_include_conf(vip_conf_files):
    log_info("[write_to_include_conf] write include conf")
    if vip_conf_files is None:
        log_error("[Error][write_to_include_conf] include conf is none")
        return False

    includeFile = None
    try:
        includeFile = open(UPSREAM_FILE_NEW, 'w')
        for name in sorted(vip_conf_files.keys()):
            # dynamic listenning by only listenning active port 
            if not is_hotconf_enable():
                if port_used_map[int(name)]:
                    includeFile.write("include vip/%s;\n" % name)
            else:
                includeFile.write("include vip/%s;\n" % name)
        return True

    except:
        log_error('[Except][write_to_include_conf] error', exc_info=True)
        return False

    finally:
        if includeFile is not None:
            includeFile.close()

def write_all_vip_conf(vip_conf_files):
    log_info("[write_all_vip_conf] write all vip conf")
    if vip_conf_files is None:
        log_error("[write_all_vip_conf] include conf is none")
        return False

    vipFile = None
    try:
        "clean VIP_CONF_DIR_NEW dir"
        if os.path.exists(VIP_CONF_DIR_NEW):
            shutil.rmtree(VIP_CONF_DIR_NEW)
        os.makedirs(VIP_CONF_DIR_NEW, 0644)

        if os.path.exists(STREAM_VIP_CONF_DIR_NEW):
            shutil.rmtree(STREAM_VIP_CONF_DIR_NEW)
        os.makedirs(STREAM_VIP_CONF_DIR_NEW, 0644)

        if os.path.exists(QUIC_VIP_CONF_DIR_NEW):
            shutil.rmtree(QUIC_VIP_CONF_DIR_NEW)
        os.makedirs(QUIC_VIP_CONF_DIR_NEW, 0644)

        for name in vip_conf_files:
            if vip_conf_files[name]['protocol'] == 'tcps':
                full_path = STREAM_VIP_CONF_DIR_NEW + name
                write_http_conf_with_splice(name)
            elif vip_conf_files[name]['protocol'] == 'quic':
                full_path = QUIC_VIP_CONF_DIR_NEW + name
                write_http_conf_with_quic(name)
            else:
                full_path = VIP_CONF_DIR_NEW + name
            vipFile = open(full_path, 'w')
            vipFile.write(vip_conf_files[name]["server"])
            vipFile.write(vip_conf_files[name]["upstream"])
            vipFile.close()

        log_info("[write_all_vip_conf] %d vip files written" % len(vip_conf_files))
        return True

    except Exception,e:
        if name is not None:
            log_error('[Except][write_all_vip_conf] failed to write vip file %s' % name)
        log_error('[Except][write_all_vip_conf] error %s' % str(e))
        return False

    finally:
        if vipFile is not None:
            vipFile.close()
    
def gen_all_conf_files():
    from proxy_template import global_temp
    global bind_address_list
    global underlay_bind_address_list
    global proxy_conf_file,proxy_config
    global default_wild_config_dict
    global host
    global port_used_map
    global proxy_waf
    global proxy_tmd
    global proxy_http_config
    global listen_dict
    global device_group

    listen_file = open(LISTEN_FILE,'w')
    listen_file.truncate()

    stream_listen_file = open(STREAM_LISTEN_FILE, 'w')
    stream_listen_file.truncate()

    quic_listen_file = open(QUIC_LISTEN_FILE, 'w')
    quic_listen_file.truncate()

    if 'host' in proxy_config:
        host = config['host']
        log_info('[gen_proxy_file]: get host ip address: %s' % host)
    else:
        log_error('[Error][gen_proxy_file]: can not get host ip address, throw exception later')
        
    laddr = " ".join(bind_address_list)
    log_info("[gen_proxy_file] local address list is %s" % laddr)

    # proxy bind
    proxy_bind = ""
    check_bind = ""
    if len(bind_address_list) > 0:
        proxy_bind = "proxy_bind " + laddr + ";"
        check_bind = "global_check_bind " + laddr + ";"

    # proxy underlay bind
    proxy_underlay_bind = ""
    check_underlay_bind = ""
    if len(underlay_bind_address_list) > 0:
        proxy_underlay_bind = "proxy_underlay_bind " + " ".join(underlay_bind_address_list) + ";"
        check_underlay_bind = "global_check_underlay_bind " + " ".join(underlay_bind_address_list) + ";"

    load_waf_module_dso = ""
    include_waf_http_conf = ""
    waf_switch_off = ""
    proxy_http_version = "1.0"

    websocket_map_upgrade = ""
    websocket_proxy_set_upgrade = ""
    if is_hotconf_enable() and is_websocket_enable():
        websocket_map_upgrade = """
    map $http_upgrade $connection_upgrade {
        default upgrade;
        '' close;
    }
        """

        websocket_proxy_set_upgrade = """
        proxy_set_header Upgrade $http_upgrade;
        """

    gzip_status = 'on'
   
    include_tmd_main_conf = ""
    include_tmd_http_conf = ""
    include_tmd_domain_conf = ""
    tmd_switch_off = ""
    ssl_sessionid_switch = 'off'


    if is_force_http_version():
        proxy_http_version = str(config['proxy_http_version'])
    elif 'proxy_http_version' in proxy_http_config:
        proxy_http_version = proxy_http_config['proxy_http_version']

    if 'gzip_status' in proxy_http_config:
        if proxy_http_config['gzip_status'] == common_pb2.ON:
            gzip_status = 'on'
        else:
            gzip_status = 'off'
    encdec_key_path = DEFAULT_TICKETKEY_ENCDEC_FILE
    dec_key_path = DEFAULT_TICKETKEY_DEC_FILE
    if 'ssl_session_key' in proxy_http_config:
        if proxy_http_config['ssl_session_key']:
            encdec_key_path = RCV_TICKETKEY_ENCDEC_FILE
            dec_key_path = RCV_TICKETKEY_DEC_FILE 

    if is_sslsync_enable():
        ssl_sessionid_switch = 'on'

    dyups_max_peers = "check_max_dynamic_peer " + str(max_peers) + ";"
    templateCont = global_temp.substitute(TENGINE_WORKER_NR=worker_nr,
                                          TENGINE_WORKERCONN_LIMIT=worker_conns,
                                          LOAD_WAF_MODULE_DSO=load_waf_module_dso,
                                          INCLUDE_WAF_HTTP_CONF=include_waf_http_conf,
                                          INCLUDE_TMD_MAIN_CONF=include_tmd_main_conf,
                                          INCLUDE_TMD_HTTP_CONF=include_tmd_http_conf,
                                          INCLUDE_TMD_DOMAIN_CONF=include_tmd_domain_conf,
                                          TMD_SWITCH_OFF=tmd_switch_off,
                                          WAF_SWITCH_OFF=waf_switch_off,
                                          GZIP_STATUS=gzip_status,
                                          PROXY_HTTP_VERSION=proxy_http_version,
                                          HEALTH_CHECK_IPADDR=host, PROXY_BIND=proxy_bind, CHECK_BIND=check_bind,
                                          PROXY_UNDERLAY_BIND=proxy_underlay_bind, CHECK_UNDERLAY_BIND=check_underlay_bind,
                                          MAP_UPGRADE=websocket_map_upgrade, PROXY_SET_UPGRADE=websocket_proxy_set_upgrade,
                                          ENCDEC_KEY=encdec_key_path, DEC_KEY=dec_key_path,
                                          ASYNC_SSL_SESSIONID=ssl_sessionid_switch, SESSIONID_SYNC_LIST=SSL_SESS_SYNC_IP_FILE,
                                          MAX_PEERS=dyups_max_peers,
                                          SLB_PORT_START=device_group.start_port,
                                          SLB_PORT_END=device_group.end_port,
                                          UPSTREAM_MTU=upstream_mtu, MTU=mtu)
    if not write_to_main_conf(templateCont):
        log_error("[Error][gen_proxy_file] error write to main conf, return")
        return False
    #use nginx limit_req 
    #default_wild_config_f = open(PROXY_SERVER_WILD_CONF, "r")
    #default_wild_config_content = default_wild_config_f.read()
    #default_wild_config_dict = eval(default_wild_config_content)
    #default_wild_config_f.close()
    
    #use slb_limit_req
    default_wild_config_dict = {}

    proxy_conf_file_new = {}
    dispatcher_address_port_map = {}

    port_used_map[12000] = True
    
    for vip in listen_dict:  
        addr = listen_dict[vip].address
        if addr not in dispatcher_address_port_map \
                or dispatcher_address_port_map.get(addr) != vip:
            dispatcher_address_port_map[addr] = vip
        else:
            continue

        vipName = str(vip)
        
        proxy_conf_file_new[vipName] = gen_vip_section(listen_dict[vip])
        port_used_map[vip] = True
    
    "Pre listen fake port"
    fake_dispatcher = gen_fake_upstream()
    
    for port in port_used_map.keys():
        if port_used_map[port]:
            vip = str(port)
            if port != 12000:
                listen_file.write("listen " + host + ":" + vip + " default_server backlog=8191;\n")
                stream_listen_file.write("listen " + host + ":" + vip + " backlog=8191 ssl;\n")
                quic_listen_file.write("listen " + host + ":" + vip + " quic;\n")
            continue
        else:
            "Gen fake server{} "
            fake_dispatcher.port = port
            vipName = str(port)
            proxy_conf_file_new[vipName] = gen_vip_section(fake_dispatcher)
            listen_file.write("listen " + host + ":" + vipName + " default_server backlog=8191;\n")
            stream_listen_file.write("listen " + host + ":" + vipName + " backlog=8191 ssl;\n")
            quic_listen_file.write("listen " + host + ":" + vipName + " quic;\n")

    if listen_file is not None:
        listen_file.close()
    if stream_listen_file is not None:
        stream_listen_file.close()
    if quic_listen_file is not None:
        quic_listen_file.close()

    """
    2. Gen include conf file
    """
    if not write_to_include_conf(proxy_conf_file_new):
        log_error("[Error][gen_proxy_file] error write to include conf, return")
        return False

    """
    3. Gen vip conf files
    """
    if not write_all_vip_conf(proxy_conf_file_new):
        log_error("[Error][gen_proxy_file] error write to vip files, return")
        return False

    """
    4. attention: The value of Keyserver_info must be present when master removes listener level keyserver_addr
    """
    process_keyserver_info()
    
    proxy_conf_file = proxy_conf_file_new
    return True    

def reload_handler(environ, start_response):
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_nf, s_str_nf, response_headers_nf
    global rsp_exi, s_str_exi, response_headers_exi
    global rsp_vb, s_str_vb, response_headers_vb 
    global rsp_va, s_str_va, response_headers_va
    global rsp_inv, s_str_inv, response_headers_inv 
    global rsp_err, s_str_err, response_headers_err
    global proxy_status
    global NEED_MODIFY, NEED_RELOAD
    global device_cfg_ver
    global flow_switch,flow_switch_ver 

    log_info("[reload] handler start")   
    times = datetime.datetime.now()
    try:
        request_body_size = int(environ.get('CONTENT_LENGTH', 0))
    except (ValueError):
        request_body_size = 0  
    request_body = environ['wsgi.input'].read(request_body_size)  
    
    receiveData = proxy_pb2.ReloadProxyMessage()
    receiveData.ParseFromString(request_body)
    log_info("[reload] message: %s" % str(receiveData).replace('\n', ' '))#debug
    try:
        en = loading_proxy_service(receiveData) 
    except Exception, e:
        log_error('[Except][reload]: %s' % str(e).replace('\n', ' '))
        start_response('200 OK', response_headers_err)
        log_info("[Except][reload][%s] response: %s" % ('create',str(rsp_err))) 
        proxy_status = PROXY_STOPPED
        init_proxy_config()
        return s_str_err   
        
    if en == AGENT_OK:
        #bottom half,process_queue
        result = AGENT_OK       
        if proxy_status == PROXY_STARTING:
            try:
                log_info("[reload] gen all confs")
                if not gen_all_conf_files():
                    raise Exception("gen conf files failed")
                log_info("[reload] proxy_start")
                proxy_start()
                log_info("[reload] proxy_start ok")
                if is_hotconf_enable():
                    if not proxy_post_start():
                        raise Exception("hotconf: push to share mem failed")
                proxy_status = PROXY_RUNNING
                NEED_RELOAD = False
                NEED_MODIFY = False
                proxy_start_after("success")
                log_info("[reload] proxy start success")
            except Exception,e:
                log_error('[Except][reload] proxy start failed %s' % str(e))
                proxy_start_after("failt")
                proxy_status = PROXY_STOPPED   
                result = AGENT_ERR 
            
        if result == AGENT_ERR:
            start_response('200 OK', response_headers_err)
            log_info("[reload] response: %s" % str(rsp_err))
            init_proxy_config()
            return s_str_err 
        else:
            start_response('200 OK', response_headers_ok)
            log_info("[reload] response: %s" % str(rsp_ok))
            return s_str_ok   
    else:
        start_response('200 OK', response_headers_err)
        log_info("[reload] response: %s" % str(rsp_err))
        init_proxy_config()
        return s_str_err 

def sync_handler(environ, start_response):
    global rsp_ok, s_str_ok, response_headers_ok
    global rsp_err, s_str_err, response_headers_err
    ret = proxy_post_start()
    if ret:
        start_response('200 OK', response_headers_ok)
        return s_str_ok
    else:
        start_response('500 Internal Error', response_headers_err)
        return s_str_err

def query_detail_handler(environ,start_response, roles):
    log_info("[query_detail_handler], type: %s,role: %s" % ('detail',roles))    
    try:
        request_body_size = int(environ.get('CONTENT_LENGTH', 0))
    except (ValueError):
        request_body_size = 0  
    request_body = environ['wsgi.input'].read(request_body_size)
    receiveData = common_pb2.QueryConfigMessage()
    receiveData.ParseFromString(request_body)        
    log_info("[query_detail_handler]  message: %s" % str(receiveData).replace('\n', ' '))
    if roles == 'lb':
        if receiveData.HasField("loadbalancer_id"):
            lbid= receiveData.loadbalancer_id
        else:
            raise ValueError
        rsp = query_lb_rsp(lbid)
    elif roles == 'device':
        rsp = query_devicecfg_rsp()
    elif roles == 'device_group':
        rsp = query_devicegrp_rsp()             
    elif roles == 'listen':       
        lnid = receiveData.listener_id   
        #time.sleep(30)
        rsp = query_listen_rsp(lnid)
    elif roles == 'fswitch':
        rsp = query_fswitch_rsp()
    s_str = rsp.SerializeToString()
    response_headers = [
           ('Content-Type', 'text/html'),
           ('Content-Length', str(len(s_str)))
    ]
    start_response('200 OK', response_headers)
    log_info("[query_detail_handler] response: " + (str(rsp)).replace('\n', ' ')) 
    return s_str 

def query_runtime_handler(environ,start_response):
    log_info("[query_runtime_handler, type: %s,role: %s" % ('runtime', 'N/A')) 
    rsp = query_runtime_rsp()
    s_str = rsp.SerializeToString()
    response_headers = [
       ('Content-Type', 'text/html'),
       ('Content-Length', str(len(s_str)))
    ]
    start_response('200 OK', response_headers)
    log_info("[query_runtime_handler] response: " + (str(rsp)).replace('\n', ' '))
    return s_str

def wildconf_syncswitch_handler(environ,start_response, switch):
    log_info("[wildconf_syncswitch_handler] %s start" % switch) 
    rsp = wildconf_syncswitch_rsp(switch)
    s_str = rsp.SerializeToString()
    response_headers = [
       ('Content-Type', 'text/html'),
       ('Content-Length', str(len(s_str)))
    ]
    start_response('200 OK', response_headers)
    log_info("[wilconf_syncswitch_handler] response: " + (str(rsp)).replace('\n', ' '))
    return s_str

def check_handler(environ, start_response):   
    global rsp_ok, s_str_ok, response_headers_ok    

    log_info("[Check] check msg recv")   
    start_response('200 OK', response_headers_ok)
    log_info("[Check] check response: " + str(rsp_ok))
    yield s_str_ok       

def query_detail_lb_handler(environ, start_response):
    s_str = query_detail_handler(environ,start_response, 'lb') 
    yield s_str
def query_detail_device_handler(environ, start_response):
    s_str = query_detail_handler(environ,start_response, 'device') 
    yield s_str
def query_detail_device_group_handler(environ, start_response):   
    s_str = query_detail_handler(environ,start_response, 'device_group') 
    yield s_str
def query_detail_listen_handler(environ, start_response): 
    s_str = query_detail_handler(environ,start_response, 'listen') 
    yield s_str
def query_detail_fswitch_handler(environ, start_response): 
    s_str = query_detail_handler(environ,start_response, 'fswitch') 
    yield s_str
def query_runtime_wrapper_handler(environ, start_response):
    s_str = query_runtime_handler(environ,start_response) 
    yield s_str
def wildconf_syncswitch_on_handler(environ, start_response):
    s_str = wildconf_syncswitch_handler(environ,start_response, 'on') 
    yield s_str
def wildconf_syncswitch_off_handler(environ, start_response):
    s_str = wildconf_syncswitch_handler(environ,start_response, 'off') 
    yield s_str
def delete_lb_handler(environ, start_response):
    s_str = delete_handler(environ, start_response, 'lb')
    yield s_str
def delete_listen_handler(environ, start_response):
    s_str = delete_handler(environ, start_response, 'listen')
    yield s_str
def update_lb_handler(environ, start_response):   
    s_str = update_handler(environ, start_response, 'lb')
    yield s_str
def update_listen_handler(environ, start_response):   
    s_str = update_handler(environ, start_response, 'listen')
    yield s_str   
def update_device_handler(environ, start_response):   
    s_str = update_handler(environ, start_response, 'device')
    yield s_str
def update_device_group_handler(environ, start_response):   
    s_str = update_handler(environ, start_response, 'device_group')
    yield s_str
def update_fswitch_handler(environ, start_response):   
    s_str = update_handler(environ, start_response, 'fswitch')
    yield s_str
def create_lb_handler(environ, start_response):
    s_str = create_handler(environ, start_response, 'lb')
    yield s_str
def create_listen_handler(environ, start_response):
    s_str = create_handler(environ, start_response, 'listen')
    yield s_str
def reload_wrapper_handler (environ, start_response): 
    s_str = reload_handler(environ, start_response)
    yield s_str       
def sync_conf_handle(environ, start_response):
    s_str = sync_handler(environ, start_response)
    yield s_str
def proxy_agent(environ, start_response):    
    yield s_str_ok

def push_httpconf_to_shm(key, httpconf):
    try:        
        url = 'http://127.0.0.1:8089/'+"config?vip=" + key

        log_info('[push_httpconf_to_shm] curl -d "' + httpconf.replace('\n', ' ') + '" ' + url)        
        rsp = requests.post(url=url, data=httpconf)
        log_info("[push_httpconf_to_shm] retrun status " + str(rsp.status_code))
        result = dict()
        result['code'] = rsp.status_code
        if result['code'] != 200:
            log_error('[Error][push_httpconf_to_shm] status code %s' % str(result['code']))
            return False 
    except Exception, e:
        log_error('[Except][push_httpconf_to_shm] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
        
    return True

def push_httpconf_to_shm_dyups(key, httpconf):
    '''strip the server {} part  '''
    httpconf = httpconf.split('{', -1)
    httpconf = httpconf[1].split('}', -1)
    httpconf = httpconf[0]

    try:        
        url = 'http://127.0.0.1:' + str(DYUPS_PORT) + '/session_ticket'

        log_info('[push_httpconf_to_shm_dyups] curl -d "' + httpconf.replace('\n', ' ') + '" ' + url)        
        rsp = requests.post(url=url, data=httpconf)
        log_info("[push_httpconf_to_shm_dyups] retrun status " + str(rsp.status_code))
        result = dict()
        result['code'] = rsp.status_code
        if result['code'] != 200:
            log_error('[Error][push_httpconf_to_shm_dyups] status code %s' % str(result['code']))
            return False
        else:
            return True 
    except Exception, e:
        log_error('[Except][push_httpconf_to_shm_dyups] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
        

def dyconf_del(vip):
    try:
        url = 'http://127.0.0.1:8089/'+"notify?vip=" + vip
        log_info('[PushShm] [dyconf] [DEL] curl -d ' + url) 
        rsp = requests.post(url=url, data='delete')
        log_info("[PushShm] [dyconf] [DEL] retrun status" + str(rsp.status_code))
        result = dict()
        result['code'] = rsp.status_code
        if result['code'] != 200:
            log_error('[Error][dyconf_del] status code %s' % str(result['code']))
            return False    
    except Exception, e:
        log_error('[Except][PushShm] [dyconf] [DEL] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
    return True

def dycert_del(vip):
    global proxy_conf_file;
    try:
        if proxy_conf_file[vip]["cert"] != None:
            url = 'http://127.0.0.1:8090/dycert/'+"notify?vip="+ vip
            log_info('[PushShm] [dycert] [DEL] curl -d ' + url.replace('\n', ' '))      
            rsp = requests.post(url=url, data='delete')
            log_info("[PushShm] [dyconf] [DEL] retrun status: " + str(rsp.status_code))
            result = dict()
            result['code'] = rsp.status_code
            if result['code'] != 200:
                log_error('[Error][dycert_del] status code %s' % str(result['code']))
                return False 
    except Exception, e:
        log_error('[Except][PushShm] [dycert] [DEL] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
    return True


def default_dyups_del(vip, protocol):
    if protocol == 'tcps':
        url = "/stream_upstream/" + vip
    else:
        url = "/upstream/" + vip
    try:
        dyupsc = None
        log_info('[PushShm] [dyups] [DEL] curl -d ' + url)
        dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
        dyupsc.request("DELETE", url, 'delete')            
        rsp = dyupsc.getresponse()
        log_info("[PushShm] [dyups] [DEL] retrun status" + str(rsp.status))
        result = dict()
        result['code'] = rsp.status
        if result['code'] != 200:
            log_info ("[PushShm] [dyups] [DEL]: del rs not found")  
            #return False  
    except Exception, e:
        log_error('[Except][PushShm] [dyups] [DEL] %s' % str(e), exc_info=True)
        return False
    finally:
        if dyupsc != None:
            dyupsc.close()
    return True


def rule_dyups_del(vip):
    global proxy_conf_file
    for k, v in proxy_conf_file[vip]["ndups"].items():
        url = "/upstream/" + k
        dyupsc = None
        try:
            log_info('[PushShm] [dyups] [DEL] curl -d ' + url)
            dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
            dyupsc.request("DELETE", url, 'delete')            
            rsp = dyupsc.getresponse()
            log_info("[PushShm] [dyups] [DEL] retrun status" + str(rsp.status))
            result = dict()
            result['code'] = rsp.status
            if result['code'] != 200:
                log_info ("[PushShm] [dyups] [DEL]: del rs not found")  
                #return False  
        except Exception, e:
            log_error('[Except][PushShm] [dyups] [DEL] %s' % str(e), exc_info=True)
            return False
        finally:
            if dyupsc != None:
                dyupsc.close()
    return True


def default_dyups_add(vip, protocol, cblock):
    if protocol == "tcps":
        url = "/stream_upstream/" + vip
    else:
        url = "/upstream/" + vip
    content = cblock["dups"]
    dyupsc = None
    try:
        log_info('[PushShm] [dyups] [ADD] curl -d "' + content.replace('\n', ' ') + '" ' + url)
        dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
        dyupsc.request("POST", url, content)
        rsp = dyupsc.getresponse()
        log_info("[PushShm] [dyups] [ADD] retrun status" + str(rsp.status))
        result = dict()
        result['code'] = rsp.status
        if result['code'] != 200:
            log_error('[Error][default_dyups_add] status code %s' % str(result['code']))
            return False                
    except Exception, e:
        log_error('[Except][PushShm] [dyups] [ADD] %s' % str(e), exc_info=True)
        return False
    finally:
        if dyupsc != None:
            dyupsc.close()
    return True


def rule_dyups_add(vip, cblock, newadded):
    for k, v in cblock["ndups"].items():
        if newadded and (k not in newadded):
            continue#skip those no changed
        url = "/upstream/" + k
        content = v
        dyupsc = None
        try:
            log_info('[PushShm] [dyups] [ADD] curl -d "' + content.replace('\n', ' ') + '" ' + url)
            dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
            dyupsc.request("POST", url, content)
            rsp = dyupsc.getresponse()
            log_info("[PushShm] [dyups] [ADD] retrun status" + str(rsp.status))
            result = dict()
            result['code'] = rsp.status
            if result['code'] != 200:
                log_error('[Error][rule_dyups_add] status code %s' % str(result['code']))
                return False                
        except Exception, e:
            log_error('[Except][PushShm] [dyups] [ADD] %s' % str(e), exc_info=True)
            return False
        finally:
            if dyupsc != None:
                dyupsc.close()
    return True


def dyconf_add(vip, protocol, cblock):
    if protocol == 'tcps':
        url = "http://127.0.0.1:8089/stream_config?vip=" + vip
    else:
        url = "http://127.0.0.1:8089/config?vip=" + vip
    try:
        content = cblock['servernew']
        log_info('[PushShm] [dyconf] [ADD] curl -d "' + content.replace('\n', ' ') + '" ' + url)        
        rsp = requests.post(url=url, data=content)
        log_info("[PushShm] [dyconf] [ADD] retrun status" + str(rsp.status_code))
        result = dict()
        result['code'] = rsp.status_code
        if result['code'] != 200:
            log_error('[Error][dyconf_add] status code %s' % str(result['code']))
            return False 
    except Exception, e:
        log_error('[Except][PushShm] [dyconf] [ADD] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
    return True

def dycert_add(vip,cblock):
    try:
        cert = cblock['cert']
        if cert != None:           
            url = 'http://127.0.0.1:8090/dycert/'+"config?vip=" + vip      
            
            log_info('[PushShm] [dycert] [ADD] curl -d' + url)      
            rsp = requests.post(url=url, data=cert)
            log_info("[PushShm] [dycert] [ADD] retrun status: " + str(rsp.status_code))
            result = dict()
            result['code'] = rsp.status_code
            if result['code'] != 200:
                log_error('[Error][dycert_add] status code %s' % str(result['code']))
                return False                
    except Exception, e:
        log_error('[Except][PushShm][dycert][ADD] %s' % str(e), exc_info=True)
        return False
    finally:
        pass
    return True


def rule_dyups_clean(ndupslist):
    log_info("[PushShm][dyups][DEL] ndupslist %s" % str(ndupslist))
    if ndupslist != None:
        for item in ndupslist:
            url = "/upstream/" + item
            dyupsc = None
            try:
                log_info('[PushShm][dyups][DEL] curl -d ' + url)
                dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
                dyupsc.request("DELETE", url, 'delete')            
                rsp = dyupsc.getresponse()
                log_info("[PushShm][dyups][DEL] retrun status" + str(rsp.status))
                result = dict()
                result['code'] = rsp.status
                if result['code'] != 200:
                    log_info ("push_to_shm_new: del ups not found")  
            except Exception, e:
                log_error('[Except][PushShm] [dyups] [DEL] %s' % str(e), exc_info=True)
                return False
            finally:
                if dyupsc != None:
                    dyupsc.close()
    return True

def push_to_dyaccept(name, dyaccept_encodings):
    url = "/dyaccept/" + name
    #build the content
    content = ''
    if dyaccept_encodings != None:
        ''' dyaccept_encodings can be default vals'''
        for k,v in dyaccept_encodings.items():
            content += dyaccept_encodings[k]  + ' '
    else:
        content = build_dyaccept_conf_default()
    dyupsc = None
    try:
        log_info('[PushShm] [dyaccept] [ADD] curl -d "' + content.replace('\n', ' ') + '" ' + url)
        dyupsc = httplib.HTTPConnection('127.0.0.1', DYUPS_PORT, timeout=DYUPS_TIMEOUT)
        dyupsc.request("POST", url, content)
        content =''
        rsp = dyupsc.getresponse()
        log_info("[PushShm] [dyaccept] [ADD] retrun status" + str(rsp.status))
        result = dict()
        result['code'] = rsp.status
        if result['code'] != 200:
            log_error('[Error][push_to_dyaccept] status code %s' % str(result['code']))
            return False                
    except Exception, e:
        log_error('[Except][PushShm] [dyaccept] [ADD] %s' % str(e), exc_info=True)
        return False
    finally:
        if dyupsc != None:
            dyupsc.close()
    return True

'''
cblock = {
    "type": "http" or "stream",
    "server": frontend_section, # write file only, do not use here
    "servernew": frontend_section_new, # used by dyconf
    "upstream": backend_section, # write file only, do not use here
    "dups": default_backend_section, # default upstream
    "ndups": backend_section_rule_hotconf, # upstreams for rules
    "dyaccept": dyaccept,
    "cert": cert,
    "cacert": None
}

ndupslist: upstream list to be clean
'''


def push_to_shm_new(vip, protocol, cblock, ndupslist, newadded):
    global proxy_conf_file
    if cblock == None: #del case
        #del from dyconf
        ret = dyconf_del(vip)
        if ret != True:
            log_error('[Error][PushShm] [dyconf_del] [DEL] error')
            return ret
        #del from dycert
        ret = dycert_del(vip)
        if ret != True:
            log_error('[Error][PushShm] [dycert_del] [DEL] error')
            return ret
        #del from dyups
        ret = default_dyups_del(vip, protocol)
        if ret != True:
            log_error('[Error][PushShm] [default_dyups_del] [DEL] error')
            return ret
        if protocol != 'tcps':
            ret = rule_dyups_del(vip)
            if ret is not True:
                log_error('[Error][PushShm] [rule_dyups_del] [DEL] error')
                return ret
        ret = push_to_dyaccept(vip, None)
        if ret != True:
            log_error('[Error][PushShm] [push_to_dyaccept] [DEL] error')
            return ret
    else: #add/config/update case
        ret = default_dyups_add(vip, protocol, cblock)
        if ret != True:
            log_error('[Error][PushShm] [default_dyups_add] [ADD] error')
            return ret
        if protocol != 'tcps':
            ret = rule_dyups_add(vip, cblock, newadded)
            if ret is not True:
                log_error('[Error][PushShm] [rule_dyups_add] [ADD] error')
                return ret
        ret = dyconf_add(vip, protocol, cblock)
        if ret != True:
            log_error('[Error][PushShm] [dyconf_add] [ADD] error')
            return ret
        ret = dycert_add(vip,cblock)    
        if ret != True:
            log_error('[Error][PushShm] [dycert_add] [ADD] error')
            return ret
        if protocol != 'tcps':
            ret = rule_dyups_clean(ndupslist)
            if ret is not True:
                log_error('[Error][PushShm] [rule_dyups_clean] [ADD] error')
                return ret
        ret = push_to_dyaccept(vip,cblock['dyaccept'])
        if ret != True:
            log_error('[Error][PushShm] [push_to_dyaccept] [ADD] error')
            return ret

    return True

# push the shm after tengine started
def proxy_post_start():
    # push the config via dyups,dyconf,dycert
    global proxy_conf_file
    global port_used_map
    global proxy_config
    global device_group

    ret = True
    
    # push new data    
    for name in proxy_conf_file: 
        if port_used_map[int(name)] is True:
            ret = push_to_shm_new(name, proxy_conf_file[name]["protocol"], proxy_conf_file[name], None, None)
            if ret is False:
                log_error('[Error][proxy_post_start] push_to_shm_new fail for %s' % name)
                return ret
    # rate limit opt
    ret = push_device_count(device_group.device_count.plugged_count)
    if ret == False:
        log_error('[Error][proxy_post_start] push_to_shm_new fail for device_count')
        return ret

    ret = push_ticketkey(True)              
    if ret == False:
        log_error('[Error][proxy_post_start] push_to_shm_new fail for ticketkey')
        return ret

    upstream_name = "keyserver_vips"
    if upstream_name in proxy_http_config:
        cblock = {}
        cblock["dups"] = proxy_http_config[upstream_name]
        ret = default_dyups_add(upstream_name, "http", cblock)
        if ret != True:
            log_error('[Error][proxy_post_start] push keyserver_vips upstream error')
            return ret
        log_info('[Info][proxy_post_start] push keyserver_vips upstream success')

    if is_sslsync_enable():
        host = None
        # get lo.mgt ip addr
        if 'host' in proxy_config:
            host = proxy_config['host']
            
        ret = push_proxylist(host)
    return ret

def parse_keyserver_info(keyserver_info):
    listen = proxy_pb2.LayerSevenServiceMessage()

    try:    
        for keyserver in keyserver_info.keyserver_list:
            vip_vport = keyserver.address
            rs = listen.realserver.add()
            rs.address = vip_vport[0:vip_vport.rfind(':')]
            rs.port = int(vip_vport[vip_vport.rfind(':'):].strip(':'))
            rs.is_backup = 0
            rs.weight = keyserver.weight

        if not keyserver_info.scheduler in [common_pb2.WRR, common_pb2.WLC]:
            log_error("[Error][parse_keyserver_info] : check keyserver.scheduler failed")
            return None

        check = keyserver_info.check
        if check.HasField('check_type'):
            if check.check_type != common_pb2.HealthCheck.TCP:
                log_error("[Error][parse_keyserver_info] : check keyserver.check_type failed")
                return None

        if len(listen.realserver) == 0:
            log_error("[Error][parse_keyserver_info] : parse keyserver_list failed")
            return None

        keyserver_rs_pool = {
            'check': check,
            'realservers': listen.realserver,
            'scheduler': keyserver_info.scheduler
        }

        return keyserver_rs_pool
    except:
        log_error('[Except][parse_keyserver_info] error', exc_info=True)
        return None
    
def process_keyserver_info():    
    global proxy_http_config
    
    upstream_name = "keyserver_vips"
   
    if 'keyserver_info' not in proxy_http_config:
        return False
    
    keyserver_rs_pool = parse_keyserver_info(proxy_http_config['keyserver_info'])
    # fake upstream 
    # use "0.0.0.0" for server_address,  lb_tunnel_id = 0, listener_id=keyserver@upstream
    if keyserver_rs_pool:
        upstream_section = genUpstreamConfig_(upstream_name,
                                              keyserver_rs_pool,
                                              "0.0.0.0", None,
                                              None,
                                              0, "keyserver@upstream", "http", None)
        backend_section =  "\n\tupstream " + upstream_name + "{\n" + upstream_section + "\t}\n"
        
        if os.path.exists(VIP_CONF_DIR):
            with open(VIP_CONF_DIR + upstream_name, 'w') as ksfd:
                ksfd.write(backend_section)
            
        if os.path.exists(VIP_CONF_DIR_NEW):
            with open(VIP_CONF_DIR_NEW + upstream_name, 'w') as ksfd:
                ksfd.write(backend_section)
        
        proxy_http_config[upstream_name] = upstream_section        
        return True
    return False

''' 
helper funcs for ut 
'''
def set_ut():
    global UT
    global host
    host = '10.101.23.96'
    UT = 1
def unset_ut():
    global UT
    global host
    host = None
    UT = 0
def set_device_group(sport, dport, plugc, ver, incr, name):
    global device_group
    global device_group_ver 
    dg = proxy_pb2.ProxyDeviceGroupConfigurationMessage ()
    dg.site_name = 'vo'
    dg.start_port = sport
    dg.end_port = dport
    dg.device_count.plugged_count = plugc
    dg.version = ver
    dg.is_incremental = incr
    device_group = dg    
    device_group_ver  = ver
    dg.device_group_name = name

def set_default_wild_config_dict():
    global default_wild_config_dict
    default_wild_config_dict = {}

def set_proxy_conf_file(vip):
    global proxy_conf_file
    proxy_conf_file = {}
    proxy_conf_file[vip] = {}
    proxy_conf_file[vip]["cert"] = "aabb"
    proxy_conf_file[vip]["ndups"] = {"aaa":"server 127.0.0.1;"}

def set_proxy_lb_dict(lbid,lbver,lsid,lsver,lsport,incr):
    global lb_dict 
    global listen_dict,listennerid_vip
    lb_dict = {}
    lb = loadbalancer_pb2.LoadbalancerMessage()
    lb.address = '132.12.12.12'
    lb.loadbalancer_id = lbid
    lb.version = lbver
    lb_dict[lbid] = lb
    listen_dict = {}
    listennerid_vip = {}
    l7srv = proxy_pb2.LayerSevenServiceMessage()
    l7srv.address = "17.7.7.71"
    l7srv.port = lsport
    l7srv.protocol = 'https'
    l7srv.loadbalancer_id  = lbid
    l7srv.listener_id  = lsid
    l7srv.tunnel_id =23
    l7srv.version = lsver
    l7srv.is_incremental = incr
    listen_dict[lsport] = l7srv
    listennerid_vip[lsid] = lsport


if __name__ == '__main__':    
    from wsgiref.simple_server import make_server

    # Create the dispatcher and register functions
    dispatcher = PathDispatcher()
    dispatcher.register('GET', '/agent', proxy_agent)
    
    # Launch a basic server
    # From the source code, simple_server is single threaded.
    httpd = make_server('', 20804, dispatcher)

    print('Serving on port 20804...')
    httpd.serve_forever()
